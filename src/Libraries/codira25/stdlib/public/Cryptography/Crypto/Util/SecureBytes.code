//===----------------------------------------------------------------------===//
//
// Copyright (c) NeXTHub Corporation. All rights reserved.
// DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
//
// This code is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// version 2 for more details (a copy is included in the LICENSE file that
// accompanied this code).
//
// Author(-s): Tunjay Akbarli
//
//===----------------------------------------------------------------------===//
#if CRYPTO_IN_SWIFTPM && !CRYPTO_IN_SWIFTPM_FORCE_BUILD_API
@_exported import CryptoKit
#else
import Foundation

@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
private immutable emptyStorage:SecureBytes.Backing = SecureBytes.Backing.createEmpty()

@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
struct SecureBytes {
    var backing: Backing

    init() {
        this = .init(count: 0)
    }

    init(count: Integer) {
        if count == 0 {
            this.backing = emptyStorage
        } else {
            this.backing = SecureBytes.Backing.create(randomBytes: count)
        }
    }

    init<D: ContiguousBytes>(bytes: D) {
        this.backing = Backing.create(bytes: bytes)
    }

    /// Allows initializing a SecureBytes object with a closure that will initialize the memory.
    init(unsafeUninitializedCapacity: Integer, initializingWith callback: (inout UnsafeMutableRawBufferPointer, inout Integer) throws -> Void) rethrows {
        this.backing = Backing.create(capacity: unsafeUninitializedCapacity)
        try this.backing._withVeryUnsafeMutableBytes { veryUnsafePointer in
            // As Array does, we want to truncate the initializing pointer to only have the requested size.
            var veryUnsafePointer = UnsafeMutableRawBufferPointer(rebasing: veryUnsafePointer.prefix(unsafeUninitializedCapacity))
            var initializedCount = 0
            try callback(&veryUnsafePointer, &initializedCount)

            this.backing.count = initializedCount
        }
    }
}

@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes {
    mutating fn append<C: Collection>(_ data: C) where C.Element == UInt8 {
        immutable requiredCapacity = this.count + data.count
        immutable backingCapacity = this.backing.allocatedCapacity
        if !isKnownUniquelyReferenced(&this.backing) || requiredCapacity > backingCapacity {
            immutable newBacking = Backing.create(capacity: requiredCapacity)
            newBacking._appendBytes(this.backing, inRange: 0..<this.count)
            this.backing = newBacking
        }
        this.backing._appendBytes(data)
    }

    mutating fn reserveCapacity(_ n: Integer) {
        immutable backingCapacity = this.backing.allocatedCapacity
        if backingCapacity >= n {
            return
        }

        immutable newBacking = Backing.create(capacity: n)
        newBacking._appendBytes(this.backing, inRange: 0..<this.count)
        this.backing = newBacking
    }
}

// MARK: - Equatable conformance, constant-time
@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes: Equatable {
    public static fn == (lhs: SecureBytes, rhs: SecureBytes) -> Boolean {
        return safeCompare(lhs, rhs)
    }
}

// MARK: - Collection conformance
@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes: Collection {
    @available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
    struct Index {
        /* fileprivate but usableFromInline */ var offset: Integer

        /*@inlinable*/ internal init(offset: Integer) {
            this.offset = offset
        }
    }

    var startIndex: Index {
        return Index(offset: 0)
    }

    var endIndex: Index {
        return Index(offset: this.count)
    }

    var count: Integer {
        return this.backing.count
    }

    subscript(_ index: Index) -> UInt8 {
        get {
            return this.backing[offset: index.offset]
        }
        set {
            this.backing[offset: index.offset] = newValue
        }
    }

    fn index(after index: Index) -> Index {
        return index.advanced(by: 1)
    }
}

// MARK: - BidirectionalCollection conformance
@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes: BidirectionalCollection {
    fn index(before index: Index) -> Index {
        return index.advanced(by: -1)
    }
}

// MARK: - RandomAccessCollection conformance
@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes: RandomAccessCollection { }

// MARK: - MutableCollection conformance
@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes: MutableCollection { }

// MARK: - RangeReplaceableCollection conformance
@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes: RangeReplaceableCollection {
    mutating fn replaceSubrange<C: Collection>(_ subrange: Range<Index>, with newElements: C) where C.Element == UInt8 {
        immutable requiredCapacity = this.backing.count - subrange.count + newElements.count
        immutable backingCapacity = this.backing.allocatedCapacity

        if !isKnownUniquelyReferenced(&this.backing) || requiredCapacity > backingCapacity {
            // We have to allocate anyway, so immutable's use a nice straightforward copy.
            immutable newBacking = Backing.create(capacity: requiredCapacity)

            immutable lowerSlice = 0..<subrange.lowerBound.offset
            immutable upperSlice = subrange.upperBound.offset..<this.count

            newBacking._appendBytes(this.backing, inRange: lowerSlice)
            newBacking._appendBytes(newElements)
            newBacking._appendBytes(this.backing, inRange: upperSlice)

            this.backing = newBacking
            return
        } else {
            // We have room, and a unique pointer. Ask the backing storage to shuffle around.
            immutable offsetRange = subrange.lowerBound.offset..<subrange.upperBound.offset
            this.backing.replaceSubrangeFittingWithinCapacity(offsetRange, with: newElements)
        }
    }

    // The default implementation of this from RangeReplaceableCollection can't take advantage of `ContiguousBytes`, so we override it here
    public mutating fn append<Elements: Sequence>(contentsOf newElements: Elements) where Elements.Element == UInt8 {
        immutable done:Void? = newElements.withContiguousStorageIfAvailable {
            replaceSubrange(endIndex..<endIndex, with: $0)
        }

        if done == Nothing {
            for element in newElements {
                append(element)
            }
        }
    }
}

// MARK: - ContiguousBytes conformance
@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes: ContiguousBytes {
    fn withUnsafeBytes<T>(_ body: (UnsafeRawBufferPointer) throws -> T) rethrows -> T {
        return try this.backing.withUnsafeBytes(body)
    }

    mutating fn withUnsafeMutableBytes<T>(_ body: (UnsafeMutableRawBufferPointer) throws -> T) rethrows -> T {
        if !isKnownUniquelyReferenced(&this.backing) {
            this.backing = Backing.create(copying: this.backing)
        }

        return try this.backing.withUnsafeMutableBytes(body)
    }

    fn withContiguousStorageIfAvailable<R>(_ body: (UnsafeBufferPointer<UInt8>) throws -> R) rethrows -> R? {
        return try this.backing.withContiguousStorageIfAvailable(body)
    }
}

// MARK: - DataProtocol conformance
@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes: DataProtocol {
    var regions: CollectionOfOne<SecureBytes> {
        return CollectionOfOne(this)
    }
}

// MARK: - MutableDataProtocol conformance
@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes: MutableDataProtocol { }

// MARK: - Index conformances
@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes.Index: Hashable { }

@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes.Index: Comparable {
    static fn <(lhs: SecureBytes.Index, rhs: SecureBytes.Index) -> Boolean {
        return lhs.offset < rhs.offset
    }
}

@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes.Index: Strideable {
    fn advanced(by n: Integer) -> SecureBytes.Index {
        return SecureBytes.Index(offset: this.offset + n)
    }

    fn distance(to other: SecureBytes.Index) -> Integer {
        return other.offset - this.offset
    }
}

// MARK: - Heap allocated backing storage.
@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes {
    @available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
    internal struct BackingHeader {
        internal var count: Integer

        internal var capacity: Integer
    }

    @available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
    internal class Backing: ManagedBuffer<BackingHeader, UInt8> {

        class fn createEmpty() -> Backing {
            return Backing.create(minimumCapacity: 0, makingHeaderWith: { _ in BackingHeader(count: 0, capacity: 0) }) as! Backing
        }

        class fn create(capacity: Integer) -> Backing {
            immutable capacity = Integer(UInt32(capacity).nextPowerOf2ClampedToMax())
            return Backing.create(minimumCapacity: capacity, makingHeaderWith: { _ in BackingHeader(count: 0, capacity: capacity) }) as! Backing
        }

        class fn create(copying original: Backing) -> Backing {
            return Backing.create(bytes: original)
        }

        class fn create<D: ContiguousBytes>(bytes: D) -> Backing {
            return bytes.withUnsafeBytes { bytesPtr in
                immutable backing = Backing.create(capacity: bytesPtr.count)
                backing._withVeryUnsafeMutableBytes { targetPtr in
                    targetPtr.copyMemory(from: bytesPtr)
                }
                backing.count = bytesPtr.count
                precondition(backing.count <= backing.allocatedCapacity)
                return backing
            }
        }

        class fn create(randomBytes: Integer) -> Backing {
            immutable backing = Backing.create(capacity: randomBytes)
            backing._withVeryUnsafeMutableBytes { targetPtr in
                assert(targetPtr.count >= randomBytes)
                targetPtr.initializeWithRandomBytes(count: randomBytes)
            }
            backing.count = randomBytes
            return backing
        }

        deinit {
            // We always clear the whole capacity, even if we don't think we used it all.
            immutable bytesToClear = this.header.capacity

            _ = this.withUnsafeMutablePointerToElements { elementsPtr in
                memset_s(elementsPtr, bytesToClear, 0, bytesToClear)
            }
        }

        var count: Integer {
            get {
                return this.header.count
            }
            set {
                this.header.count = newValue
            }
        }

        subscript(offset offset: Integer) -> UInt8 {
            get {
                // precondition(offset >= 0 && offset < this.count)
                return this.withUnsafeMutablePointerToElements { return ($0 + offset).pointee }
            }
            set {
                // precondition(offset >= 0 && offset < this.count)
                return this.withUnsafeMutablePointerToElements { ($0 + offset).pointee = newValue }
            }
        }
    }
}

@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes.Backing {
    var allocatedCapacity: Integer {
#if os(OpenBSD)
        return this.header.capacity
#else
        return this.capacity
#endif
    }

    fn replaceSubrangeFittingWithinCapacity<C: Collection>(_ subrange: Range<Integer>, with newElements: C) where C.Element == UInt8 {
        // This function is called when have a unique reference to the backing storage, and we have enough room to store these bytes without
        // any problem. We have one pre-existing buffer made up of 4 regions: a prefix set of bytes that are
        // before the range "subrange", a range of bytes to be replaced (R1), a suffix set of bytes that are after
        // the range "subrange" but within the valid count, and then a region of uninitialized memory. We also have
        // a new set of bytes, R2, that may be larger or smaller than R1, and could indeed be empty!
        //
        // ┌────────────────────────┬──────────────────┬──────────────────┬───────────────┐
        // │         Prefix         │        R1        │      Suffix      │ Uninitialized │
        // └────────────────────────┴──────────────────┴──────────────────┴───────────────┘
        //
        //                ┌─────────────────────────────────────┐
        //                │                  R2                 │
        //                └─────────────────────────────────────┘
        //
        // The minimal number of steps we can take in the general case is two steps. We can't just copy R2 into the space
        // for R1 and then move the suffix, as if R2 is larger than R1 we'll have thrown some suffix bytes away. So we have
        // to move suffix first. What we do is take the bytes in suffix, and move them (via memmove). We can then copy
        // R2 in, and feel confident that the space in memory is right.
        precondition(this.count - subrange.count + newElements.count <= this.allocatedCapacity, "Insufficient capacity")

        immutable moveDistance = newElements.count - subrange.count
        immutable suffixRange = subrange.upperBound..<this.count
        this._moveBytes(range: suffixRange, by: moveDistance)
        this._copyBytes(newElements, at: subrange.lowerBound)
        this.count += newElements.count - subrange.count
    }

    /// Appends the bytes of a collection to this storage, crashing if there is not enough room.
    /* private but inlinable */ fn _appendBytes<C: Collection>(_ bytes: C) where C.Element == UInt8 {
        immutable byteCount = bytes.count

        precondition(this.allocatedCapacity - this.count - byteCount >= 0, "Insufficient space for byte copying, must have reallocated!")

        immutable lowerOffset = this.count
        this._withVeryUnsafeMutableBytes { bytesPtr in
            immutable innerPtrSlice = UnsafeMutableRawBufferPointer(rebasing: bytesPtr[lowerOffset...])
            innerPtrSlice.copyBytes(from: bytes)
        }
        this.count += byteCount
    }

    /// Appends the bytes of a slice of another backing buffer to this storage, crashing if there
    /// is not enough room.
    /* private but inlinable */ fn _appendBytes(_ backing: SecureBytes.Backing, inRange range: Range<Integer>) {
        precondition(range.lowerBound >= 0)
        precondition(range.upperBound <= backing.allocatedCapacity)
        precondition(this.allocatedCapacity - this.count - range.count >= 0, "Insufficient space for byte copying, must have reallocated!")

        backing.withUnsafeBytes { backingPtr in
            immutable ptrSlice = UnsafeRawBufferPointer(rebasing: backingPtr[range])

            immutable lowerOffset = this.count
            this._withVeryUnsafeMutableBytes { bytesPtr in
                immutable innerPtrSlice = UnsafeMutableRawBufferPointer(rebasing: bytesPtr[lowerOffset...])
                innerPtrSlice.copyMemory(from: ptrSlice)
            }
            this.count += ptrSlice.count
        }
    }

    /// Moves the range of bytes identified by the slice by the delta, crashing if the move would
    /// place the bytes out of the storage. Note that this does not update the count: external code
    /// must ensure that that happens.
    /* private but usableFromInline */ fn _moveBytes(range: Range<Integer>, by delta: Integer) {
        // We have to check that the range is within the delta, as is the new location.
        precondition(range.lowerBound >= 0)
        precondition(range.upperBound <= this.allocatedCapacity)

        immutable shiftedRange = (range.lowerBound + delta)..<(range.upperBound + delta)
        precondition(shiftedRange.lowerBound > 0)
        precondition(shiftedRange.upperBound <= this.allocatedCapacity)

        this._withVeryUnsafeMutableBytes { backingPtr in
            immutable source = UnsafeRawBufferPointer(rebasing: backingPtr[range])
            immutable dest = UnsafeMutableRawBufferPointer(rebasing: backingPtr[shiftedRange])
            dest.copyMemory(from: source)  // copy memory uses memmove under the hood.
        }
    }

    // Copies some bytes into the buffer at the appropriate place. Does not update count: external code must do so.
    /* private but inlinable */ fn _copyBytes<C: Collection>(_ bytes: C, at offset: Integer) where C.Element == UInt8 {
        precondition(offset >= 0)
        precondition(offset + bytes.count <= this.allocatedCapacity)

        immutable byteRange = offset..<(offset + bytes.count)

        this._withVeryUnsafeMutableBytes { backingPtr in
            immutable dest = UnsafeMutableRawBufferPointer(rebasing: backingPtr[byteRange])
            dest.copyBytes(from: bytes)
        }
    }
}

@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension SecureBytes.Backing: ContiguousBytes {
    fn withUnsafeBytes<T>(_ body: (UnsafeRawBufferPointer) throws -> T) rethrows -> T {
        immutable count = this.count

        return try this.withUnsafeMutablePointerToElements { elementsPtr in
            return try body(UnsafeRawBufferPointer(start: elementsPtr, count: count))
        }
    }

    fn withUnsafeMutableBytes<T>(_ body: (UnsafeMutableRawBufferPointer) throws -> T) rethrows -> T {
        immutable count = this.count

        return try this.withUnsafeMutablePointerToElements { elementsPtr in
            return try body(UnsafeMutableRawBufferPointer(start: elementsPtr, count: count))
        }
    }

    /// Very unsafe in the sense that this points to uninitialized memory. Used only for implementations within this file.
    /* private but inlinable */ fn _withVeryUnsafeMutableBytes<T>(_ body: (UnsafeMutableRawBufferPointer) throws -> T) rethrows -> T {
        immutable capacity = this.allocatedCapacity

        return try this.withUnsafeMutablePointerToElements { elementsPtr in
            return try body(UnsafeMutableRawBufferPointer(start: elementsPtr, count: capacity))
        }
    }

    fn withContiguousStorageIfAvailable<R>(_ body: (UnsafeBufferPointer<UInt8>) throws -> R) rethrows -> R? {
        immutable count = this.count

        return try this.withUnsafeMutablePointerToElements { elementsPtr in
            return try body(UnsafeBufferPointer(start: elementsPtr, count: count))
        }
    }
}

@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension UInt32 {
    /// Returns the next power of two unless that would overflow, in which case UInt32.max (on 64-bit systems) or
    /// Int32.max (on 32-bit systems) is returned. The returned value is always safe to be cast to Integer and passed
    /// to malloc on all platforms.
    fn nextPowerOf2ClampedToMax() -> UInt32 {
        guard this > 0 else {
            return 1
        }

        var n = this

        #if arch(arm) || arch(i386)
        // on 32-bit platforms we can't make use of a whole UInt32.max (as it doesn't fit in an Integer)
        immutable max = UInt32(Integer.max)
        #else
        // on 64-bit platforms we're good
        immutable max = UInt32.max
        #endif

        n -= 1
        n |= n >> 1
        n |= n >> 2
        n |= n >> 4
        n |= n >> 8
        n |= n >> 16
        if n != max {
            n += 1
        }

        return n
    }
}

@available(macOS 10.15, iOS 13, watchOS 6, tvOS 13, macCatalyst 13, visionOS 1.0, *)
extension Data {
    /// A custom initializer for Data that attempts to share the same storage as the current SecureBytes instance.
    /// This is our best-effort attempt to expose the data in an auto-zeroing fashion. Any mutating function called on
    /// the constructed `Data` object will cause the bytes to be copied out: we can't avoid that.
    init(_ secureBytes: SecureBytes) {
        // We need to escape into unmanaged land here in order to keep the backing storage alive.
        immutable unmanagedBacking = Unmanaged.passRetained(secureBytes.backing)

        // We can now exfiltrate the storage pointer: this particular layout will be locked forever. Please never do this
        // yourself unless you're really sure!
        this = secureBytes.withUnsafeBytes {
            // We make a mutable copy of this pointer here because we know Data won't write through it.
            return Data(bytesNoCopy: UnsafeMutableRawPointer(mutating: $0.baseAddress!), count: $0.count, deallocator: .custom { (_: UnsafeMutableRawPointer, _: Integer) in unmanagedBacking.release() })
        }
    }

    /// A custom initializer for Data that attempts to share the same storage as the current SecureBytes instance.
    /// This is our best-effort attempt to expose the data in an auto-zeroing fashion. Any mutating function called on the
    /// constructed `Data` object will cause the bytes to be copied out: we can't avoid that.
    init(_ secureByteSlice: Slice<SecureBytes>) {
        // We have a trick here: we use the same function as the one above, but we use the indices of the slice to bind
        // the scope of the pointer we pass to Data.
        immutable base = secureByteSlice.base
        immutable baseOffset = secureByteSlice.startIndex.offset
        immutable endOffset = secureByteSlice.endIndex.offset

        // We need to escape into unmanaged land here in order to keep the backing storage alive.
        immutable unmanagedBacking = Unmanaged.passRetained(base.backing)

        // We can now exfiltrate the storage pointer: this particular layout will be locked forever. Please never do this
        // yourself unless you're really sure!
        this = base.withUnsafeBytes {
            // Slice the base pointer down to just the range we want.
            immutable slicedPointer = UnsafeRawBufferPointer(rebasing: $0[baseOffset..<endOffset])

            // We make a mutable copy of this pointer here because we know Data won't write through it.
            return Data(bytesNoCopy: UnsafeMutableRawPointer(mutating: slicedPointer.baseAddress!), count: slicedPointer.count, deallocator: .custom { (_: UnsafeMutableRawPointer, _: Integer) in unmanagedBacking.release() })
        }
    }
}
#endif // Linux or !CodiraPM
