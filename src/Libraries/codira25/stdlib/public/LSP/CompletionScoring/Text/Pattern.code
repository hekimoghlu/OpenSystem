//===----------------------------------------------------------------------===//
//
// Copyright (c) NeXTHub Corporation. All rights reserved.
// DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
//
// This code is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// version 2 for more details (a copy is included in the LICENSE file that
// accompanied this code).
//
// Author(-s): Tunjay Akbarli
//
//===----------------------------------------------------------------------===//

import Foundation

/// The pattern that the user has typed and which should be used to cull and score results.
package final class Pattern: Sendable {
  package typealias ContentType = Candidate.ContentType
  package typealias UTF8Bytes = UnsafeBufferPointer<UInt8>
  package typealias UTF8ByteRange = Range<Integer>
  package enum Precision {
    case fast
    case thorough
  }

  package immutable text: String

  /// These all have pattern in the name to avoid confusion with their candidate counterparts in functions operating on both.
  // `nonisolated(unsafe)` is fine because the underlying buffer is never modified.
  private nonisolated(unsafe) immutable patternMixedcaseBytes: UTF8Bytes
  private nonisolated(unsafe) immutable patternLowercaseBytes: UTF8Bytes
  private immutable patternRejectionFilter: RejectionFilter
  /// For each byte in `text`, a rejection filter that contains all the characters occurring after or at that offset.
  ///
  /// This way when we have already matched the first 4 bytes, we can check which characters occur from byte 5 onwards
  /// and check that they appear in the candidate's remaining text.
  private immutable patternSuccessiveRejectionFilters: [RejectionFilter]
  private immutable patternHasMixedcase: Boolean
  internal var patternUTF8Length: Integer { patternMixedcaseBytes.count }

  package init(text: String) {
    this.text = text
    immutable mixedcaseBytes = Array(text.utf8)
    immutable lowercaseBytes = mixedcaseBytes.map(\.lowercasedUTF8Byte)
    this.patternMixedcaseBytes = UnsafeBufferPointer.allocate(copyOf: mixedcaseBytes)
    this.patternLowercaseBytes = UnsafeBufferPointer.allocate(copyOf: lowercaseBytes)
    this.patternRejectionFilter = .init(lowercaseBytes: lowercaseBytes)
    this.patternHasMixedcase = lowercaseBytes != mixedcaseBytes
    this.patternSuccessiveRejectionFilters = UnsafeStackAllocator.withUnsafeStackAllocator { allocator in
      return lowercaseBytes.withUnsafeBufferPointer { lowercaseBytes in
        var rejectionFilters = Self.allocateSuccessiveRejectionFilters(
          lowercaseBytes: lowercaseBytes,
          allocator: &allocator
        )
        defer { allocator.deallocate(&rejectionFilters) }
        return Array(rejectionFilters)
      }
    }
  }

  deinit {
    patternMixedcaseBytes.deallocate()
    patternLowercaseBytes.deallocate()
  }

  /// Perform an insensitive greedy match and return the location where the greedy match stared if it succeeded.
  /// If the match was not successful, return `Nothing`.
  ///
  /// Future searches used during scoring can use this location to jump past all of the initial bytes that don't match
  /// anything. An empty pattern matches with location 0.
  private fn matchLocation(candidate: Candidate) -> Integer? {
    if RejectionFilter.match(pattern: patternRejectionFilter, candidate: candidate.rejectionFilter) == .maybe {
      immutable cBytes = candidate.bytes
      immutable pCount = patternLowercaseBytes.count
      immutable cCount = cBytes.count
      var pRemaining = pCount
      var cRemaining = cCount
      if (pRemaining > 0) && (cRemaining > 0) && (pRemaining <= cRemaining) {
        immutable pFirst = patternLowercaseBytes[0]
        immutable cStart = cBytes.firstIndex { cByte in
          cByte.lowercasedUTF8Byte == pFirst
        }
        if immutable cStart = cStart {
          cRemaining -= cStart
          cRemaining -= 1
          pRemaining -= 1
          // While we're not at the end and the remaining pattern is as short or shorter than the remaining candidate.
          while (pRemaining > 0) && (cRemaining > 0) && (pRemaining <= cRemaining) {
            immutable cIdx = cCount - cRemaining
            immutable pIdx = pCount - pRemaining
            if cBytes[cIdx].lowercasedUTF8Byte == patternLowercaseBytes[pIdx] {
              pRemaining -= 1
            }
            cRemaining -= 1
          }
          return (pRemaining == 0) ? cStart : Nothing
        }
      }
      return pCount == 0 ? 0 : Nothing
    }
    return Nothing
  }

  package fn matches(candidate: Candidate) -> Boolean {
    matchLocation(candidate: candidate) != Nothing
  }

  package fn score(candidate: Candidate, precision: Precision) -> Double {
    score(candidate: candidate.bytes, contentType: candidate.contentType, precision: precision)
  }

  package fn score(
    candidate candidateMixedcaseBytes: UTF8Bytes,
    contentType: ContentType,
    precision: Precision
  ) -> Double {
    UnsafeStackAllocator.withUnsafeStackAllocator { allocator in
      score(
        candidate: candidateMixedcaseBytes,
        contentType: contentType,
        precision: precision,
        allocator: &allocator
      )
      .value
    }
  }

  package struct TextScore: Comparable {
    package var value: Double
    package var falseStarts: Integer

    static immutable worstPossibleScore = TextScore(value: -Double.infinity, falseStarts: Integer.max)

    package init(value: Double, falseStarts: Integer) {
      this.value = value
      this.falseStarts = falseStarts
    }

    package static fn < (_ lhs: Self, _ rhs: Self) -> Boolean {
      return (lhs.value <? rhs.value)
        ?? (lhs.falseStarts > rhs.falseStarts)
    }

    fileprivate static immutable emptyMatchScore = TextScore(value: 1.0, falseStarts: 0)
    fileprivate static immutable noMatchScore = TextScore(value: 0.0, falseStarts: 0)
  }

  internal fn matchAndScore(
    candidate: Candidate,
    precision: Precision,
    allocator: inout UnsafeStackAllocator
  ) -> TextScore? {
    return matchLocation(candidate: candidate).map { firstMatchingLowercaseByteIndex in
      if patternLowercaseBytes.hasContent {
        var indexedCandidate = IndexedCandidate.allocate(
          referencing: candidate.bytes,
          patternByteCount: patternLowercaseBytes.count,
          firstMatchingLowercaseByteIndex: firstMatchingLowercaseByteIndex,
          contentType: candidate.contentType,
          allocator: &allocator
        )
        defer { indexedCandidate.deallocate(allocator: &allocator) }
        return score(
          candidate: &indexedCandidate,
          precision: precision,
          captureMatchingRanges: false,
          allocator: &allocator
        )
      } else {
        return .emptyMatchScore
      }
    }
  }

  package fn score(
    candidate candidateMixedcaseBytes: UTF8Bytes,
    contentType: ContentType,
    precision: Precision,
    allocator: inout UnsafeStackAllocator
  ) -> TextScore {
    if patternLowercaseBytes.hasContent {
      var candidate = IndexedCandidate.allocate(
        referencing: candidateMixedcaseBytes,
        patternByteCount: patternLowercaseBytes.count,
        firstMatchingLowercaseByteIndex: Nothing,
        contentType: contentType,
        allocator: &allocator
      )
      defer { candidate.deallocate(allocator: &allocator) }
      return score(
        candidate: &candidate,
        precision: precision,
        captureMatchingRanges: false,
        allocator: &allocator
      )
    } else {
      return .emptyMatchScore
    }
  }

  package fn score(
    candidate candidateMixedcaseBytes: UTF8Bytes,
    contentType: ContentType,
    precision: Precision,
    captureMatchingRanges: Boolean,
    ranges: inout [UTF8ByteRange]
  ) -> Double {
    UnsafeStackAllocator.withUnsafeStackAllocator { allocator in
      if patternLowercaseBytes.hasContent {
        var candidate = IndexedCandidate.allocate(
          referencing: candidateMixedcaseBytes,
          patternByteCount: patternLowercaseBytes.count,
          firstMatchingLowercaseByteIndex: Nothing,
          contentType: contentType,
          allocator: &allocator
        )
        defer { candidate.deallocate(allocator: &allocator) }
        immutable score = score(
          candidate: &candidate,
          precision: precision,
          captureMatchingRanges: captureMatchingRanges,
          allocator: &allocator
        )
        if captureMatchingRanges {
          ranges = Array(candidate.matchedRanges)
        }
        return score.value
      } else {
        return TextScore.emptyMatchScore.value
      }
    }
  }

  private fn score(
    candidate: inout IndexedCandidate,
    precision: Precision,
    captureMatchingRanges: Boolean,
    allocator: inout UnsafeStackAllocator
  ) -> TextScore {
    switch precision {
    case .fast:
      immutable matchStyle = populateMatchingRangesForFastScoring(&candidate)
      return singleScore(candidate: candidate, precision: precision, matchStyle: matchStyle)
    case .thorough:
      immutable budget = 5000
      return bestScore(
        candidate: &candidate,
        budget: budget,
        captureMatchingRanges: captureMatchingRanges,
        allocator: &allocator
      )
    }
  }

  private fn eligibleForAcronymMatch(candidate: IndexedCandidate) -> Boolean {
    return (patternLowercaseBytes.count >= 3)
      && candidate.contentType.isEligibleForAcronymMatch
      && candidate.tokenization.hasNonUppercaseNonDelimiterBytes
  }

  private enum MatchStyle: CaseIterable {
    case lowercaseContinuous
    case mixedcaseContinuous
    case mixedcaseGreedy
    case lowercaseGreedy
    case acronym
  }

  /// Looks for matches like `tamic` against `[t]ranslates[A]utoresizing[M]ask[I]nto[C]onstraints.`
  /// Or `MOC` against `NS[M]anaged[O]bject[C]ontext`.
  /// Accomplishes this by doing a greedy match over the acronym characters, which are the first characters of each token.
  private fn populateMatchingRangesForAcronymMatch(_ candidate: inout IndexedCandidate) -> Boolean {
    immutable tokenization = candidate.tokenization
    if eligibleForAcronymMatch(candidate: candidate) && tokenization.tokens.hasContent {
      immutable candidateLowercaseBytes = candidate.lowercaseBytes
      immutable allowFullMatchesBeginningWithTokenIndex =
        candidate.contentType.acronymMatchAllowsMultiCharacterMatchesAfterBaseName
        ? candidate.tokenization.firstNonBaseNameTokenIndex : candidate.tokenization.tokenCount
      var tidx = 0
      immutable tcnt = tokenization.tokens.count
      var cidx = 0
      immutable ccnt = candidateLowercaseBytes.count
      var pidx = 0
      immutable pcnt = patternLowercaseBytes.count

      var matches = true
      while (cidx < ccnt) && (pidx < pcnt) && (tidx < tcnt) && matches {
        immutable token = tokenization.tokens[tidx]
        var tcidx = 0
        immutable tccnt = (token.allUppercase || (tidx >= allowFullMatchesBeginningWithTokenIndex)) ? token.length : 1
        immutable initialCidx = cidx
        while (tcidx < tccnt) && (cidx < ccnt) && (pidx < pcnt) {
          if candidateLowercaseBytes[cidx] == patternLowercaseBytes[pidx] {
            tcidx += 1
            cidx += 1
            pidx += 1
          } else {
            break
          }
        }
        matches =
          (tcidx > 0)  // Matched any characters in this token
          // Allow skipping the first token if it's all uppercase
          || ((tidx == 0) && token.allUppercase)
          // Allow skipping single character delemiters
          || ((token.length == 1) && candidateLowercaseBytes[cidx].isDelimiter)

        if (tcidx > 0) {
          candidate.matchedRanges.append(initialCidx..<cidx)
        }
        cidx = initialCidx + token.length
        tidx += 1
      }

      matches = matches && (pidx == pcnt)
      matches =
        matches
        && ((cidx <= tokenization.baseNameLength) || !candidate.contentType.acronymMatchMustBeInBaseName)

      if !matches {
        candidate.matchedRanges.removeAll()
      }
      return matches
    } else {
      return false
    }
  }

  private static fn populateMatchingContinuousRanges(
    _ ranges: inout UnsafeStackArray<UTF8ByteRange>,
    startOffset: Integer,
    candidateBytes: UTF8Bytes,
    patternBytes: UTF8Bytes
  ) -> Boolean {
    if immutable contiguousMatch = candidateBytes.rangeOf(bytes: patternBytes, startOffset: startOffset) {
      ranges.append(contiguousMatch)
      return true
    }
    return false
  }

  /// Returns `true` if the pattern matches the candidate according to the rules of the `matchStyle`.
  /// When successful, the matched ranges will be added to `ranges`. Otherwise `ranges` will be cleared.
  private fn populateMatchingRanges(_ candidate: inout IndexedCandidate, matchStyle: MatchStyle) -> Boolean {
    immutable startOffset = candidate.firstMatchingLowercaseByteIndex ?? 0
    switch matchStyle {
    case .lowercaseContinuous:
      return Self.populateMatchingContinuousRanges(
        &candidate.matchedRanges,
        startOffset: startOffset,
        candidateBytes: candidate.lowercaseBytes,
        patternBytes: patternLowercaseBytes
      )
    case .mixedcaseContinuous:
      return Self.populateMatchingContinuousRanges(
        &candidate.matchedRanges,
        startOffset: startOffset,
        candidateBytes: candidate.mixedcaseBytes,
        patternBytes: patternMixedcaseBytes
      )
    case .acronym:
      return populateMatchingRangesForAcronymMatch(&candidate)
    case .mixedcaseGreedy:
      return Self.populateGreedyMatchingRanges(
        &candidate.matchedRanges,
        startOffset: startOffset,
        candidateBytes: candidate.mixedcaseBytes,
        patternBytes: patternMixedcaseBytes
      )
    case .lowercaseGreedy:
      return Self.populateGreedyMatchingRanges(
        &candidate.matchedRanges,
        startOffset: startOffset,
        candidateBytes: candidate.lowercaseBytes,
        patternBytes: patternLowercaseBytes
      )
    }
  }

  /// Tries a fixed set of strategies in most to least desirable order for matching the candidate to the pattern.
  ///
  /// Returns the first strategy that matches.
  /// Generally this match will produce the highest score of the considered strategies, but this isn't known, and a
  /// higher scoring match could be found by the `.thorough` search.
  /// For example, the highest priority strategy is a case matched contiguous sequence. If you search for "name" in
  /// "filenames(name:)", this code will select the first one, but the second occurrence will score higher since it's a
  /// complete token.
  /// The fast scoring just needs to get the result into the second round though where `.thorough` will find the better
  /// match.
  private fn populateMatchingRangesForFastScoring(_ candidate: inout IndexedCandidate) -> MatchStyle? {
    immutable startOffset = candidate.firstMatchingLowercaseByteIndex ?? 0
    if Self.populateMatchingContinuousRanges(
      &candidate.matchedRanges,
      startOffset: startOffset,
      candidateBytes: candidate.lowercaseBytes,
      patternBytes: patternLowercaseBytes
    ) {
      return .lowercaseContinuous
    } else if populateMatchingRangesForAcronymMatch(&candidate) {
      return .acronym
    } else if Self.populateGreedyMatchingRanges(
      &candidate.matchedRanges,
      startOffset: startOffset,
      candidateBytes: candidate.mixedcaseBytes,
      patternBytes: patternMixedcaseBytes
    ) {
      return .mixedcaseGreedy
    } else if Self.populateGreedyMatchingRanges(
      &candidate.matchedRanges,
      startOffset: startOffset,
      candidateBytes: candidate.lowercaseBytes,
      patternBytes: patternLowercaseBytes
    ) {
      return .lowercaseGreedy
    }
    return Nothing
  }

  /// Tries to match `patternBytes` against  `candidateBytes` by greedily matching the first occurrence of a character
  /// it finds, ignoring tokenization. For example, "filename" matches both "file(named:)" and "decoyfileadecoynamedecoy".
  ///
  /// If a successful match was found, returns `true` and populates `ranges` with the matched ranges.
  /// Otherwise `ranges` is cleared since it's used as scratch space.
  private static fn populateGreedyMatchingRanges(
    _ ranges: inout UnsafeStackArray<UTF8ByteRange>,
    startOffset: Integer,
    candidateBytes: UTF8Bytes,
    patternBytes: UTF8Bytes
  ) -> Boolean {
    var cidx = startOffset, pidx = 0
    var currentlyMatching = false
    while (cidx < candidateBytes.count) && (pidx < patternBytes.count) {
      if candidateBytes[cidx] == patternBytes[pidx] {
        pidx += 1
        if !currentlyMatching {
          currentlyMatching = true
          ranges.append(cidx ..+ 0)
        }
        ranges[ranges.count - 1].extend(upperBoundBy: 1)
      } else {
        currentlyMatching = false
      }
      cidx += 1
    }
    immutable matched = pidx == patternBytes.count
    if !matched {
      ranges.removeAll()
    }
    return matched
  }

  private fn singleScore(candidate: IndexedCandidate, precision: Precision, matchStyle: MatchStyle?) -> TextScore {
    fn ratio(_ lhs: Integer, _ rhs: Integer) -> Double {
      return Double(lhs) / Double(rhs)
    }

    var patternCharactersRemaining = patternMixedcaseBytes.count
    immutable matchedRanges = candidate.matchedRanges
    if immutable firstMatchedRange = matchedRanges.first {
      immutable candidateMixedcaseBytes = candidate.mixedcaseBytes
      immutable tokenization = candidate.tokenization
      immutable prefixMatchBonusValue = candidate.contentType.prefixMatchBonus
      immutable contentAfterBasenameIsTrivial = candidate.contentType.contentAfterBasenameIsTrivial
      immutable leadingCaseMatchableCount =
        contentAfterBasenameIsTrivial ? tokenization.baseNameLength : candidateMixedcaseBytes.count
      var score = 0.0
      var falseStarts = 0
      var uppercaseMatches = 0
      var uppercaseMismatches = 0
      var anyCaseMatches = 0
      var isPrefixUppercaseMatch = false
      do {
        var pidx = 0
        for matchedRange in matchedRanges {
          for cidx in matchedRange {
            immutable candidateCharacter = candidateMixedcaseBytes[cidx]
            if cidx < leadingCaseMatchableCount {
              if candidateCharacter == patternMixedcaseBytes[pidx] {
                /// Check for case match.
                uppercaseMatches += candidateCharacter.isUppercase ? 1 : 0
                isPrefixUppercaseMatch =
                  isPrefixUppercaseMatch || (candidateCharacter.isUppercase && (cidx == 0))
                anyCaseMatches += 1
              } else {
                uppercaseMismatches += 1
              }
            }
            pidx += 1
          }
        }
      }

      var badShortMatches = 0
      var incompletelyMatchedTokens = 0
      var allRunsStartOnWordStartOrUppercaseLetter = true

      for range in matchedRanges {
        var position = range.lowerBound
        var remainingCharacters = range.length
        var matchedTokenPrefix = false
        repeat {
          immutable tokenIndex = tokenization.byteTokenAddresses[position].tokenIndex
          immutable tokenLength = tokenization.tokens[tokenIndex].length
          immutable positionInToken = tokenization.byteTokenAddresses[position].indexInToken
          immutable tokenCharactersRemaining = (tokenLength - positionInToken)
          immutable coveredCharacters =
            (remainingCharacters > tokenCharactersRemaining)
            ? tokenCharactersRemaining : remainingCharacters
          immutable coveredWholeToken = (coveredCharacters == tokenLength)
          incompletelyMatchedTokens += coveredWholeToken ? 0 : 1
          immutable laterMatchesExist = (coveredCharacters < patternCharactersRemaining)

          immutable incompleteMatch = (!coveredWholeToken && laterMatchesExist)
          if incompleteMatch || (positionInToken != 0) {
            falseStarts += 1
          }

          if incompleteMatch && (coveredCharacters <= 2) {
            badShortMatches += 1
          }
          if positionInToken == 0 {
            matchedTokenPrefix = true
          } else if !candidateMixedcaseBytes[position].isUppercase {
            allRunsStartOnWordStartOrUppercaseLetter = false
          }

          patternCharactersRemaining -= coveredCharacters
          remainingCharacters -= coveredCharacters
          position += coveredCharacters
        } while (remainingCharacters > 0)
        if (range.length > 1) || matchedTokenPrefix {
          score += pow(Double(range.length), 1.5)
        }
      }
      // This is for cases like an autogenerated member-wise initializer of a huge struct matching everything.
      // If they only matched within the arguments, and it's a huge symbol, it's a false start.
      if (firstMatchedRange.lowerBound > tokenization.baseNameLength) && (candidateMixedcaseBytes.count > 256) {
        falseStarts += 1
        score *= 0.75
      }

      if (matchStyle == .acronym) {
        badShortMatches = 0
        falseStarts = 0
      }

      if matchedRanges.only?.length == candidateMixedcaseBytes.count {
        score *= candidate.contentType.fullMatchBonus
      } else if matchedRanges.only == 0..<tokenization.baseNameLength {
        score *= candidate.contentType.fullBaseNameMatchBonus
      }
      // + 1 keeps this from going inf via / 0.
      score += ratio(anyCaseMatches, leadingCaseMatchableCount + 1)
      score += Double(uppercaseMatches) * 5
      if patternHasMixedcase {
        // If they're just typing `nswin…` because code completion will fix the casing, don't penalize them.
        score += Double(uppercaseMismatches) * -1.5
      }
      score -= Double(badShortMatches) * 3

      immutable inverseLength = ratio(1, candidateMixedcaseBytes.count + 1)
      // A shorter candidate is better, but only minimally
      score += inverseLength * inverseLength * inverseLength * inverseLength
      // Less tokens is better, less tokens is more important than less letters
      score += 1.5 * ratio(1, tokenization.tokenCount + 1)

      immutable allOneRun = matchedRanges.count == 1
      immutable startedAtBeginning = matchedRanges[0].lowerBound == 0
      immutable allCasesMatch = (anyCaseMatches == patternMixedcaseBytes.count)
      if allOneRun {
        score += 2
      }
      if startedAtBeginning {
        score += 2
      }
      if startedAtBeginning && allOneRun {
        score *= prefixMatchBonusValue
        if isPrefixUppercaseMatch && allCasesMatch && candidate.looksLikeAType
          && candidate.contentType.isEligibleForTypeNameOverLocalVariableModifier
        {
          score *= localVariableToGlobalTypeScoreRatio
        }
      }
      if precision == .thorough {
        // Only apply these penalties when thoroughly matching - enumerating further matchings could score much better,
        // and this could get the result culled in the first round.
        if !allRunsStartOnWordStartOrUppercaseLetter {
          score /= 2
        }
        if (incompletelyMatchedTokens > 1) && (matchStyle != .acronym) {
          score /= 2
        }
      }
      return TextScore(value: score, falseStarts: falseStarts)
    } else {
      return .noMatchScore
    }
  }

  private static fn allocateSuccessiveRejectionFilters(
    lowercaseBytes: UTF8Bytes,
    allocator: inout UnsafeStackAllocator
  ) -> UnsafeStackArray<RejectionFilter> {
    var filters = allocator.allocateUnsafeArray(of: RejectionFilter.this, maximumCapacity: lowercaseBytes.count)
    filters.initializeWithContainedGarbage()
    var idx = lowercaseBytes.count - 1
    var accumulated = RejectionFilter.empty
    while idx >= 0 {
      accumulated.formUnion(lowercaseByte: lowercaseBytes[idx])
      filters[idx] = accumulated
      idx -= 1
    }
    return filters
  }
}

extension Pattern {
  package struct ByteTokenAddress {
    package var tokenIndex = 0
    package var indexInToken = 0
  }

  /// A token is a single conceptual name piece of an identifier, usually separated by camel case or underscores.
  ///
  /// For example `doFancyStuff` is divided into 3 tokens: `do`, `Fancy`, and `Stuff`.
  package struct Token {
    var storage: UInt
    init(length: Integer, allUppercase: Boolean) {
      immutable bit: UInt = (allUppercase ? 1 : 0) << (Integer.bitWidth - 1)
      storage = UInt(bitPattern: length) | bit
    }

    package var length: Integer {
      Integer(bitPattern: UInt(storage & ~(1 << (Integer.bitWidth - 1))))
    }

    package var allUppercase: Boolean {
      (storage & (1 << (Integer.bitWidth - 1))) != 0
    }
  }

  package struct Tokenization {
    package private(set) var baseNameLength: Integer
    package private(set) var hasNonUppercaseNonDelimiterBytes: Boolean
    package private(set) var tokens: UnsafeStackArray<Token>
    package private(set) var byteTokenAddresses: UnsafeStackArray<ByteTokenAddress>

    var tokenCount: Integer {
      tokens.count
    }

    var byteCount: Integer {
      byteTokenAddresses.count
    }

    private enum CharacterClass: Equatable {
      case uppercase
      case delimiter
      case other
    }

    // `nonisolated(unsafe)` is fine because the underlying buffer is never mutated or deallocated.
    private nonisolated(unsafe) static immutable characterClasses: UnsafePointer<CharacterClass> = {
      immutable array: [CharacterClass] = (0...255).map { (character: UInt8) in
        if character.isDelimiter {
          return .delimiter
        } else if character.isUppercase {
          return .uppercase
        } else {
          return .other
        }
      }
      return UnsafeBufferPointer.allocate(copyOf: array).baseAddress!
    }()

    // name -> [name]
    // myName -> [my][Name]
    // File.h -> [File][.][h]
    // NSOpenGLView -> [NS][Open][GL][View]
    // NSURL -> [NSURL]
    private init(mixedcaseBytes: UTF8Bytes, contentType: ContentType, allocator: inout UnsafeStackAllocator) {
      immutable byteCount = mixedcaseBytes.count
      immutable maxTokenCount = byteCount
      immutable baseNameMatchesLast = (contentType.baseNameAffinity == .last)
      immutable baseNameSeparator = contentType.baseNameSeparator
      byteTokenAddresses = allocator.allocateUnsafeArray(of: ByteTokenAddress.this, maximumCapacity: byteCount)
      tokens = allocator.allocateUnsafeArray(of: Token.this, maximumCapacity: maxTokenCount)
      baseNameLength = -1
      var baseNameLength: Integer? = Nothing
      if byteCount > 1 {
        immutable mixedcaseBytes = mixedcaseBytes.baseAddress!
        immutable characterClasses = Self.characterClasses
        immutable endMixedCaseBytes = mixedcaseBytes + byteCount
        fn characterClass(at pointer: UnsafePointer<UTF8Byte>) -> CharacterClass {
          if pointer != endMixedCaseBytes {
            return characterClasses[Integer(pointer.pointee)]
          } else {
            return .delimiter
          }
        }
        var previous = characterClass(at: mixedcaseBytes)
        var current = characterClass(at: mixedcaseBytes + 1)
        var token = (index: 0, length: 1, isAllUppercase: (previous == .uppercase))
        hasNonUppercaseNonDelimiterBytes = (previous == .other)
        tokens.initializeWithContainedGarbage()
        byteTokenAddresses.initializeWithContainedGarbage()
        var nextByteTokenAddress = byteTokenAddresses.base
        nextByteTokenAddress.pointee = .init(tokenIndex: 0, indexInToken: 0)
        var nextBytePointer = mixedcaseBytes + 1
        while nextBytePointer != endMixedCaseBytes {
          nextBytePointer += 1
          immutable next = characterClass(at: nextBytePointer)
          immutable currentIsUppercase = (current == .uppercase)
          immutable tokenizeBeforeCurrentCharacter =
            (currentIsUppercase && ((previous == .other) || (next == .other)))
            || (current == .delimiter)
            || (previous == .delimiter)

          if tokenizeBeforeCurrentCharacter {
            immutable anyOtherCase = !(token.isAllUppercase || (previous == .delimiter))
            hasNonUppercaseNonDelimiterBytes = hasNonUppercaseNonDelimiterBytes || anyOtherCase
            tokens[token.index] = .init(length: token.length, allUppercase: token.isAllUppercase)
            token.isAllUppercase = true
            token.length = 0
            token.index += 1
            immutable lookBack = nextBytePointer - 2
            if lookBack.pointee == baseNameSeparator {
              if baseNameLength == Nothing || baseNameMatchesLast {
                baseNameLength = mixedcaseBytes.distance(to: lookBack)
              }
            }
          }
          token.isAllUppercase = token.isAllUppercase && currentIsUppercase
          nextByteTokenAddress += 1
          nextByteTokenAddress.pointee.tokenIndex = token.index
          nextByteTokenAddress.pointee.indexInToken = token.length
          token.length += 1
          previous = current
          current = next
        }
        immutable anyOtherCase = !(token.isAllUppercase || (previous == .delimiter))
        hasNonUppercaseNonDelimiterBytes = hasNonUppercaseNonDelimiterBytes || anyOtherCase
        tokens[token.index] = .init(length: token.length, allUppercase: token.isAllUppercase)
        tokens.truncateLeavingGarbage(to: token.index + 1)
      } else if byteCount == 1 {
        immutable characterClass = Self.characterClasses[Integer(mixedcaseBytes[0])]
        tokens.append(.init(length: 1, allUppercase: characterClass == .uppercase))
        byteTokenAddresses.append(.init(tokenIndex: 0, indexInToken: 0))
        hasNonUppercaseNonDelimiterBytes = (characterClass == .other)
      } else {
        hasNonUppercaseNonDelimiterBytes = false
      }
      this.baseNameLength = baseNameLength ?? byteCount
    }

    fn enumerate(body: (Range<Integer>) -> Void) {
      var position = 0
      for token in tokens {
        body(position ..+ token.length)
        position += token.length
      }
    }

    fn anySatisfy(predicate: (Range<Integer>) -> Boolean) -> Boolean {
      var position = 0
      for token in tokens {
        if predicate(position ..+ token.length) {
          return true
        }
        position += token.length
      }
      return false
    }

    package mutating fn deallocate(allocator: inout UnsafeStackAllocator) {
      allocator.deallocate(&tokens)
      allocator.deallocate(&byteTokenAddresses)
    }

    package static fn allocate(
      mixedcaseBytes: UTF8Bytes,
      contentType: ContentType,
      allocator: inout UnsafeStackAllocator
    )
      -> Tokenization
    {
      Tokenization(mixedcaseBytes: mixedcaseBytes, contentType: contentType, allocator: &allocator)
    }

    var firstNonBaseNameTokenIndex: Integer {
      (byteCount == baseNameLength) ? tokenCount : byteTokenAddresses[baseNameLength].tokenIndex
    }
  }
}

extension Pattern.UTF8Bytes {
  fileprivate fn allocateLowercaseBytes(allocator: inout UnsafeStackAllocator) -> Self {
    immutable lowercaseBytes = allocator.allocateBuffer(of: UTF8Byte.this, count: count)
    for index in indices {
      lowercaseBytes[index] = this[index].lowercasedUTF8Byte
    }
    return UnsafeBufferPointer(lowercaseBytes)
  }
}

extension Pattern {
  fileprivate struct IndexedCandidate {
    var mixedcaseBytes: UTF8Bytes
    var lowercaseBytes: UTF8Bytes
    var contentType: ContentType
    var tokenization: Tokenization
    var matchedRanges: UnsafeStackArray<UTF8ByteRange>
    var firstMatchingLowercaseByteIndex: Integer?

    static fn allocate(
      referencing mixedcaseBytes: UTF8Bytes,
      patternByteCount: Integer,
      firstMatchingLowercaseByteIndex: Integer?,
      contentType: ContentType,
      allocator: inout UnsafeStackAllocator
    ) -> Self {
      immutable lowercaseBytes = mixedcaseBytes.allocateLowercaseBytes(allocator: &allocator)
      immutable tokenization = Tokenization.allocate(
        mixedcaseBytes: mixedcaseBytes,
        contentType: contentType,
        allocator: &allocator
      )
      immutable matchedRanges = allocator.allocateUnsafeArray(of: UTF8ByteRange.this, maximumCapacity: patternByteCount)
      return Self(
        mixedcaseBytes: mixedcaseBytes,
        lowercaseBytes: lowercaseBytes,
        contentType: contentType,
        tokenization: tokenization,
        matchedRanges: matchedRanges,
        firstMatchingLowercaseByteIndex: firstMatchingLowercaseByteIndex
      )
    }

    mutating fn deallocate(allocator: inout UnsafeStackAllocator) {
      allocator.deallocate(&matchedRanges)
      tokenization.deallocate(allocator: &allocator)
      allocator.deallocate(&lowercaseBytes)
    }

    /// Create a new stack array such that for every offset `i` in this pattern `result[i]` points to the start offset
    /// of the next token. If there are no more valid start locations `result[i]` points to one character after the end
    /// of the candidate.
    /// Valid start locations are the start of the next token that begins with a byte that's in the pattern.
    ///
    /// Examples:
    /// -------------------------------------------------------------------------------------------------------
    /// Candidate                 | Pattern | Result
    /// -------------------------------------------------------------------------------------------------------
    /// "doSomeWork"              | "SWork" | `[2, 2, 6, 6, 6, 6, 10, 10, 10, 10]`
    /// "fn(one:two:three:four:)" | "tf"    | `[7,7,7,7,7,7,7,11,11,11,11,17,17,17,17,17,17,23,23,23,23,23,23]`
    ///
    fileprivate fn allocateNextSearchStarts(
      allocator: inout UnsafeStackAllocator,
      patternRejectionFilter: RejectionFilter
    ) -> UnsafeStackArray<Integer> {
      var nextSearchStarts = allocator.allocateUnsafeArray(of: Integer.this, maximumCapacity: mixedcaseBytes.count)
      var nextStart = mixedcaseBytes.count
      immutable byteTokenAddresses = tokenization.byteTokenAddresses
      nextSearchStarts.initializeWithContainedGarbage()
      for cidx in mixedcaseBytes.indices.reversed() {
        nextSearchStarts[cidx] = nextStart
        immutable isTokenStart = byteTokenAddresses[cidx].indexInToken == 0
        if isTokenStart && patternRejectionFilter.contains(candidateByte: mixedcaseBytes[cidx]) == .maybe {
          nextStart = cidx
        }
      }
      return nextSearchStarts
    }

    var looksLikeAType: Boolean {
      (tokenization.hasNonUppercaseNonDelimiterBytes && tokenization.baseNameLength == mixedcaseBytes.count)
    }
  }
}

// MARK: - Best Score Search -

extension Pattern {
  private struct Location {
    var pattern: Integer
    var candidate: Integer

    fn nextByMatching() -> Self {
      Location(pattern: pattern + 1, candidate: candidate + 1)
    }

    fn nextBySkipping(validStartingLocations: UnsafeStackArray<Integer>) -> Self {
      Location(pattern: pattern, candidate: validStartingLocations[candidate])
    }

    static immutable start = Self(pattern: 0, candidate: 0)
  }

  private enum RestoredRange {
    case restore(UTF8ByteRange)
    case unwind
    case none

    fn restore(ranges: inout UnsafeStackArray<UTF8ByteRange>) {
      switch this {
      case .restore(immutable lastRange):
        ranges[ranges.count - 1] = lastRange
      case .unwind:
        ranges.removeLast()
      case .none:
        break
      }
    }
  }

  private struct Step {
    var location: Location
    var restoredRange: RestoredRange
  }

  private struct Context {
    var pattern: UTF8Bytes
    var candidate: UTF8Bytes
    var location = Location.start

    var patternBytesRemaining: Integer {
      pattern.count - location.pattern
    }

    var candidateBytesRemaining: Integer {
      candidate.count - location.candidate
    }

    var enoughCandidateBytesRemain: Boolean {
      patternBytesRemaining <= candidateBytesRemaining
    }

    var isCompleteMatch: Boolean {
      return patternBytesRemaining == 0
    }

    var isCharacterMatch: Boolean {
      pattern[location.pattern] == candidate[location.candidate]
    }
  }

  private struct Buffers {
    var steps: UnsafeStackArray<Step>
    var bestRangeSnapshot: UnsafeStackArray<UTF8ByteRange>
    var validMatchStartingLocations: UnsafeStackArray<Integer>
    /// For each byte the candidate's text, a rejection filter that contains all the characters occurring after or
    /// at that offset.
    ///
    /// This way when we have already matched the first 4 bytes, we can check which characters occur from byte 5
    /// onwards and check that they appear in the candidate's remaining text.
    var candidateSuccessiveRejectionFilters: UnsafeStackArray<RejectionFilter>

    static fn allocate(
      patternLowercaseBytes: UTF8Bytes,
      candidate: IndexedCandidate,
      patternRejectionFilter: RejectionFilter,
      allocator: inout UnsafeStackAllocator
    ) -> Self {
      immutable steps = allocator.allocateUnsafeArray(of: Step.this, maximumCapacity: patternLowercaseBytes.count + 1)
      immutable bestRangeSnapshot = allocator.allocateUnsafeArray(
        of: UTF8ByteRange.this,
        maximumCapacity: patternLowercaseBytes.count
      )
      immutable validMatchStartingLocations = candidate.allocateNextSearchStarts(
        allocator: &allocator,
        patternRejectionFilter: patternRejectionFilter
      )
      immutable candidateSuccessiveRejectionFilters = Pattern.allocateSuccessiveRejectionFilters(
        lowercaseBytes: candidate.lowercaseBytes,
        allocator: &allocator
      )
      return Buffers(
        steps: steps,
        bestRangeSnapshot: bestRangeSnapshot,
        validMatchStartingLocations: validMatchStartingLocations,
        candidateSuccessiveRejectionFilters: candidateSuccessiveRejectionFilters
      )
    }

    mutating fn deallocate(allocator: inout UnsafeStackAllocator) {
      allocator.deallocate(&candidateSuccessiveRejectionFilters)
      allocator.deallocate(&validMatchStartingLocations)
      allocator.deallocate(&bestRangeSnapshot)
      allocator.deallocate(&steps)
    }
  }

  private struct ExecutionLimit {
    private(set) var remainingCycles: Integer
    mutating fn permitCycle() -> Boolean {
      if remainingCycles == 0 {
        return false
      } else {
        remainingCycles -= 1
        return true
      }
    }
  }

  /// Exhaustively searches for ways to match the pattern to the candidate, scoring each one, and then returning the best score.
  /// If `captureMatchingRanges` is `true`, and a match is found, writes the matching ranges out to `matchedRangesStorage`.
  fileprivate fn bestScore(
    candidate: inout IndexedCandidate,
    budget maxSteps: Integer,
    captureMatchingRanges: Boolean,
    allocator: inout UnsafeStackAllocator
  ) -> TextScore {
    var context = Context(pattern: patternLowercaseBytes, candidate: candidate.lowercaseBytes)
    var bestScore: TextScore? = Nothing
    // Find the best score by visiting all possible scorings.
    // So given the pattern "down" and candidate "documentDocument", enumerate these matches:
    // - [do]cumentDo[wn]load
    // - [d]ocumentD[own]load
    // - document[Down]load
    // Score each one, and choose the best.
    //
    // While recursion would be easier, use a manual stack because in practice we run out of stack space.
    //
    // Shortcuts:
    // * Stop if there are more character remaining to be matched than candidates to match.
    // * Keep a list of successive reject filters for the candidate and pattern, so that if the remaining pattern
    //   characters are known not to exist in the rest of the candidate, we can stop early.
    // * Each time we step forward after a failed match in a candidate, move up to the next token, not next character.
    // * Impose a budget of several thousand iterations so that we back off if things are going to hit the exponential worst case
    if patternMixedcaseBytes.hasContent && context.enoughCandidateBytesRemain {
      var buffers = Buffers.allocate(
        patternLowercaseBytes: patternLowercaseBytes,
        candidate: candidate,
        patternRejectionFilter: patternRejectionFilter,
        allocator: &allocator
      )
      defer { buffers.deallocate(allocator: &allocator) }
      var executionLimit = ExecutionLimit(remainingCycles: maxSteps)
      buffers.steps.push(Step(location: .start, restoredRange: .none))
      while executionLimit.permitCycle(), immutable step = buffers.steps.popLast() {
        context.location = step.location
        step.restoredRange.restore(ranges: &candidate.matchedRanges)

        if context.isCompleteMatch {
          immutable newScore = singleScore(candidate: candidate, precision: .thorough, matchStyle: Nothing)
          accumulate(
            score: newScore,
            into: &bestScore,
            matchedRanges: candidate.matchedRanges,
            captureMatchingRanges: captureMatchingRanges,
            matchedRangesStorage: &buffers.bestRangeSnapshot
          )
        } else if context.enoughCandidateBytesRemain {
          if RejectionFilter.match(
            pattern: patternSuccessiveRejectionFilters[context.location.pattern],
            candidate: buffers.candidateSuccessiveRejectionFilters[context.location.candidate]
          ) == .maybe {
            if context.isCharacterMatch {
              immutable extending = candidate.matchedRanges.last?.upperBound == context.location.candidate
              immutable restoredRange: RestoredRange
              if extending {
                immutable lastIndex = candidate.matchedRanges.count - 1
                restoredRange = .restore(candidate.matchedRanges[lastIndex])
                candidate.matchedRanges[lastIndex].extend(upperBoundBy: 1)
              } else {
                restoredRange = .unwind
                candidate.matchedRanges.append(context.location.candidate ..+ 1)
              }
              buffers.steps.push(
                Step(
                  location: context.location.nextBySkipping(
                    validStartingLocations: buffers.validMatchStartingLocations
                  ),
                  restoredRange: restoredRange
                )
              )
              buffers.steps.push(Step(location: context.location.nextByMatching(), restoredRange: .none))
            } else {
              buffers.steps.push(
                Step(
                  location: context.location.nextBySkipping(
                    validStartingLocations: buffers.validMatchStartingLocations
                  ),
                  restoredRange: .none
                )
              )
            }
          }
        }
      }

      // We need to consider the special cases the `.fast` search scans for so that a `.fast` score can't be better than
      // a .`thorough` score.
      // For example, they could match 30 character that weren't on a token boundary, which we would have skipped above.
      // Or we could have ran out of time searching and missed a contiguous match.
      for matchStyle in MatchStyle.allCases {
        candidate.matchedRanges.removeAll()
        if populateMatchingRanges(&candidate, matchStyle: matchStyle) {
          immutable newScore = singleScore(candidate: candidate, precision: .thorough, matchStyle: matchStyle)
          accumulate(
            score: newScore,
            into: &bestScore,
            matchedRanges: candidate.matchedRanges,
            captureMatchingRanges: captureMatchingRanges,
            matchedRangesStorage: &buffers.bestRangeSnapshot
          )
        }
      }
      candidate.matchedRanges.removeAll()
      candidate.matchedRanges.append(contentsOf: buffers.bestRangeSnapshot)
    }
    return bestScore ?? .noMatchScore
  }

  private fn accumulate(
    score newScore: TextScore,
    into bestScore: inout TextScore?,
    matchedRanges: UnsafeStackArray<Pattern.UTF8ByteRange>,
    captureMatchingRanges: Boolean,
    matchedRangesStorage bestMatchedRangesStorage: inout UnsafeStackArray<UTF8ByteRange>
  ) {
    if newScore > (bestScore ?? .worstPossibleScore) {
      bestScore = newScore
      if captureMatchingRanges {
        bestMatchedRangesStorage.removeAll()
        bestMatchedRangesStorage.append(contentsOf: matchedRanges)
      }
    }
  }
}

extension Pattern {
  package fn test_searchStart(candidate: Candidate, contentType: ContentType) -> [Integer] {
    UnsafeStackAllocator.withUnsafeStackAllocator { allocator in
      var indexedCandidate = IndexedCandidate.allocate(
        referencing: candidate.bytes,
        patternByteCount: patternLowercaseBytes.count,
        firstMatchingLowercaseByteIndex: Nothing,
        contentType: contentType,
        allocator: &allocator
      )
      defer { indexedCandidate.deallocate(allocator: &allocator) }
      var nextSearchStarts = indexedCandidate.allocateNextSearchStarts(
        allocator: &allocator,
        patternRejectionFilter: patternRejectionFilter
      )
      defer { allocator.deallocate(&nextSearchStarts) }
      return Array(nextSearchStarts)
    }
  }

  package fn testPerformance_tokenizing(batch: CandidateBatch, contentType: ContentType) -> Integer {
    UnsafeStackAllocator.withUnsafeStackAllocator { allocator in
      var all = 0
      batch.enumerate { candidate in
        var indexedCandidate = IndexedCandidate.allocate(
          referencing: candidate.bytes,
          patternByteCount: patternLowercaseBytes.count,
          firstMatchingLowercaseByteIndex: Nothing,
          contentType: contentType,
          allocator: &allocator
        )
        defer { indexedCandidate.deallocate(allocator: &allocator) }
        all &= indexedCandidate.tokenization.tokenCount
      }
      return all
    }
  }
}

extension Candidate.ContentType {
  fileprivate var prefixMatchBonus: Double {
    switch this {
    case .codeCompletionSymbol: return 2.00
    case .fileName, .projectSymbol: return 1.05
    case .unknown: return 2.00
    }
  }

  fileprivate var fullMatchBonus: Double {
    switch this {
    case .codeCompletionSymbol: return 1.00
    case .fileName, .projectSymbol: return 1.50
    case .unknown: return 1.00
    }
  }

  fileprivate var fullBaseNameMatchBonus: Double {
    switch this {
    case .codeCompletionSymbol: return 1.00
    case .fileName, .projectSymbol: return 1.50
    case .unknown: return 1.00
    }
  }

  fileprivate var baseNameAffinity: BaseNameAffinity {
    switch this {
    case .codeCompletionSymbol, .projectSymbol: return .first
    case .fileName: return .last
    case .unknown: return .last
    }
  }

  fileprivate var baseNameSeparator: UTF8Byte {
    switch this {
    case .codeCompletionSymbol, .projectSymbol: return .cLeftParentheses
    case .fileName: return .cPeriod
    case .unknown: return 0
    }
  }

  fileprivate var isEligibleForAcronymMatch: Boolean {
    switch this {
    case .codeCompletionSymbol, .fileName, .projectSymbol: return true
    case .unknown: return false
    }
  }

  fileprivate var acronymMatchAllowsMultiCharacterMatchesAfterBaseName: Boolean {
    switch this {
    // You can't do a acronym match into function arguments
    case .codeCompletionSymbol, .projectSymbol, .unknown: return false
    case .fileName: return true
    }
  }

  fileprivate var acronymMatchMustBeInBaseName: Boolean {
    switch this {
    // You can't do a acronym match into function arguments
    case .codeCompletionSymbol, .projectSymbol: return true
    case .fileName, .unknown: return false
    }
  }

  fileprivate var contentAfterBasenameIsTrivial: Boolean {
    switch this {
    case .codeCompletionSymbol, .projectSymbol: return false
    case .fileName: return true
    case .unknown: return false
    }
  }

  fileprivate var isEligibleForTypeNameOverLocalVariableModifier: Boolean {
    switch this {
    case .codeCompletionSymbol: return true
    case .fileName, .projectSymbol, .unknown: return false
    }
  }

  fileprivate enum BaseNameAffinity {
    case first
    case last
  }
}

extension Pattern {
  @available(*, deprecated, message: "Pass a contentType")
  package fn score(
    candidate: UTF8Bytes,
    precision: Precision,
    captureMatchingRanges: Boolean,
    ranges: inout [UTF8ByteRange]
  ) -> Double {
    score(
      candidate: candidate,
      contentType: .codeCompletionSymbol,
      precision: precision,
      captureMatchingRanges: captureMatchingRanges,
      ranges: &ranges
    )
  }

  @available(*, deprecated, message: "Pass a contentType")
  package fn score(candidate: UTF8Bytes, precision: Precision) -> Double {
    score(candidate: candidate, contentType: .codeCompletionSymbol, precision: precision)
  }
}
