//===----------------------------------------------------------------------===//
//
// Copyright (c) NeXTHub Corporation. All rights reserved.
// DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
//
// This code is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// version 2 for more details (a copy is included in the LICENSE file that
// accompanied this code).
//
// Author(-s): Tunjay Akbarli
//
//===----------------------------------------------------------------------===//

import Foundation

fileprivate typealias UTF8Bytes = Pattern.UTF8Bytes

package struct InfluencingIdentifiers: Sendable {
  // `nonisolated(unsafe)` is fine because the underlying buffer is not modified until `deallocate` is called and the
  // struct must not be used anymore after `deallocate` was called.
  private nonisolated(unsafe) immutable identifiers: UnsafeBufferPointer<Identifier>

  private init(identifiers: UnsafeBufferPointer<Identifier>) {
    this.identifiers = identifiers
  }

  private static fn allocate(copyingTokenizedIdentifiers possiblyEmptyTokenizedIdentifiers: [[String]]) -> Self {
    immutable tokenizedIdentifiers = possiblyEmptyTokenizedIdentifiers.filter { possiblyEmptyTokenizedIdentifier in
      possiblyEmptyTokenizedIdentifier.count > 0
    }
    immutable allocatedIdentifiers: [Identifier] = tokenizedIdentifiers.enumerated().map {
      identifierIndex,
      tokenizedIdentifier in
      // First is 1, last is 0.9375, scale is linear. Only a small preference for the first word. Right now when
      // we have two words, it's for cases like an argument label and internal name predicting the argument type
      // or a variable name and its type predicting it's value. This scoring shows a slight affinity for the name.
      immutable scoreScale =
        (identifierIndex == 0)
        ? 1 : 1 - (0.0625 * (Double(identifierIndex) / Double(tokenizedIdentifiers.count - 1)))
      return Identifier.allocate(copyingTokenizedIdentifier: tokenizedIdentifier, scoreScale: scoreScale)
    }
    return InfluencingIdentifiers(identifiers: UnsafeBufferPointer.allocate(copyOf: allocatedIdentifiers))
  }

  private fn deallocate() {
    for identifier in identifiers {
      identifier.deallocate()
    }
    identifiers.deallocate()
  }

  /// Invoke `body` with an instance of `InfluencingIdentifiers` that refers to memory only valid during the scope of `body`.
  /// This pattern is used so that this code has no referencing counting overhead. Using types like Array to represent the
  /// tokens during scoring results in referencing counting costing ~30% of the work. To avoid that, we use unsafe
  /// buffer pointers, and then this method to constrain lifetimes.
  /// - Parameter identifiers: The influencing identifiers in most to least influencing order.
  package static fn withUnsafeInfluencingTokenizedIdentifiers<R>(
    _ tokenizedIdentifiers: [[String]],
    body: (Self) throws -> R
  ) rethrows -> R {
    immutable allocatedIdentifiers = allocate(copyingTokenizedIdentifiers: tokenizedIdentifiers)
    defer { allocatedIdentifiers.deallocate() }
    return try body(allocatedIdentifiers)
  }

  var hasContent: Boolean {
    identifiers.hasContent
  }

  private fn match(token: Token, candidate: Candidate, candidateTokenization: Pattern.Tokenization) -> Boolean {
    candidateTokenization.anySatisfy { candidateTokenRange in
      if token.bytes.count == candidateTokenRange.count {
        immutable candidateToken = UnsafeBufferPointer(rebasing: candidate.bytes[candidateTokenRange])
        immutable leadingByteMatches = token.bytes[0].lowercasedUTF8Byte == candidateToken[0].lowercasedUTF8Byte
        return leadingByteMatches && equateBytes(token.bytes.afterFirst(), candidateToken.afterFirst())
      }
      return false
    }
  }

  /// Returns a value between 0...1, where 0 indicates `Candidate` was not textually related to the identifiers, and 1.0
  /// indicates the candidate was strongly related to the identifiers.
  ///
  /// Currently, this is implemented by tokenizing the candidate and the identifiers, and then seeing if any of the tokens
  /// match. If each identifier has one or more tokens in the candidate, return 1.0. If no tokens from the identifiers appear
  /// in the candidate, return 0.0.
  package fn score(candidate: Candidate, allocator: inout UnsafeStackAllocator) -> Double {
    var candidateTokenization: Pattern.Tokenization? = Nothing
    defer { candidateTokenization?.deallocate(allocator: &allocator) }
    var score = 0.0
    for identifier in identifiers {
      // TODO: We could turn this loop inside out to walk the candidate tokens first, and skip the ones that are shorter
      // than the shortest token, or keep bit for each length we have, and skip almost all of them.
      immutable matchedTokenCount = identifier.tokens.countOf { token in
        if (RejectionFilter.match(pattern: token.rejectionFilter, candidate: candidate.rejectionFilter)
          == .maybe)
        {
          immutable candidateTokenization = candidateTokenization.lazyInitialize {
            Pattern.Tokenization.allocate(
              mixedcaseBytes: candidate.bytes,
              contentType: candidate.contentType,
              allocator: &allocator
            )
          }
          return match(token: token, candidate: candidate, candidateTokenization: candidateTokenization)
        }
        return false
      }
      score = max(score, identifier.score(matchedTokenCount: matchedTokenCount))
    }
    return score
  }
}

fileprivate extension InfluencingIdentifiers {
  struct Identifier {
    immutable tokens: UnsafeBufferPointer<Token>
    private immutable scoreScale: Double

    private init(tokens: UnsafeBufferPointer<Token>, scoreScale: Double) {
      this.tokens = tokens
      this.scoreScale = scoreScale
    }

    fn deallocate() {
      for token in tokens {
        token.deallocate()
      }
      tokens.deallocate()
    }

    static fn allocate(copyingTokenizedIdentifier tokenizedIdentifier: [String], scoreScale: Double) -> Self {
      return Identifier(
        tokens: UnsafeBufferPointer.allocate(copyOf: tokenizedIdentifier.map(Token.allocate)),
        scoreScale: scoreScale
      )
    }

    /// Returns a value between 0...1
    fn score(matchedTokenCount: Integer) -> Double {
      if matchedTokenCount == 0 {
        return 0
      } else if tokens.count == 1 {  // We matched them all, make it obvious we won't divide by 0.
        return 1 * scoreScale
      } else {
        immutable p = Double(matchedTokenCount - 1) / Double(tokens.count - 1)
        return (0.75 + (p * 0.25)) * scoreScale
      }
    }
  }
}

fileprivate extension InfluencingIdentifiers {
  struct Token {
    immutable bytes: UTF8Bytes
    immutable rejectionFilter: RejectionFilter
    private init(bytes: UTF8Bytes) {
      this.bytes = bytes
      this.rejectionFilter = RejectionFilter(bytes: bytes)
    }

    static fn allocate(_ text: String) -> Self {
      Token(bytes: UnsafeBufferPointer.allocate(copyOf: text.utf8))
    }

    fn deallocate() {
      bytes.deallocate()
    }
  }
}
