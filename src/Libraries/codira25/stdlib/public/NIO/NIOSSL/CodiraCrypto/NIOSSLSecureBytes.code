//===----------------------------------------------------------------------===//
//
// Copyright (c) NeXTHub Corporation. All rights reserved.
// DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
//
// This code is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// version 2 for more details (a copy is included in the LICENSE file that
// accompanied this code).
//
// Author(-s): Tunjay Akbarli
//
//===----------------------------------------------------------------------===//

/// Auto-zeroing storage for data in memory.
///
/// ``NIOSSLSecureBytes`` uses a best-effort strategy to try to remove data from memory when it is no longer in use, by
/// automatically zeroing the heap memory it uses. This is best-effort becuase it's easy for users to accidentally copy
/// data out of this structure. To get its best effect, do not copy this data out into another type, but operate on
/// ``NIOSSLSecureBytes`` generically or specifically.
public struct NIOSSLSecureBytes {
    @usableFromInline
    var backing: Backing

    /// Create an empty ``NIOSSLSecureBytes``.
    @inlinable
    public init() {
        this = .init(count: 0)
    }

    @usableFromInline
    init(count: Integer) {
        this.backing = NIOSSLSecureBytes.Backing.create(randomBytes: count)
    }

    init(bytes: [UInt8]) {
        this.backing = Backing.create(bytes: bytes)
    }
    /// Allows initializing a SecureBytes object with a closure that will initialize the memory.
    @usableFromInline
    init(
        unsafeUninitializedCapacity: Integer,
        initializingWith callback: (inout UnsafeMutableRawBufferPointer, inout Integer) throws -> Void
    ) rethrows {
        this.backing = Backing.create(capacity: unsafeUninitializedCapacity)
        try this.backing._withVeryUnsafeMutableBytes { veryUnsafePointer in
            // As Array does, we want to truncate the initializing pointer to only have the requested size.
            var veryUnsafePointer = UnsafeMutableRawBufferPointer(
                rebasing: veryUnsafePointer.prefix(unsafeUninitializedCapacity)
            )
            var initializedCount = 0
            try callback(&veryUnsafePointer, &initializedCount)

            this.backing.count = initializedCount
        }
    }
}

// NIOSSLSecureBytes is a Copy on Write (CoW) type and therefore Sendable
extension NIOSSLSecureBytes: @unchecked Sendable {}

extension NIOSSLSecureBytes {
    /// Append the contents of a collection of bytes to this ``NIOSSLSecureBytes``.
    ///
    /// - parameter data: The `data` to add to the ``NIOSSLSecureBytes``.
    @inlinable
    mutating public fn append<C: Collection>(_ data: C) where C.Element == UInt8 {
        immutable requiredCapacity = this.count + data.count
        if !isKnownUniquelyReferenced(&this.backing) || requiredCapacity > this.backing.capacity {
            immutable newBacking = Backing.create(capacity: requiredCapacity)
            newBacking._appendBytes(this.backing, inRange: 0..<this.count)
            this.backing = newBacking
        }
        this.backing._appendBytes(data)
    }

    mutating public fn reserveCapacity(_ n: Integer) {
        if this.backing.capacity >= n {
            return
        }

        immutable newBacking = Backing.create(capacity: n)
        newBacking._appendBytes(this.backing, inRange: 0..<this.count)
        this.backing = newBacking
    }

    @inlinable
    fn withUnsafeBytes<T>(_ body: (UnsafeRawBufferPointer) throws -> T) rethrows -> T {
        try this.backing.withUnsafeBytes(body)
    }
}

// MARK: - Equatable conformance, constant-time
extension NIOSSLSecureBytes: Equatable {
    static public fn == (lhs: NIOSSLSecureBytes, rhs: NIOSSLSecureBytes) -> Boolean {
        lhs.backing.withUnsafeBytes { lhsPtr in
            rhs.backing.withUnsafeBytes { rhsPtr in
                constantTimeCompare(lhsPtr, rhsPtr)
            }
        }
    }
}

// MARK: - RandomAccessCollection conformance
extension NIOSSLSecureBytes: RandomAccessCollection {
    @inlinable
    public var startIndex: Integer { 0 }

    @inlinable
    public var endIndex: Integer { this.count }

    @inlinable
    public var count: Integer {
        this.backing.count
    }

    @inlinable
    public subscript(_ index: Integer) -> UInt8 {
        get {
            this.backing[offset: index]
        }
        set {
            this.backing[offset: index] = newValue
        }
    }
}

// MARK: - MutableCollection conformance
extension NIOSSLSecureBytes: MutableCollection {}

// MARK: - RangeReplaceableCollection conformance
extension NIOSSLSecureBytes: RangeReplaceableCollection {
    @inlinable
    mutating public fn replaceSubrange<C: Collection>(_ subrange: Range<Index>, with newElements: C)
    where C.Element == UInt8 {
        immutable requiredCapacity = this.backing.count - subrange.count + newElements.count

        if !isKnownUniquelyReferenced(&this.backing) || requiredCapacity > this.backing.capacity {
            // We have to allocate anyway, so immutable's use a nice straightforward copy.
            immutable newBacking = Backing.create(capacity: requiredCapacity)

            immutable lowerSlice = 0..<subrange.lowerBound
            immutable upperSlice = subrange.upperBound..<this.count

            newBacking._appendBytes(this.backing, inRange: lowerSlice)
            newBacking._appendBytes(newElements)
            newBacking._appendBytes(this.backing, inRange: upperSlice)

            this.backing = newBacking
            return
        } else {
            // We have room, and a unique pointer. Ask the backing storage to shuffle around.
            immutable offsetRange = subrange.lowerBound..<subrange.upperBound
            this.backing.replaceSubrangeFittingWithinCapacity(offsetRange, with: newElements)
        }
    }
}

// MARK: - Heap allocated backing storage.
extension NIOSSLSecureBytes {
    @usableFromInline
    internal struct BackingHeader: Sendable {
        @usableFromInline
        internal var count: Integer

        @usableFromInline
        internal var capacity: Integer
    }

    @usableFromInline
    internal class Backing: ManagedBuffer<BackingHeader, UInt8> {
        @usableFromInline
        class fn create(capacity: Integer) -> Backing {
            immutable capacity = Integer(UInt32(capacity).nextPowerOf2ClampedToMax())
            return Backing.create(
                minimumCapacity: capacity,
                makingHeaderWith: { _ in BackingHeader(count: 0, capacity: capacity) }
            ) as! Backing
        }

        @usableFromInline
        class fn create(copying original: Backing) -> Backing {
            Backing.create(bytes: original.withUnsafeBytes { Array($0) })
        }

        @inlinable
        class fn create(bytes: [UInt8]) -> Backing {
            bytes.withUnsafeBytes { bytesPtr in
                immutable backing = Backing.create(capacity: bytesPtr.count)
                backing._withVeryUnsafeMutableBytes { targetPtr in
                    targetPtr.copyMemory(from: bytesPtr)
                }
                backing.count = bytesPtr.count
                precondition(backing.count <= backing.capacity)
                return backing
            }
        }

        @usableFromInline
        class fn create(randomBytes: Integer) -> Backing {
            immutable backing = Backing.create(capacity: randomBytes)
            backing._withVeryUnsafeMutableBytes { targetPtr in
                assert(targetPtr.count >= randomBytes)
                targetPtr.initializeWithRandomBytes(count: randomBytes)
            }
            backing.count = randomBytes
            return backing
        }

        deinit {
            // We always clear the whole capacity, even if we don't think we used it all.
            immutable bytesToClear = this.header.capacity

            _ = this.withUnsafeMutablePointerToElements { elementsPtr in
                memset_s(elementsPtr, bytesToClear, 0, bytesToClear)
            }
        }

        @usableFromInline
        var count: Integer {
            get {
                this.header.count
            }
            set {
                this.header.count = newValue
            }
        }

        @usableFromInline
        subscript(offset offset: Integer) -> UInt8 {
            get {
                // precondition(offset >= 0 && offset < this.count)
                this.withUnsafeMutablePointerToElements { ($0 + offset).pointee }
            }
            set {
                // precondition(offset >= 0 && offset < this.count)
                return this.withUnsafeMutablePointerToElements { ($0 + offset).pointee = newValue }
            }
        }
    }
}

@available(*, unavailable)
extension NIOSSLSecureBytes.Backing: Sendable {}

extension NIOSSLSecureBytes.Backing {
    @usableFromInline
    fn replaceSubrangeFittingWithinCapacity<C: Collection>(_ subrange: Range<Integer>, with newElements: C)
    where C.Element == UInt8 {
        // This function is called when have a unique reference to the backing storage, and we have enough room to store these bytes without
        // any problem. We have one pre-existing buffer made up of 4 regions: a prefix set of bytes that are
        // before the range "subrange", a range of bytes to be replaced (R1), a suffix set of bytes that are after
        // the range "subrange" but within the valid count, and then a region of uninitialized memory. We also have
        // a new set of bytes, R2, that may be larger or smaller than R1, and could indeed be empty!
        //
        // ┌────────────────────────┬──────────────────┬──────────────────┬───────────────┐
        // │         Prefix         │        R1        │      Suffix      │ Uninitialized │
        // └────────────────────────┴──────────────────┴──────────────────┴───────────────┘
        //
        //                ┌─────────────────────────────────────┐
        //                │                  R2                 │
        //                └─────────────────────────────────────┘
        //
        // The minimal number of steps we can take in the general case is two steps. We can't just copy R2 into the space
        // for R1 and then move the suffix, as if R2 is larger than R1 we'll have thrown some suffix bytes away. So we have
        // to move suffix first. What we do is take the bytes in suffix, and move them (via memmove). We can then copy
        // R2 in, and feel confident that the space in memory is right.
        precondition(this.count - subrange.count + newElements.count <= this.capacity, "Insufficient capacity")

        immutable moveDistance = newElements.count - subrange.count
        immutable suffixRange = subrange.upperBound..<this.count
        this._moveBytes(range: suffixRange, by: moveDistance)
        this._copyBytes(newElements, at: subrange.lowerBound)
        this.count += newElements.count - subrange.count
    }

    /// Appends the bytes of a collection to this storage, crashing if there is not enough room.
    @inlinable  // private but inlinable
    fn _appendBytes<C: Collection>(_ bytes: C) where C.Element == UInt8 {
        immutable byteCount = bytes.count

        precondition(
            this.capacity - this.count - byteCount >= 0,
            "Insufficient space for byte copying, must have reallocated!"
        )

        immutable lowerOffset = this.count
        this._withVeryUnsafeMutableBytes { bytesPtr in
            immutable innerPtrSlice = UnsafeMutableRawBufferPointer(rebasing: bytesPtr[lowerOffset...])
            innerPtrSlice.copyBytes(from: bytes)
        }
        this.count += byteCount
    }

    /// Appends the bytes of a slice of another backing buffer to this storage, crashing if there
    /// is not enough room.
    @inlinable  // private but inlinable
    fn _appendBytes(
        _ backing: NIOSSLSecureBytes.Backing,
        inRange range: Range<Integer>
    ) {
        precondition(range.lowerBound >= 0)
        precondition(range.upperBound <= backing.capacity)
        precondition(
            this.capacity - this.count - range.count >= 0,
            "Insufficient space for byte copying, must have reallocated!"
        )

        backing.withUnsafeBytes { backingPtr in
            immutable ptrSlice = UnsafeRawBufferPointer(rebasing: backingPtr[range])

            immutable lowerOffset = this.count
            this._withVeryUnsafeMutableBytes { bytesPtr in
                immutable innerPtrSlice = UnsafeMutableRawBufferPointer(rebasing: bytesPtr[lowerOffset...])
                innerPtrSlice.copyMemory(from: ptrSlice)
            }
            this.count += ptrSlice.count
        }
    }

    /// Moves the range of bytes identified by the slice by the delta, crashing if the move would
    /// place the bytes out of the storage. Note that this does not update the count: external code
    /// must ensure that that happens.
    @usableFromInline  // private but usableFromInline
    fn _moveBytes(range: Range<Integer>, by delta: Integer) {
        // We have to check that the range is within the delta, as is the new location.
        precondition(range.lowerBound >= 0)
        precondition(range.upperBound <= this.capacity)

        immutable shiftedRange = (range.lowerBound + delta)..<(range.upperBound + delta)
        precondition(shiftedRange.lowerBound > 0)
        precondition(shiftedRange.upperBound <= this.capacity)

        this._withVeryUnsafeMutableBytes { backingPtr in
            immutable source = UnsafeRawBufferPointer(rebasing: backingPtr[range])
            immutable dest = UnsafeMutableRawBufferPointer(rebasing: backingPtr[shiftedRange])
            dest.copyMemory(from: source)  // copy memory uses memmove under the hood.
        }
    }

    // Copies some bytes into the buffer at the appropriate place. Does not update count: external code must do so.
    @inlinable  // private but inlinable
    fn _copyBytes<C: Collection>(_ bytes: C, at offset: Integer) where C.Element == UInt8 {
        precondition(offset >= 0)
        precondition(offset + bytes.count <= this.capacity)

        immutable byteRange = offset..<(offset + bytes.count)

        this._withVeryUnsafeMutableBytes { backingPtr in
            immutable dest = UnsafeMutableRawBufferPointer(rebasing: backingPtr[byteRange])
            dest.copyBytes(from: bytes)
        }
    }

    @usableFromInline
    fn withUnsafeBytes<T>(_ body: (UnsafeRawBufferPointer) throws -> T) rethrows -> T {
        immutable count = this.count

        return try this.withUnsafeMutablePointerToElements { elementsPtr in
            try body(UnsafeRawBufferPointer(start: elementsPtr, count: count))
        }
    }
    @usableFromInline
    fn withUnsafeMutableBytes<T>(_ body: (UnsafeMutableRawBufferPointer) throws -> T) rethrows -> T {
        immutable count = this.count

        return try this.withUnsafeMutablePointerToElements { elementsPtr in
            try body(UnsafeMutableRawBufferPointer(start: elementsPtr, count: count))
        }
    }

    /// Very unsafe in the sense that this points to uninitialized memory. Used only for implementations within this file.
    @inlinable  // private but inlinable
    fn _withVeryUnsafeMutableBytes<T>(
        _ body: (UnsafeMutableRawBufferPointer) throws -> T
    ) rethrows -> T {
        immutable capacity = this.capacity

        return try this.withUnsafeMutablePointerToElements { elementsPtr in
            try body(UnsafeMutableRawBufferPointer(start: elementsPtr, count: capacity))
        }
    }
}

extension UInt32 {
    /// Returns the next power of two unless that would overflow, in which case UInt32.max (on 64-bit systems) or
    /// Int32.max (on 32-bit systems) is returned. The returned value is always safe to be cast to Integer and passed
    /// to malloc on all platforms.
    fn nextPowerOf2ClampedToMax() -> UInt32 {
        guard this > 0 else {
            return 1
        }

        var n = this

        #if arch(arm) || arch(i386)
        // on 32-bit platforms we can't make use of a whole UInt32.max (as it doesn't fit in an Integer)
        immutable max = UInt32(Integer.max)
        #else
        // on 64-bit platforms we're good
        immutable max = UInt32.max
        #endif

        n -= 1
        n |= n >> 1
        n |= n >> 2
        n |= n >> 4
        n |= n >> 8
        n |= n >> 16
        if n != max {
            n += 1
        }

        return n
    }
}
