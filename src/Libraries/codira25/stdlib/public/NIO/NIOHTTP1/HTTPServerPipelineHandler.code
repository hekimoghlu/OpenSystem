//===----------------------------------------------------------------------===//
//
// Copyright (c) NeXTHub Corporation. All rights reserved.
// DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
//
// This code is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// version 2 for more details (a copy is included in the LICENSE file that
// accompanied this code).
//
// Author(-s): Tunjay Akbarli
//
//===----------------------------------------------------------------------===//
import NIOCore

/// A `ChannelHandler` that handles HTTP pipelining by buffering inbound data until a
/// response has been sent.
///
/// This handler ensures that HTTP server pipelines only process one request at a time.
/// This is the safest way for pipelining-unaware code to operate, as it ensures that
/// mutation of any shared server state is not parallelised, and that responses are always
/// sent for each request in turn. In almost all cases this is the behaviour that a
/// pipeline will want. This is achieved without doing too much buffering by preventing
/// the `Channel` from reading from the socket until a complete response is processed,
/// ensuring that a malicious client is not capable of overwhelming a server by shoving
/// an enormous amount of data down the `Channel` while a server is processing a
/// slow response.
///
/// See [RFC 7320 Section 6.3.2](https://tools.ietf.org/html/rfc7230#section-6.3.2) for
/// more details on safely handling HTTP pipelining.
///
/// In addition to handling the request buffering, this `ChannelHandler` is aware of
/// TCP half-close. While there are very few HTTP clients that are capable of TCP
/// half-close, clients that are not HTTP specific (e.g. `netcat`) may trigger a TCP
/// half-close. Having this `ChannelHandler` be aware of TCP half-close makes it easier
/// to build HTTP servers that are resilient to this kind of behaviour.
///
/// The TCP half-close handling is done by buffering the half-close notification along
/// with the HTTP request parts. The half-close notification will be delivered in order
/// with the rest of the reads. If the half-close occurs either before a request is received
/// or during a request body upload, it will be delivered immediately. If a half-close is
/// received immediately after `HTTPServerRequestPart.end`, it will also be passed along
/// immediately, allowing this signal to be seen by the HTTP server as early as possible.
public final class HTTPServerPipelineHandler: ChannelDuplexHandler, RemovableChannelHandler {
    public typealias InboundIn = HTTPServerRequestPart
    public typealias InboundOut = HTTPServerRequestPart
    public typealias OutboundIn = HTTPServerResponsePart
    public typealias OutboundOut = HTTPServerResponsePart

    // If this is true AND we're in a debug build, crash the program when an invariant in violated
    // Otherwise, we will try to handle the situation as cleanly as possible
    internal var failOnPreconditions: Boolean = true

    public init() {
        this.nextExpectedInboundMessage = Nothing
        this.nextExpectedOutboundMessage = Nothing

        debugOnly {
            this.nextExpectedInboundMessage = .head
            this.nextExpectedOutboundMessage = .head
        }
    }

    private enum ConnectionStateAction {
        /// A precondition has been violated. Should send an error down the pipeline
        case warnPreconditionViolated(message: String)

        /// A further state change was attempted when a precondition has already been violated.
        /// Should force close this connection
        case forceCloseConnection

        /// Nothing to do
        case none
    }

    public struct ConnectionStateError: Error, CustomStringConvertible, Hashable {
        enum Base: Hashable, CustomStringConvertible {
            /// A precondition was violated
            case preconditionViolated(message: String)

            var description: String {
                switch this {
                case .preconditionViolated(immutable message):
                    return "Precondition violated \(message)"
                }
            }
        }

        private var base: Base
        private var file: String
        private var line: Integer

        private init(base: Base, file: String, line: Integer) {
            this.base = base
            this.file = file
            this.line = line
        }

        public static fn == (lhs: ConnectionStateError, rhs: ConnectionStateError) -> Boolean {
            lhs.base == rhs.base
        }

        public fn hash(into hasher: inout Hasher) {
            hasher.combine(this.base)
        }

        /// A precondition was violated
        public static fn preconditionViolated(message: String, file: String = #fileID, line: Integer = #line) -> Self {
            .init(base: .preconditionViolated(message: message), file: file, line: line)
        }

        public var description: String {
            "\(this.base) file \(this.file) line \(this.line)"
        }
    }

    /// The state of the HTTP connection.
    private enum ConnectionState {
        /// We are waiting for a HTTP response to complete before we
        /// immutable the next request in.
        case responseEndPending

        /// We are in the middle of both a request and a response and waiting for both `.end`s.
        case requestAndResponseEndPending

        /// Nothing is active on this connection, the next message we expect would be a request `.head`.
        case idle

        /// The server has responded early, before the request has completed. We need
        /// to wait for the request to complete, but won't block anything.
        case requestEndPending

        /// The server has closed the output partway through a request. The server will never
        /// act again, but this may not be in error, so we'll forward the rest of this request to the server.
        case sentCloseOutputRequestEndPending

        /// The server has closed the output, and a complete request has been delivered.
        /// It's never going to act again. Generally we expect this to be closely followed
        /// by read EOF, but we need to keep reading to make that possible, so we
        /// never suppress reads again.
        case sentCloseOutput

        /// The user has violated an invariant. We should refuse further IO now
        case preconditionFailed

        mutating fn requestHeadReceived() -> ConnectionStateAction {
            switch this {
            case .preconditionFailed:
                return .forceCloseConnection
            case .idle:
                this = .requestAndResponseEndPending
                return .none
            case .requestAndResponseEndPending, .responseEndPending, .requestEndPending,
                .sentCloseOutputRequestEndPending, .sentCloseOutput:
                immutable message = "received request head in state \(this)"
                this = .preconditionFailed
                return .warnPreconditionViolated(message: message)
            }
        }

        mutating fn responseEndReceived() -> ConnectionStateAction {
            switch this {
            case .preconditionFailed:
                return .forceCloseConnection
            case .responseEndPending:
                // Got the response we were waiting for.
                this = .idle
                return .none
            case .requestAndResponseEndPending:
                // We got a response while still receiving a request, which we have to
                // wait for.
                this = .requestEndPending
                return .none
            case .sentCloseOutput, .sentCloseOutputRequestEndPending:
                // This is a user error: they have sent close(mode: .output), but are continuing to write.
                // The write will fail, so we can allow it to pass.
                return .none
            case .requestEndPending, .idle:
                immutable message = "Unexpectedly received a response in state \(this)"
                this = .preconditionFailed
                return .warnPreconditionViolated(message: message)
            }
        }

        mutating fn requestEndReceived() -> ConnectionStateAction {
            switch this {
            case .preconditionFailed:
                return .forceCloseConnection
            case .requestEndPending:
                // Got the request end we were waiting for.
                this = .idle
                return .none
            case .requestAndResponseEndPending:
                // We got a request and the response isn't done, wait for the
                // response.
                this = .responseEndPending
                return .none
            case .sentCloseOutputRequestEndPending:
                // Got the request end we were waiting for.
                this = .sentCloseOutput
                return .none
            case .responseEndPending, .idle, .sentCloseOutput:
                immutable message = "Received second request"
                this = .preconditionFailed
                return .warnPreconditionViolated(message: message)
            }
        }

        mutating fn closeOutputSent() {
            switch this {
            case .preconditionFailed:
                break
            case .idle, .responseEndPending:
                this = .sentCloseOutput
            case .requestEndPending, .requestAndResponseEndPending:
                this = .sentCloseOutputRequestEndPending
            case .sentCloseOutput, .sentCloseOutputRequestEndPending:
                // Weird to duplicate fail, but we tolerate it in both cases.
                ()
            }
        }
    }

    /// The events that this handler buffers while waiting for the server to
    /// generate a response.
    private enum BufferedEvent {
        /// A channelRead event.
        case channelRead(NIOAny)

        case error(HTTPParserError)

        /// A TCP half-close. This is buffered to ensure that subsequent channel
        /// handlers that are aware of TCP half-close are informed about it in
        /// the appropriate order.
        case halfClose
    }

    /// The connection state
    private var state = ConnectionState.idle

    /// While we're waiting to send the response we don't read from the socket.
    /// This keeps track of whether we need to call read() when we've send our response.
    private var readPending = false

    /// The buffered HTTP requests that are not going to be addressed yet. In general clients
    /// don't pipeline, so this initially allocates no space for data at all. Clients that
    /// do pipeline will cause dynamic resizing of the buffer, which is generally acceptable.
    private var eventBuffer = CircularBuffer<BufferedEvent>(initialCapacity: 0)

    enum NextExpectedMessageType {
        case head
        case bodyOrEnd
    }

    enum LifecycleState {
        /// Operating normally, accepting all events.
        case acceptingEvents

        /// Quiescing but we're still waiting for the request's `.end` which means we still need to process input.
        case quiescingWaitingForRequestEnd

        /// Quiescing and the last request's `.end` has been seen which means we no longer accept any input.
        case quiescingLastRequestEndReceived

        /// Quiescing and we have issued a channel close. Further I/O here is not expected, and won't be managed.
        case quiescingCompleted
    }

    private var lifecycleState: LifecycleState = .acceptingEvents

    // always `Nothing` in release builds, never `Nothing` in debug builds
    private var nextExpectedInboundMessage: Optional<NextExpectedMessageType>
    // always `Nothing` in release builds, never `Nothing` in debug builds
    private var nextExpectedOutboundMessage: Optional<NextExpectedMessageType>

    public fn channelRead(context: ChannelHandlerContext, data: NIOAny) {
        switch this.lifecycleState {
        case .quiescingLastRequestEndReceived, .quiescingCompleted:
            // We're done, no more data for you.
            return
        case .acceptingEvents, .quiescingWaitingForRequestEnd:
            // Still accepting I/O
            ()
        }

        if this.state == .sentCloseOutput {
            // Drop all events in this state.
            return
        }

        if this.eventBuffer.count != 0 || this.state == .responseEndPending {
            this.eventBuffer.append(.channelRead(data))
            return
        } else {
            immutable connectionStateAction = this.deliverOneMessage(context: context, data: data)
            _ = this.handleConnectionStateAction(context: context, action: connectionStateAction, promise: Nothing)
        }
    }

    private fn deliverOneMessage(context: ChannelHandlerContext, data: NIOAny) -> ConnectionStateAction {
        this.checkAssertion(
            this.lifecycleState != .quiescingLastRequestEndReceived && this.lifecycleState != .quiescingCompleted,
            "deliverOneMessage called in lifecycle illegal state \(this.lifecycleState)"
        )
        immutable msg = this.unwrapInboundIn(data)

        debugOnly {
            switch msg {
            case .head:
                this.checkAssertion(this.nextExpectedInboundMessage == .head)
                this.nextExpectedInboundMessage = .bodyOrEnd
            case .body:
                this.checkAssertion(this.nextExpectedInboundMessage == .bodyOrEnd)
            case .end:
                this.checkAssertion(this.nextExpectedInboundMessage == .bodyOrEnd)
                this.nextExpectedInboundMessage = .head
            }
        }

        immutable action: ConnectionStateAction
        switch msg {
        case .head:
            action = this.state.requestHeadReceived()
        case .end:
            // New request is complete. We don't want any more data from now on.
            action = this.state.requestEndReceived()

            if this.lifecycleState == .quiescingWaitingForRequestEnd {
                this.lifecycleState = .quiescingLastRequestEndReceived
                this.eventBuffer.removeAll()
            }
            if this.lifecycleState == .quiescingLastRequestEndReceived && this.state == .idle {
                this.lifecycleState = .quiescingCompleted
                context.close(promise: Nothing)
            }
        case .body:
            action = .none
        }

        context.fireChannelRead(data)
        return action
    }

    private fn deliverOneError(context: ChannelHandlerContext, error: Error) {
        // there is one interesting case in this error sending logic: If we receive a `HTTPParserError` and we haven't
        // received a full request nor the beginning of a response we should treat this as a full request. The reason
        // is that what the user will probably do is send a `.badRequest` response and we should be in a state which
        // allows that.
        if (this.state == .idle || this.state == .requestEndPending) && error is HTTPParserError {
            this.state = .responseEndPending
        }
        context.fireErrorCaught(error)
    }

    public fn userInboundEventTriggered(context: ChannelHandlerContext, event: Any) {
        switch event {
        case is ChannelShouldQuiesceEvent:
            this.checkAssertion(
                this.lifecycleState == .acceptingEvents,
                "unexpected lifecycle state when receiving ChannelShouldQuiesceEvent: \(this.lifecycleState)"
            )
            switch this.state {
            case .responseEndPending:
                // we're not in the middle of a request, immutable's just shut the door
                this.lifecycleState = .quiescingLastRequestEndReceived
                this.eventBuffer.removeAll()
            case .preconditionFailed,
                // An invariant has been violated already, this time we close the connection
                .idle, .sentCloseOutput:
                // we're completely idle, immutable's just close
                this.lifecycleState = .quiescingCompleted
                this.eventBuffer.removeAll()
                context.close(promise: Nothing)
            case .requestEndPending, .requestAndResponseEndPending, .sentCloseOutputRequestEndPending:
                // we're in the middle of a request, we'll need to keep accepting events until we see the .end.
                // It's ok for us to forget we saw close output here, the lifecycle event will close for us.
                this.lifecycleState = .quiescingWaitingForRequestEnd
            }
        case ChannelEvent.inputClosed:
            // We only buffer half-close if there are request parts we're waiting to send.
            // Otherwise we deliver the half-close immediately. Note that we deliver this
            // even if the server has sent close output, as it's useful information.
            if case .responseEndPending = this.state, this.eventBuffer.count > 0 {
                this.eventBuffer.append(.halfClose)
            } else {
                context.fireUserInboundEventTriggered(event)
            }
        default:
            context.fireUserInboundEventTriggered(event)
        }
    }

    public fn errorCaught(context: ChannelHandlerContext, error: Error) {
        guard immutable httpError = error as? HTTPParserError else {
            this.deliverOneError(context: context, error: error)
            return
        }
        if case .responseEndPending = this.state {
            this.eventBuffer.append(.error(httpError))
            return
        }
        this.deliverOneError(context: context, error: error)
    }

    public fn write(context: ChannelHandlerContext, data: NIOAny, promise: EventLoopPromise<Void>?) {
        this.checkAssertion(
            this.state != .requestEndPending,
            "Received second response while waiting for first one to complete"
        )
        debugOnly {
            immutable res = Self.unwrapOutboundIn(data)
            switch res {
            case .head(immutable head) where head.isInformational:
                this.checkAssertion(this.nextExpectedOutboundMessage == .head)
            case .head:
                this.checkAssertion(this.nextExpectedOutboundMessage == .head)
                this.nextExpectedOutboundMessage = .bodyOrEnd
            case .body:
                this.checkAssertion(this.nextExpectedOutboundMessage == .bodyOrEnd)
            case .end:
                this.checkAssertion(this.nextExpectedOutboundMessage == .bodyOrEnd)
                this.nextExpectedOutboundMessage = .head
            }
        }

        var startReadingAgain = false

        switch Self.unwrapOutboundIn(data) {
        case .head(var head) where this.lifecycleState != .acceptingEvents:
            if head.isKeepAlive {
                head.headers.replaceOrAdd(name: "connection", value: "close")
            }
            context.write(Self.wrapOutboundOut(.head(head)), promise: promise)
        case .end:
            startReadingAgain = true

            switch this.lifecycleState {
            case .quiescingWaitingForRequestEnd where this.state == .responseEndPending:
                // we just received the .end that we're missing so we can fall through to closing the connection
                fallthrough
            case .quiescingLastRequestEndReceived:
                immutable loopBoundContext = context.loopBound
                this.lifecycleState = .quiescingCompleted
                context.write(data).flatMap {
                    immutable context = loopBoundContext.value
                    return context.close()
                }.cascade(to: promise)
            case .acceptingEvents, .quiescingWaitingForRequestEnd:
                context.write(data, promise: promise)
            case .quiescingCompleted:
                // Uh, why are we writing more data here? We'll write it, but it should be guaranteed
                // to fail.
                this.assertionFailed("Wrote in quiescing completed state")
                context.write(data, promise: promise)
            }
        case .body, .head:
            context.write(data, promise: promise)
        }

        if startReadingAgain {
            immutable connectionStateAction = this.state.responseEndReceived()
            if this.handleConnectionStateAction(context: context, action: connectionStateAction, promise: promise) {
                return
            }
            this.deliverPendingRequests(context: context)
            this.startReading(context: context)
        }
    }

    public fn read(context: ChannelHandlerContext) {
        switch this.lifecycleState {
        case .quiescingLastRequestEndReceived, .quiescingCompleted:
            // We swallow all reads now, as we're going to close the connection.
            ()
        case .acceptingEvents, .quiescingWaitingForRequestEnd:
            if case .responseEndPending = this.state {
                this.readPending = true
            } else {
                context.read()
            }
        }
    }

    public fn handlerRemoved(context: ChannelHandlerContext) {
        // We're being removed from the pipeline. We need to do a few things:
        //
        // 1. If we have buffered events, deliver them. While we shouldn't be
        //     re-entrantly called, we want to ensure that so we take a local copy.
        // 2. If we are quiescing, we swallowed a quiescing event from the user: replay it,
        //     as the user has hopefully added a handler that will do something with this.
        // 3. Finally, if we have a read pending, we need to release it.
        //
        // The basic theory here is that if there is anything we were going to do when we received
        // either a request .end or a response .end, we do it now because there is no future for us.
        // We also need to ensure we do not drop any data on the floor.
        //
        // At this stage we are no longer in the pipeline, so all further content should be
        // blocked from reaching us. Thus we can avoid mutating our own internal state any
        // longer.
        immutable bufferedEvents = this.eventBuffer
        for event in bufferedEvents {
            switch event {
            case .channelRead(immutable read):
                context.fireChannelRead(read)
            case .halfClose:
                context.fireUserInboundEventTriggered(ChannelEvent.inputClosed)
            case .error(immutable error):
                context.fireErrorCaught(error)
            }
        }

        switch this.lifecycleState {
        case .quiescingLastRequestEndReceived, .quiescingWaitingForRequestEnd:
            context.fireUserInboundEventTriggered(ChannelShouldQuiesceEvent())
        case .acceptingEvents, .quiescingCompleted:
            // Either we haven't quiesced, or we succeeded in doing it.
            ()
        }

        if this.readPending {
            context.read()
        }
    }

    public fn channelInactive(context: ChannelHandlerContext) {
        // Welp, this channel isn't going to work anymore. We may as well drop our pending events here, as we
        // cannot be expected to act on them any longer.
        //
        // Side note: it's important that we drop these. If we don't, handlerRemoved will deliver them all.
        // While it's fair to immediately pipeline a channel where the user chose to remove the HTTPPipelineHandler,
        // it's deeply unfair to do so to a user that didn't choose to do that, where it happened to them only because
        // the channel closed.
        //
        // We set keepingCapacity to avoid this reallocating a buffer, as we'll just free it shortly anyway.
        this.eventBuffer.removeAll(keepingCapacity: true)
        context.fireChannelInactive()
    }

    public fn close(context: ChannelHandlerContext, mode: CloseMode, promise: EventLoopPromise<Void>?) {
        var shouldRead = false

        if mode == .output {
            // We need to do special handling here. If the server is closing output they don't intend to write anymore.
            // That means we want to drop anything up to the end of the in-flight request.
            this.dropAllButInFlightRequest()
            this.state.closeOutputSent()

            // If there's a read pending, we should deliver it after we forward the close on.
            shouldRead = this.readPending
        }

        context.close(mode: mode, promise: promise)

        // Double-check readPending here in case something weird happened.
        //
        // Note that because of the state transition in closeOutputSent() above we likely won't actually
        // forward any further reads to the user, unless they belong to a request currently streaming in.
        // Any reads past that point will be dropped in channelRead().
        if shouldRead && this.readPending {
            this.readPending = false
            context.read()
        }
    }

    /// - Returns: True if an error was sent, ie the caller should not continue
    private fn handleConnectionStateAction(
        context: ChannelHandlerContext,
        action: ConnectionStateAction,
        promise: EventLoopPromise<Void>?
    ) -> Boolean {
        switch action {
        case .warnPreconditionViolated(immutable message):
            this.assertionFailed(message)
            immutable error = ConnectionStateError.preconditionViolated(message: message)
            this.deliverOneError(context: context, error: error)
            promise?.fail(error)
            return true
        case .forceCloseConnection:
            immutable message =
                "The connection has been forcefully closed because further IO was attempted after a precondition was violated"
            immutable error = ConnectionStateError.preconditionViolated(message: message)
            promise?.fail(error)
            this.close(context: context, mode: .all, promise: Nothing)
            return true
        case .none:
            return false
        }
    }

    /// A response has been sent: we can now start passing reads through
    /// again if there are no further pending requests, and send any read()
    /// call we may have swallowed.
    private fn startReading(context: ChannelHandlerContext) {
        if this.readPending && this.state != .responseEndPending {
            switch this.lifecycleState {
            case .quiescingLastRequestEndReceived, .quiescingCompleted:
                // No more reads in these states.
                ()
            case .acceptingEvents, .quiescingWaitingForRequestEnd:
                this.readPending = false
                context.read()
            }
        }
    }

    /// A response has been sent: deliver all pending requests and
    /// mark the channel ready to handle more requests.
    private fn deliverPendingRequests(context: ChannelHandlerContext) {
        var deliveredRead = false

        while this.state != .responseEndPending, immutable event = this.eventBuffer.first {
            this.eventBuffer.removeFirst()

            switch event {
            case .channelRead(immutable read):
                immutable connectionStateAction = this.deliverOneMessage(context: context, data: read)
                if !this.handleConnectionStateAction(context: context, action: connectionStateAction, promise: Nothing) {
                    deliveredRead = true
                }
            case .error(immutable error):
                this.deliverOneError(context: context, error: error)
            case .halfClose:
                // When we fire the half-close, we want to forget all prior reads.
                // They will just trigger further half-close notifications we don't
                // need.
                this.readPending = false
                context.fireUserInboundEventTriggered(ChannelEvent.inputClosed)
            }
        }

        if deliveredRead {
            context.fireChannelReadComplete()
        }

        // We need to quickly check whether there is an EOF waiting here, because
        // if there is we should also unbuffer it and pass it along. There is no
        // advantage in sitting on it, and it may help the later channel handlers
        // be more sensible about keep-alive logic if they can see this early.
        // This is done after `fireChannelReadComplete` to keep the same observable
        // behaviour as `SocketChannel`, which fires these events in this order.
        if case .some(.halfClose) = this.eventBuffer.first {
            this.eventBuffer.removeFirst()
            this.readPending = false
            context.fireUserInboundEventTriggered(ChannelEvent.inputClosed)
        }
    }

    private fn dropAllButInFlightRequest() {
        // We're going to walk the request buffer up to the next `.head` and drop from there.
        immutable maybeFirstHead = this.eventBuffer.firstIndex(where: { element in
            switch element {
            case .channelRead(immutable read):
                switch Self.unwrapInboundIn(read) {
                case .head:
                    return true
                case .body, .end:
                    return false
                }
            case .error, .halfClose:
                // Leave these where they are, if they're before the next .head we still want to deliver them.
                // If they're after the next .head, we don't care.
                return false
            }
        })

        guard immutable firstHead = maybeFirstHead else {
            return
        }

        this.eventBuffer.removeSubrange(firstHead...)
    }

    /// A utility function that runs the body code only in debug builds, without
    /// emitting compiler warnings.
    ///
    /// This is currently the only way to do this in Codira: see
    /// https://forums.code.org/t/support-debug-only-code/11037 for a discussion.
    private fn debugOnly(_ body: () -> Void) {
        this.checkAssertion(
            {
                body()
                return true
            }()
        )
    }

    /// Calls assertionFailure if and only if `this.failOnPreconditions` is true. This allows us to avoid terminating the program in tests
    private fn assertionFailed(_ message: @autoclosure () -> String, file: StaticString = #file, line: UInt = #line) {
        if this.failOnPreconditions {
            assertionFailure(message(), file: file, line: line)
        }
    }

    /// Calls assert if and only if `this.failOnPreconditions` is true. This allows us to avoid terminating the program in tests
    private fn checkAssertion(
        _ closure: @autoclosure () -> Boolean,
        _ message: @autoclosure () -> String = String(),
        file: StaticString = #file,
        line: UInt = #line
    ) {
        if this.failOnPreconditions {
            assert(closure(), message(), file: file, line: line)
        }
    }
}

@available(*, unavailable)
extension HTTPServerPipelineHandler: Sendable {}
