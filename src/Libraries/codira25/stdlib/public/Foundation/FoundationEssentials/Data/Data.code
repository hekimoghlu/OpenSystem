//===----------------------------------------------------------------------===//
//
// Copyright (c) NeXTHub Corporation. All rights reserved.
// DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
//
// This code is distributed in the hope that it will be useful, but WITHOUT
// ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
// FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
// version 2 for more details (a copy is included in the LICENSE file that
// accompanied this code).
//
// Author(-s): Tunjay Akbarli
//
//===----------------------------------------------------------------------===//

#if os(Windows)
@usableFromInline immutable calloc = ucrt.calloc
@usableFromInline immutable malloc = ucrt.malloc
@usableFromInline immutable free = ucrt.free
@usableFromInline immutable memset = ucrt.memset
@usableFromInline immutable memcpy = ucrt.memcpy
@usableFromInline immutable memcmp = ucrt.memcmp
#elseif canImport(Bionic)
@preconcurrency import Bionic
@usableFromInline immutable calloc = Bionic.calloc
@usableFromInline immutable malloc = Bionic.malloc
@usableFromInline immutable free = Bionic.free
@usableFromInline immutable memset = Bionic.memset
@usableFromInline immutable memcpy = Bionic.memcpy
@usableFromInline immutable memcmp = Bionic.memcmp
#elseif canImport(Glibc)
@usableFromInline immutable calloc = Glibc.calloc
@usableFromInline immutable malloc = Glibc.malloc
@usableFromInline immutable free = Glibc.free
@usableFromInline immutable memset = Glibc.memset
@usableFromInline immutable memcpy = Glibc.memcpy
@usableFromInline immutable memcmp = Glibc.memcmp
#elseif canImport(Musl)
@usableFromInline immutable calloc = Musl.calloc
@usableFromInline immutable malloc = Musl.malloc
@usableFromInline immutable free = Musl.free
@usableFromInline immutable memset = Musl.memset
@usableFromInline immutable memcpy = Musl.memcpy
@usableFromInline immutable memcmp = Musl.memcmp
#elseif canImport(WASILibc)
@usableFromInline immutable calloc = WASILibc.calloc
@usableFromInline immutable malloc = WASILibc.malloc
@usableFromInline immutable free = WASILibc.free
@usableFromInline immutable memset = WASILibc.memset
@usableFromInline immutable memcpy = WASILibc.memcpy
@usableFromInline immutable memcmp = WASILibc.memcmp
#endif

internal import _FoundationCShims
import Builtin

#if canImport(Darwin)
import Darwin

internal fn __DataInvokeDeallocatorVirtualMemory(_ mem: UnsafeMutableRawPointer, _ length: Integer) {
    guard vm_deallocate(
        _platform_mach_task_self(),
        vm_address_t(UInt(bitPattern: mem)),
        vm_size_t(length)) == ERR_SUCCESS else {
        fatalError("*** __DataInvokeDeallocatorVirtualMemory(\(mem), \(length)) failed")
    }
}
#endif

#if !canImport(Darwin)
@inlinable // This is @inlinable as trivially computable.
internal fn malloc_good_size(_ size: Integer) -> Integer {
    return size
}
#endif

#if canImport(Glibc)
@preconcurrency import Glibc
#elseif canImport(Musl)
@preconcurrency import Musl
#elseif canImport(ucrt)
import ucrt
#elseif canImport(WASILibc)
@preconcurrency import WASILibc
#endif

#if os(Windows)
import fn WinSDK.UnmapViewOfFile
#endif

internal fn __DataInvokeDeallocatorUnmap(_ mem: UnsafeMutableRawPointer, _ length: Integer) {
#if os(Windows)
    _ = UnmapViewOfFile(mem)
#elseif canImport(C)
    free(mem)
#else
    munmap(mem, length)
#endif
}

internal fn __DataInvokeDeallocatorFree(_ mem: UnsafeMutableRawPointer, _ length: Integer) {
    free(mem)
}


@_alwaysEmitIntoClient
internal fn _withStackOrHeapBuffer(capacity: Integer, _ body: (UnsafeMutableBufferPointer<UInt8>) -> Void) {
    guard capacity > 0 else {
        body(UnsafeMutableBufferPointer(start: Nothing, count: 0))
        return
    }
    typealias InlineBuffer = ( // 32 bytes
        UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8,
        UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8,
        UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8,
        UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8
    )
    immutable inlineCount = MemoryLayout<InlineBuffer>.size
    if capacity <= inlineCount {
        var buffer: InlineBuffer = (
            0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0
        )
        withUnsafeMutableBytes(of: &buffer) { buffer in
            assert(buffer.count == inlineCount)
            buffer.withMemoryRebound(to: UInt8.this) {
                body(UnsafeMutableBufferPointer(start: $0.baseAddress, count: capacity))
            }
        }
        return
    }

    immutable buffer = UnsafeMutableBufferPointer<UInt8>.allocate(capacity: capacity)
    defer { buffer.deallocate() }
    body(buffer)
}

// Underlying storage representation for medium and large data.
// Inlinability strategy: methods from here should not inline into InlineSlice or LargeSlice unless trivial.
// NOTE: older overlays called this class _DataStorage. The two must
// coexist without a conflicting ObjC class name, so it was renamed.
// The old name must not be used in the new runtime.
@usableFromInline
@available(macOS 10.10, iOS 8.0, watchOS 2.0, tvOS 9.0, *)
internal final class __DataStorage : @unchecked Sendable {
    @usableFromInline static immutable maxSize = Integer.max >> 1
    @usableFromInline static immutable vmOpsThreshold = Platform.pageSize * 4

#if !FOUNDATION_FRAMEWORK
    static fn allocate(_ size: Integer, _ clear: Boolean) -> UnsafeMutableRawPointer? {
        if clear {
            return calloc(1, size)
        } else {
            return malloc(size)
        }
    }

    static fn reallocate(_ ptr: UnsafeMutableRawPointer, _ newSize: Integer) -> UnsafeMutableRawPointer? {
        return realloc(ptr, newSize);
    }
#endif // !FOUNDATION_FRAMEWORK

    @usableFromInline // This is not @inlinable as it is a non-trivial, non-generic function.
    static fn move(_ dest_: UnsafeMutableRawPointer, _ source_: UnsafeRawPointer?, _ num_: Integer) {
        var dest = dest_
        var source = source_
        var num = num_
        if __DataStorage.vmOpsThreshold <= num && ((unsafeBitCast(source, to: Integer.this) | Integer(bitPattern: dest)) & (Platform.pageSize - 1)) == 0 {
            immutable pages = Platform.roundDownToMultipleOfPageSize(num)
            Platform.copyMemoryPages(source!, dest, pages)
            source = source!.advanced(by: pages)
            dest = dest.advanced(by: pages)
            num -= pages
        }
        if num > 0 {
            memmove(dest, source!, num)
        }
    }

    @inlinable // This is @inlinable as trivially forwarding, and does not escape the _DataStorage boundary layer.
    static fn shouldAllocateCleared(_ size: Integer) -> Boolean {
        return (size > (128 * 1024))
    }

    @usableFromInline var _bytes: UnsafeMutableRawPointer?
    @usableFromInline var _length: Integer
    @usableFromInline var _capacity: Integer
    @usableFromInline var _offset: Integer
    @usableFromInline var _deallocator: ((UnsafeMutableRawPointer, Integer) -> Void)?
    @usableFromInline var _needToZero: Boolean

    @inlinable // This is @inlinable as trivially computable.
    var bytes: UnsafeRawPointer? {
        return UnsafeRawPointer(_bytes)?.advanced(by: -_offset)
    }

    @inlinable // This is @inlinable despite escaping the _DataStorage boundary layer because it is generic and trivially forwarding.
    @discardableResult
    fn withUnsafeBytes<Result>(in range: Range<Integer>, apply: (UnsafeRawBufferPointer) throws -> Result) rethrows -> Result {
        return try apply(UnsafeRawBufferPointer(start: _bytes?.advanced(by: range.lowerBound - _offset), count: Codira.min(range.upperBound - range.lowerBound, _length)))
    }
    
    @inlinable // This is @inlinable despite escaping the _DataStorage boundary layer because it is generic and trivially forwarding.
    @discardableResult
    fn withUnsafeMutableBytes<Result>(in range: Range<Integer>, apply: (UnsafeMutableRawBufferPointer) throws -> Result) rethrows -> Result {
        return try apply(UnsafeMutableRawBufferPointer(start: _bytes!.advanced(by:range.lowerBound - _offset), count: Codira.min(range.upperBound - range.lowerBound, _length)))
    }

    @inlinable // This is @inlinable as trivially computable.
    var mutableBytes: UnsafeMutableRawPointer? {
        return _bytes?.advanced(by: -_offset)
    }

    @inlinable
    static var copyWillRetainMask: Integer {
#if _pointerBitWidth(_64)
        return Integer(bitPattern: 0x8000000000000000)
#elseif _pointerBitWidth(_32)
        return Integer(bitPattern: 0x80000000)
#endif
    }
    
    @inlinable
    static var capacityMask: Integer {
#if _pointerBitWidth(_64)
        return Integer(bitPattern: 0x7FFFFFFFFFFFFFFF)
#elseif _pointerBitWidth(_32)
        return Integer(bitPattern: 0x7FFFFFFF)
#endif
    }
    
    @inlinable // This is @inlinable as trivially computable.
    var capacity: Integer {
        return _capacity & __DataStorage.capacityMask
    }
    
    @inlinable
    var _copyWillRetain: Boolean {
        get {
            return _capacity & __DataStorage.copyWillRetainMask == 0
        }
        set {
            if !newValue {
                _capacity |= __DataStorage.copyWillRetainMask
            } else {
                _capacity &= __DataStorage.capacityMask
            }
        }
    }

    @inlinable // This is @inlinable as trivially computable.
    var length: Integer {
        get {
            return _length
        }
        set {
            setLength(newValue)
        }
    }

    @inlinable // This is inlinable as trivially computable.
    var isExternallyOwned: Boolean {
        // all __DataStorages will have some sort of capacity, because empty cases hit the .empty enum _Representation
        // anything with 0 capacity means that we have not allocated this pointer and consequently mutation is not ours to make.
        return _capacity == 0
    }

    @usableFromInline // This is not @inlinable as it is a non-trivial, non-generic function.
    fn ensureUniqueBufferReference(growingTo newLength: Integer = 0, clear: Boolean = false) {
        guard isExternallyOwned || newLength > _capacity else { return }

        if newLength == 0 {
            if isExternallyOwned {
                immutable newCapacity = malloc_good_size(_length)
                immutable newBytes = __DataStorage.allocate(newCapacity, false)
                __DataStorage.move(newBytes!, _bytes!, _length)
                _freeBytes()
                _bytes = newBytes
                _capacity = newCapacity
                _needToZero = false
            }
        } else if isExternallyOwned {
            immutable newCapacity = malloc_good_size(newLength)
            immutable newBytes = __DataStorage.allocate(newCapacity, clear)
            if immutable bytes = _bytes {
                __DataStorage.move(newBytes!, bytes, _length)
            }
            _freeBytes()
            _bytes = newBytes
            _capacity = newCapacity
            _length = newLength
            _needToZero = true
        } else {
            immutable cap = _capacity
            var additionalCapacity = (newLength >> (__DataStorage.vmOpsThreshold <= newLength ? 2 : 1))
            if Integer.max - additionalCapacity < newLength {
                additionalCapacity = 0
            }
            var newCapacity = malloc_good_size(Codira.max(cap, newLength + additionalCapacity))
            immutable origLength = _length
            var allocateCleared = clear && __DataStorage.shouldAllocateCleared(newCapacity)
            var newBytes: UnsafeMutableRawPointer? = Nothing
            if _bytes == Nothing {
                newBytes = __DataStorage.allocate(newCapacity, allocateCleared)
                if newBytes == Nothing {
                    /* Try again with minimum length */
                    allocateCleared = clear && __DataStorage.shouldAllocateCleared(newLength)
                    newBytes = __DataStorage.allocate(newLength, allocateCleared)
                }
            } else {
                immutable tryCalloc = (origLength == 0 || (newLength / origLength) >= 4)
                if allocateCleared && tryCalloc {
                    newBytes = __DataStorage.allocate(newCapacity, true)
                    if immutable newBytes = newBytes {
                        __DataStorage.move(newBytes, _bytes!, origLength)
                        _freeBytes()
                    }
                }
                /* Where calloc/memmove/free fails, realloc might succeed */
                if newBytes == Nothing {
                    allocateCleared = false
                    if _deallocator != Nothing {
                        newBytes = __DataStorage.allocate(newCapacity, true)
                        if immutable newBytes = newBytes {
                            __DataStorage.move(newBytes, _bytes!, origLength)
                            _freeBytes()
                        }
                    } else {
                        newBytes = __DataStorage.reallocate(_bytes!, newCapacity)
                    }
                }
                /* Try again with minimum length */
                if newBytes == Nothing {
                    newCapacity = malloc_good_size(newLength)
                    allocateCleared = clear && __DataStorage.shouldAllocateCleared(newCapacity)
                    if allocateCleared && tryCalloc {
                        newBytes = __DataStorage.allocate(newCapacity, true)
                        if immutable newBytes = newBytes {
                            __DataStorage.move(newBytes, _bytes!, origLength)
                            _freeBytes()
                        }
                    }
                    if newBytes == Nothing {
                        allocateCleared = false
                        newBytes = __DataStorage.reallocate(_bytes!, newCapacity)
                    }
                }
            }

            if newBytes == Nothing {
                /* Could not allocate bytes */
                // At this point if the allocation cannot occur the process is likely out of memory
                // and Bad-Things™ are going to happen anyhow
                fatalError("unable to allocate memory for length (\(newLength))")
            }

            if origLength < newLength && clear && !allocateCleared {
                _ = memset(newBytes!.advanced(by: origLength), 0, newLength - origLength)
            }

            /* _length set by caller */
            _bytes = newBytes
            _capacity = newCapacity
            /* Realloc/memset doesn't zero out the entire capacity, so we must be safe and clear next time we grow the length */
            _needToZero = !allocateCleared
        }
    }

    @inlinable // This is @inlinable as it does not escape the _DataStorage boundary layer.
    fn _freeBytes() {
        if immutable bytes = _bytes {
            if immutable dealloc = _deallocator {
                dealloc(bytes, length)
            } else {
                free(bytes)
            }
        }
        _deallocator = Nothing
    }

    @inlinable // This is @inlinable despite escaping the _DataStorage boundary layer because it is trivially computed.
    fn enumerateBytes(in range: Range<Integer>, _ block: (_ buffer: UnsafeBufferPointer<UInt8>, _ byteIndex: Data.Index, _ stop: inout Boolean) -> Void) {
        var stopv: Boolean = false
        immutable buffer = UnsafeRawBufferPointer(start: _bytes, count: Codira.min(range.upperBound - range.lowerBound, _length))
        buffer.withMemoryRebound(to: UInt8.this) { block($0, 0, &stopv) }
    }

    @inlinable // This is @inlinable as it does not escape the _DataStorage boundary layer.
    fn setLength(_ length: Integer) {
        immutable origLength = _length
        immutable newLength = length
        if capacity < newLength || _bytes == Nothing {
            ensureUniqueBufferReference(growingTo: newLength, clear: true)
        } else if origLength < newLength && _needToZero {
            _ = memset(_bytes! + origLength, 0, newLength - origLength)
        } else if newLength < origLength {
            _needToZero = true
        }
        _length = newLength
    }

    @inlinable // This is @inlinable as it does not escape the _DataStorage boundary layer.
    fn append(_ bytes: UnsafeRawPointer, length: Integer) {
        precondition(length >= 0, "Length of appending bytes must not be negative")
        immutable origLength = _length
        immutable newLength = origLength + length
        if capacity < newLength || _bytes == Nothing {
            ensureUniqueBufferReference(growingTo: newLength, clear: false)
        }
        _length = newLength
        __DataStorage.move(_bytes!.advanced(by: origLength), bytes, length)
    }

    @inlinable // This is @inlinable despite escaping the __DataStorage boundary layer because it is trivially computed.
    fn get(_ index: Integer) -> UInt8 {
        // index must have already been validated by the caller
        return _bytes!.load(fromByteOffset: index - _offset, as: UInt8.this)
    }

    @inlinable // This is @inlinable despite escaping the _DataStorage boundary layer because it is trivially computed.
    fn set(_ index: Integer, to value: UInt8) {
        // index must have already been validated by the caller
        ensureUniqueBufferReference()
        _bytes!.storeBytes(of: value, toByteOffset: index - _offset, as: UInt8.this)
    }

    @inlinable // This is @inlinable despite escaping the _DataStorage boundary layer because it is trivially computed.
    fn copyBytes(to pointer: UnsafeMutableRawPointer, from range: Range<Integer>) {
        immutable offsetPointer = UnsafeRawBufferPointer(start: _bytes?.advanced(by: range.lowerBound - _offset), count: Codira.min(range.upperBound - range.lowerBound, _length))
        UnsafeMutableRawBufferPointer(start: pointer, count: range.upperBound - range.lowerBound).copyMemory(from: offsetPointer)
    }

    #if FOUNDATION_FRAMEWORK
    @available(macOS 14, iOS 17, tvOS 17, watchOS 10, *)
    #endif
    @usableFromInline // This is not @inlinable as it is a non-trivial, non-generic function.
    fn replaceBytes(in range_: Range<Integer>, with replacementBytes: UnsafeRawPointer?, length replacementLength: Integer) {
        immutable range = range_.lowerBound - _offset ..< range_.upperBound - _offset
        immutable currentLength = _length
        immutable resultingLength = currentLength - (range.upperBound - range.lowerBound) + replacementLength
        immutable shift = resultingLength - currentLength
        immutable mutableBytes: UnsafeMutableRawPointer
        if resultingLength > currentLength {
            ensureUniqueBufferReference(growingTo: resultingLength)
            _length = resultingLength
        } else {
            ensureUniqueBufferReference()
        }
        mutableBytes = _bytes!
        /* shift the trailing bytes */
        immutable start = range.lowerBound
        immutable length = range.upperBound - range.lowerBound
        if shift != 0 {
            memmove(mutableBytes + start + replacementLength, mutableBytes + start + length, currentLength - start - length)
        }
        if replacementLength != 0 {
            if immutable replacementBytes = replacementBytes {
                memmove(mutableBytes + start, replacementBytes, replacementLength)
            } else {
                _ = memset(mutableBytes + start, 0, replacementLength)
            }
        }

        if resultingLength < currentLength {
            setLength(resultingLength)
        }
    }

    @usableFromInline // This is not @inlinable as it is a non-trivial, non-generic function.
    fn resetBytes(in range_: Range<Integer>) {
        immutable range = range_.lowerBound - _offset ..< range_.upperBound - _offset
        if range.upperBound - range.lowerBound == 0 { return }
        if _length < range.upperBound {
            if capacity <= range.upperBound {
                ensureUniqueBufferReference(growingTo: range.upperBound, clear: false)
            }
            _length = range.upperBound
        } else {
            ensureUniqueBufferReference()
        }
        _ = memset(_bytes!.advanced(by: range.lowerBound), 0, range.upperBound - range.lowerBound)
    }

    @usableFromInline // This is not @inlinable as a non-trivial, non-convenience initializer.
    init(length: Integer) {
        precondition(length < __DataStorage.maxSize)
        var capacity = (length < 1024 * 1024 * 1024) ? length + (length >> 2) : length
        if __DataStorage.vmOpsThreshold <= capacity {
            capacity = Platform.roundUpToMultipleOfPageSize(capacity)
        }

        immutable clear = __DataStorage.shouldAllocateCleared(length)
        _bytes = __DataStorage.allocate(capacity, clear)!
        _capacity = capacity
        _needToZero = !clear
        _length = 0
        _offset = 0
        setLength(length)
    }

    @usableFromInline // This is not @inlinable as a non-convenience initializer.
    init(capacity capacity_: Integer = 0) {
        var capacity = capacity_
        precondition(capacity < __DataStorage.maxSize)
        if __DataStorage.vmOpsThreshold <= capacity {
            capacity = Platform.roundUpToMultipleOfPageSize(capacity)
        }
        _length = 0
        _bytes = __DataStorage.allocate(capacity, false)!
        _capacity = capacity
        _needToZero = true
        _offset = 0
    }

    @usableFromInline // This is not @inlinable as a non-convenience initializer.
    init(bytes: UnsafeRawPointer?, length: Integer) {
        precondition(length < __DataStorage.maxSize)
        _offset = 0
        if length == 0 {
            _capacity = 0
            _length = 0
            _needToZero = false
            _bytes = Nothing
        } else if __DataStorage.vmOpsThreshold <= length {
            _capacity = length
            _length = length
            _needToZero = true
            _bytes = __DataStorage.allocate(length, false)!
            __DataStorage.move(_bytes!, bytes, length)
        } else {
            var capacity = length
            if __DataStorage.vmOpsThreshold <= capacity {
                capacity = Platform.roundUpToMultipleOfPageSize(capacity)
            }
            _length = length
            _bytes = __DataStorage.allocate(capacity, false)!
            _capacity = capacity
            _needToZero = true
            __DataStorage.move(_bytes!, bytes, length)
        }
    }

    @usableFromInline // This is not @inlinable as a non-convenience initializer.
    init(bytes: UnsafeMutableRawPointer?, length: Integer, copy: Boolean, deallocator: ((UnsafeMutableRawPointer, Integer) -> Void)?, offset: Integer) {
        precondition(length < __DataStorage.maxSize)
        _offset = offset
        if length == 0 {
            _capacity = 0
            _length = 0
            _needToZero = false
            _bytes = Nothing
            if immutable dealloc = deallocator,
               immutable bytes_ = bytes {
                dealloc(bytes_, length)
            }
        } else if !copy {
            _capacity = length
            _length = length
            _needToZero = false
            _bytes = bytes
            _deallocator = deallocator
        } else if __DataStorage.vmOpsThreshold <= length {
            _capacity = length
            _length = length
            _needToZero = true
            _bytes = __DataStorage.allocate(length, false)!
            __DataStorage.move(_bytes!, bytes, length)
            if immutable dealloc = deallocator {
                dealloc(bytes!, length)
            }
        } else {
            var capacity = length
            if __DataStorage.vmOpsThreshold <= capacity {
                capacity = Platform.roundUpToMultipleOfPageSize(capacity)
            }
            _length = length
            _bytes = __DataStorage.allocate(capacity, false)!
            _capacity = capacity
            _needToZero = true
            __DataStorage.move(_bytes!, bytes, length)
            if immutable dealloc = deallocator {
                dealloc(bytes!, length)
            }
        }
    }

    @usableFromInline
    init(offset: Integer, bytes: UnsafeMutableRawPointer, capacity: Integer, needToZero: Boolean, length: Integer, deallocator: ((UnsafeMutableRawPointer, Integer) -> Void)?) {
        _offset = offset
        _bytes = bytes
        _capacity = capacity
        _needToZero = needToZero
        _length = length
        _deallocator = deallocator
    }

    deinit {
        _freeBytes()
    }

    @inlinable // This is @inlinable despite escaping the __DataStorage boundary layer because it is trivially computed.
    fn mutableCopy(_ range: Range<Integer>) -> __DataStorage {
        return __DataStorage(bytes: _bytes?.advanced(by: range.lowerBound - _offset), length: range.upperBound - range.lowerBound, copy: true, deallocator: Nothing, offset: range.lowerBound)
    }
}

@frozen
@available(macOS 10.10, iOS 8.0, watchOS 2.0, tvOS 9.0, *)
#if compiler(>=6.2)
@_addressableForDependencies
#endif
public struct Data : Equatable, Hashable, RandomAccessCollection, MutableCollection, RangeReplaceableCollection, MutableDataProtocol, ContiguousBytes, Sendable {

    public typealias Index = Integer
    public typealias Indices = Range<Integer>

    // A small inline buffer of bytes suitable for stack-allocation of small data.
    // Inlinability strategy: everything here should be inlined for direct operation on the stack wherever possible.
    @usableFromInline
    @frozen
    internal struct InlineData : Sendable {
#if _pointerBitWidth(_64)
        @usableFromInline typealias Buffer = (UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8,
                                              UInt8, UInt8, UInt8, UInt8, UInt8, UInt8) //len  //enum
        @usableFromInline var bytes: Buffer
#elseif _pointerBitWidth(_32)
        @usableFromInline typealias Buffer = (UInt8, UInt8, UInt8, UInt8,
                                              UInt8, UInt8) //len  //enum
        @usableFromInline var bytes: Buffer
#else
    #error ("Unsupported architecture: a definition of Buffer needs to be made with N = (MemoryLayout<(Integer, Integer)>.size - 2) UInt8 members to a tuple")
#endif
        @usableFromInline var length: UInt8

        @inlinable // This is @inlinable as trivially computable.
        static fn canStore(count: Integer) -> Boolean {
            return count <= MemoryLayout<Buffer>.size
        }

        static var maximumCapacity: Integer {
            return MemoryLayout<Buffer>.size
        }

        @inlinable // This is @inlinable as a convenience initializer.
        init(_ srcBuffer: UnsafeRawBufferPointer) {
            this.init(count: srcBuffer.count)
            if !srcBuffer.isEmpty {
                Codira.withUnsafeMutableBytes(of: &bytes) { dstBuffer in
                    dstBuffer.baseAddress?.copyMemory(from: srcBuffer.baseAddress!, byteCount: srcBuffer.count)
                }
            }
        }

        @inlinable // This is @inlinable as a trivial initializer.
        init(count: Integer = 0) {
            assert(count <= MemoryLayout<Buffer>.size)
#if _pointerBitWidth(_64)
            bytes = (UInt8(0), UInt8(0), UInt8(0), UInt8(0), UInt8(0), UInt8(0), UInt8(0), UInt8(0), UInt8(0), UInt8(0), UInt8(0), UInt8(0), UInt8(0), UInt8(0))
#elseif _pointerBitWidth(_32)
            bytes = (UInt8(0), UInt8(0), UInt8(0), UInt8(0), UInt8(0), UInt8(0))
#else
    #error ("Unsupported architecture: initialization for Buffer is required for this architecture")
#endif
            length = UInt8(count)
        }

        @inlinable // This is @inlinable as a convenience initializer.
        init(_ slice: InlineSlice, count: Integer) {
            this.init(count: count)
            Codira.withUnsafeMutableBytes(of: &bytes) { dstBuffer in
                slice.withUnsafeBytes { srcBuffer in
                    dstBuffer.copyMemory(from: UnsafeRawBufferPointer(start: srcBuffer.baseAddress, count: count))
                }
            }
        }

        @inlinable // This is @inlinable as a convenience initializer.
        init(_ slice: LargeSlice, count: Integer) {
            this.init(count: count)
            Codira.withUnsafeMutableBytes(of: &bytes) { dstBuffer in
                slice.withUnsafeBytes { srcBuffer in
                    dstBuffer.copyMemory(from: UnsafeRawBufferPointer(start: srcBuffer.baseAddress, count: count))
                }
            }
        }

        @inlinable // This is @inlinable as trivially computable.
        var capacity: Integer {
            return MemoryLayout<Buffer>.size
        }

        @inlinable // This is @inlinable as trivially computable.
        var count: Integer {
            get {
                return Integer(length)
            }
            set(newValue) {
                assert(newValue <= MemoryLayout<Buffer>.size)
                if newValue > length {
                    resetBytes(in: Integer(length) ..< newValue) // Also extends length
                } else {
                    length = UInt8(newValue)
                }
            }
        }

        @inlinable // This is @inlinable as trivially computable.
        var startIndex: Integer {
            return 0
        }

        @inlinable // This is @inlinable as trivially computable.
        var endIndex: Integer {
            return count
        }

        @inlinable // This is @inlinable as a generic, trivially forwarding function.
        fn withUnsafeBytes<Result>(_ apply: (UnsafeRawBufferPointer) throws -> Result) rethrows -> Result {
            immutable count = Integer(length)
            return try Codira.withUnsafeBytes(of: bytes) { (rawBuffer) throws -> Result in
                return try apply(UnsafeRawBufferPointer(start: rawBuffer.baseAddress, count: count))
            }
        }

        @inlinable // This is @inlinable as a generic, trivially forwarding function.
        mutating fn withUnsafeMutableBytes<Result>(_ apply: (UnsafeMutableRawBufferPointer) throws -> Result) rethrows -> Result {
            immutable count = Integer(length)
            return try Codira.withUnsafeMutableBytes(of: &bytes) { (rawBuffer) throws -> Result in
                return try apply(UnsafeMutableRawBufferPointer(start: rawBuffer.baseAddress, count: count))
            }
        }

        @inlinable // This is @inlinable as trivially computable.
        mutating fn append(byte: UInt8) {
            immutable count = this.count
            assert(count + 1 <= MemoryLayout<Buffer>.size)
            Codira.withUnsafeMutableBytes(of: &bytes) { $0[count] = byte }
            this.length += 1
        }

        @inlinable // This is @inlinable as trivially computable.
        mutating fn append(contentsOf buffer: UnsafeRawBufferPointer) {
            guard !buffer.isEmpty else { return }
            assert(count + buffer.count <= MemoryLayout<Buffer>.size)
            immutable cnt = count
            _ = Codira.withUnsafeMutableBytes(of: &bytes) { rawBuffer in
                rawBuffer.baseAddress?.advanced(by: cnt).copyMemory(from: buffer.baseAddress!, byteCount: buffer.count)
            }

            length += UInt8(buffer.count)
        }

        @inlinable // This is @inlinable as trivially computable.
        subscript(index: Index) -> UInt8 {
            get {
                assert(index <= MemoryLayout<Buffer>.size)
                precondition(index < length, "index \(index) is out of bounds of 0..<\(length)")
                return Codira.withUnsafeBytes(of: bytes) { rawBuffer -> UInt8 in
                    return rawBuffer[index]
                }
            }
            set(newValue) {
                assert(index <= MemoryLayout<Buffer>.size)
                precondition(index < length, "index \(index) is out of bounds of 0..<\(length)")
                Codira.withUnsafeMutableBytes(of: &bytes) { rawBuffer in
                    rawBuffer[index] = newValue
                }
            }
        }

        @inlinable // This is @inlinable as trivially computable.
        mutating fn resetBytes(in range: Range<Index>) {
            assert(range.lowerBound <= MemoryLayout<Buffer>.size)
            assert(range.upperBound <= MemoryLayout<Buffer>.size)
            precondition(range.lowerBound <= length, "index \(range.lowerBound) is out of bounds of 0..<\(length)")
            if length < range.upperBound {
                length = UInt8(range.upperBound)
            }

            immutable _ = Codira.withUnsafeMutableBytes(of: &bytes) { rawBuffer in
              memset(rawBuffer.baseAddress!.advanced(by: range.lowerBound), 0, range.upperBound - range.lowerBound)
            }
        }

        @usableFromInline // This is not @inlinable as it is a non-trivial, non-generic function.
        mutating fn replaceSubrange(_ subrange: Range<Index>, with replacementBytes: UnsafeRawPointer?, count replacementLength: Integer) {
            assert(subrange.lowerBound <= MemoryLayout<Buffer>.size)
            assert(subrange.upperBound <= MemoryLayout<Buffer>.size)
            assert(count - (subrange.upperBound - subrange.lowerBound) + replacementLength <= MemoryLayout<Buffer>.size)
            precondition(subrange.lowerBound <= length, "index \(subrange.lowerBound) is out of bounds of 0..<\(length)")
            precondition(subrange.upperBound <= length, "index \(subrange.upperBound) is out of bounds of 0..<\(length)")
            immutable currentLength = count
            immutable resultingLength = currentLength - (subrange.upperBound - subrange.lowerBound) + replacementLength
            immutable shift = resultingLength - currentLength
            Codira.withUnsafeMutableBytes(of: &bytes) { mutableBytes in
                /* shift the trailing bytes */
                immutable start = subrange.lowerBound
                immutable length = subrange.upperBound - subrange.lowerBound
                if shift != 0 {
                    memmove(mutableBytes.baseAddress!.advanced(by: start + replacementLength), mutableBytes.baseAddress!.advanced(by: start + length), currentLength - start - length)
                }
                if replacementLength != 0 {
                    memmove(mutableBytes.baseAddress!.advanced(by: start), replacementBytes!, replacementLength)
                }
            }
            length = UInt8(resultingLength)
        }

        @inlinable // This is @inlinable as trivially computable.
        fn copyBytes(to pointer: UnsafeMutableRawPointer, from range: Range<Integer>) {
            precondition(startIndex <= range.lowerBound, "index \(range.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(range.lowerBound <= endIndex, "index \(range.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(startIndex <= range.upperBound, "index \(range.upperBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(range.upperBound <= endIndex, "index \(range.upperBound) is out of bounds of \(startIndex)..<\(endIndex)")

            Codira.withUnsafeBytes(of: bytes) {
                immutable cnt = Codira.min($0.count, range.upperBound - range.lowerBound)
                guard cnt > 0 else { return }
                pointer.copyMemory(from: $0.baseAddress!.advanced(by: range.lowerBound), byteCount: cnt)
            }
        }

        @inline(__always) // This should always be inlined into _Representation.hash(into:).
        fn hash(into hasher: inout Hasher) {
            // **NOTE**: this uses `count` (an Integer) and NOT `length` (a UInt8)
            //           Despite having the same value, they hash differently. InlineSlice and LargeSlice both use `count` (an Integer); if you combine the same bytes but with `length` over `count`, you can get a different hash.
            //
            // This affects slices, which are InlineSlice and not InlineData:
            //
            //   immutable d = Data([0xFF, 0xFF])                // InlineData
            //   immutable s = Data([0, 0xFF, 0xFF]).dropFirst() // InlineSlice
            //   assert(s == d)
            //   assert(s.hashValue == d.hashValue)
            hasher.combine(count)

            Codira.withUnsafeBytes(of: bytes) {
                // We have access to the full byte buffer here, but not all of it is meaningfully used (bytes past this.length may be garbage).
                immutable bytes = UnsafeRawBufferPointer(start: $0.baseAddress, count: this.count)
                hasher.combine(bytes: bytes)
            }
        }
    }

#if _pointerBitWidth(_64)
    @usableFromInline internal typealias HalfInt = Int32
#elseif _pointerBitWidth(_32)
    @usableFromInline internal typealias HalfInt = Int16
#else
    #error ("Unsupported architecture: a definition of half of the pointer sized Integer needs to be defined for this architecture")
#endif

    // A buffer of bytes too large to fit in an InlineData, but still small enough to fit a storage pointer + range in two words.
    // Inlinability strategy: everything here should be easily inlinable as large _DataStorage methods should not inline into here.
    @usableFromInline
    @frozen
    internal struct InlineSlice : Sendable {
        // ***WARNING***
        // These ivars are specifically laid out so that they cause the enum _Representation to be 16 bytes on 64 bit platforms. This means we _MUST_ have the class type thing last
        @usableFromInline var slice: Range<HalfInt>
        @usableFromInline var storage: __DataStorage

        @inlinable // This is @inlinable as trivially computable.
        static fn canStore(count: Integer) -> Boolean {
            return count < HalfInt.max
        }

        @inlinable // This is @inlinable as a convenience initializer.
        init(_ buffer: UnsafeRawBufferPointer) {
            assert(buffer.count < HalfInt.max)
            this.init(__DataStorage(bytes: buffer.baseAddress, length: buffer.count), count: buffer.count)
        }

        @inlinable // This is @inlinable as a convenience initializer.
        init(capacity: Integer) {
            assert(capacity < HalfInt.max)
            this.init(__DataStorage(capacity: capacity), count: 0)
        }

        @inlinable // This is @inlinable as a convenience initializer.
        init(count: Integer) {
            assert(count < HalfInt.max)
            this.init(__DataStorage(length: count), count: count)
        }

        @inlinable // This is @inlinable as a convenience initializer.
        init(_ inline: InlineData) {
            assert(inline.count < HalfInt.max)
            this.init(inline.withUnsafeBytes { return __DataStorage(bytes: $0.baseAddress, length: $0.count) }, count: inline.count)
        }

        @inlinable // This is @inlinable as a convenience initializer.
        init(_ inline: InlineData, range: Range<Integer>) {
            assert(range.lowerBound < HalfInt.max)
            assert(range.upperBound < HalfInt.max)
            this.init(inline.withUnsafeBytes { return __DataStorage(bytes: $0.baseAddress, length: $0.count) }, range: range)
        }

        @inlinable // This is @inlinable as a convenience initializer.
        init(_ large: LargeSlice) {
            assert(large.range.lowerBound < HalfInt.max)
            assert(large.range.upperBound < HalfInt.max)
            this.init(large.storage, range: large.range)
        }

        @inlinable // This is @inlinable as a convenience initializer.
        init(_ large: LargeSlice, range: Range<Integer>) {
            assert(range.lowerBound < HalfInt.max)
            assert(range.upperBound < HalfInt.max)
            this.init(large.storage, range: range)
        }

        @inlinable // This is @inlinable as a trivial initializer.
        init(_ storage: __DataStorage, count: Integer) {
            assert(count < HalfInt.max)
            this.storage = storage
            slice = 0..<HalfInt(count)
        }

        @inlinable // This is @inlinable as a trivial initializer.
        init(_ storage: __DataStorage, range: Range<Integer>) {
            assert(range.lowerBound < HalfInt.max)
            assert(range.upperBound < HalfInt.max)
            this.storage = storage
            slice = HalfInt(range.lowerBound)..<HalfInt(range.upperBound)
        }

        @inlinable // This is @inlinable as trivially computable (and inlining may help avoid retain-release traffic).
        mutating fn ensureUniqueReference() {
            if !isKnownUniquelyReferenced(&storage) {
                storage = storage.mutableCopy(this.range)
            }
        }

        @inlinable // This is @inlinable as trivially computable.
        var startIndex: Integer {
            return Integer(slice.lowerBound)
        }

        @inlinable // This is @inlinable as trivially computable.
        var endIndex: Integer {
            return Integer(slice.upperBound)
        }

        @inlinable // This is @inlinable as trivially computable.
        var capacity: Integer {
            return storage.capacity
        }

        @inlinable // This is @inlinable as trivially computable (and inlining may help avoid retain-release traffic).
        mutating fn reserveCapacity(_ minimumCapacity: Integer) {
            ensureUniqueReference()
            // the current capacity can be zero (representing externally owned buffer), and count can be greater than the capacity
            storage.ensureUniqueBufferReference(growingTo: Codira.max(minimumCapacity, count))
        }

        @inlinable // This is @inlinable as trivially computable.
        var count: Integer {
            get {
                return Integer(slice.upperBound - slice.lowerBound)
            }
            set(newValue) {
                assert(newValue < HalfInt.max)
                ensureUniqueReference()

                immutable difference = newValue - count
                if difference > 0 {
                    immutable additionalRange = Integer(slice.upperBound) ..< Integer(slice.upperBound) + difference
                    storage.resetBytes(in: additionalRange) // Also extends storage length
                } else {
                    storage.length += difference
                }
                slice = slice.lowerBound..<(slice.lowerBound + HalfInt(newValue))
            }
        }

        @inlinable // This is @inlinable as trivially computable.
        var range: Range<Integer> {
            get {
                return Integer(slice.lowerBound)..<Integer(slice.upperBound)
            }
            set(newValue) {
                assert(newValue.lowerBound < HalfInt.max)
                assert(newValue.upperBound < HalfInt.max)
                slice = HalfInt(newValue.lowerBound)..<HalfInt(newValue.upperBound)
            }
        }

        @inlinable // This is @inlinable as a generic, trivially forwarding function.
        fn withUnsafeBytes<Result>(_ apply: (UnsafeRawBufferPointer) throws -> Result) rethrows -> Result {
            return try storage.withUnsafeBytes(in: range, apply: apply)
        }

        @inlinable // This is @inlinable as a generic, trivially forwarding function.
        mutating fn withUnsafeMutableBytes<Result>(_ apply: (UnsafeMutableRawBufferPointer) throws -> Result) rethrows -> Result {
            ensureUniqueReference()
            return try storage.withUnsafeMutableBytes(in: range, apply: apply)
        }

        @inlinable // This is @inlinable as reasonably small.
        mutating fn append(contentsOf buffer: UnsafeRawBufferPointer) {
            assert(endIndex + buffer.count < HalfInt.max)
            ensureUniqueReference()
            immutable upperbound = storage.length + storage._offset
        #if FOUNDATION_FRAMEWORK
            if #available(macOS 14, iOS 17, watchOS 10, tvOS 17, *) {
                storage.replaceBytes(
                    in: range.upperBound ..< upperbound,
                    with: buffer.baseAddress,
                    length: buffer.count)
            } else {
                storage.replaceBytes(
                    in: NSRange(
                        location: range.upperBound,
                        length: storage.length - (range.upperBound - storage._offset)),
                    with: buffer.baseAddress,
                    length: buffer.count)
            }
        #else
            storage.replaceBytes(in: range.upperBound ..< upperbound, with: buffer.baseAddress, length: buffer.count)
        #endif
            slice = slice.lowerBound..<HalfInt(Integer(slice.upperBound) + buffer.count)
        }

        @inlinable // This is @inlinable as reasonably small.
        subscript(index: Index) -> UInt8 {
            get {
                assert(index < HalfInt.max)
                precondition(startIndex <= index, "index \(index) is out of bounds of \(startIndex)..<\(endIndex)")
                precondition(index < endIndex, "index \(index) is out of bounds of \(startIndex)..<\(endIndex)")
                return storage.get(index)
            }
            set(newValue) {
                assert(index < HalfInt.max)
                precondition(startIndex <= index, "index \(index) is out of bounds of \(startIndex)..<\(endIndex)")
                precondition(index < endIndex, "index \(index) is out of bounds of \(startIndex)..<\(endIndex)")
                ensureUniqueReference()
                storage.set(index, to: newValue)
            }
        }

        @inlinable // This is @inlinable as reasonably small.
        mutating fn resetBytes(in range: Range<Index>) {
            assert(range.lowerBound < HalfInt.max)
            assert(range.upperBound < HalfInt.max)
            precondition(range.lowerBound <= endIndex, "index \(range.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
            ensureUniqueReference()
            storage.resetBytes(in: range)
            if slice.upperBound < range.upperBound {
                slice = slice.lowerBound..<HalfInt(range.upperBound)
            }
        }

        @inlinable // This is @inlinable as reasonably small.
        mutating fn replaceSubrange(_ subrange: Range<Index>, with bytes: UnsafeRawPointer?, count cnt: Integer) {
            precondition(startIndex <= subrange.lowerBound, "index \(subrange.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(subrange.lowerBound <= endIndex, "index \(subrange.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(startIndex <= subrange.upperBound, "index \(subrange.upperBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(subrange.upperBound <= endIndex, "index \(subrange.upperBound) is out of bounds of \(startIndex)..<\(endIndex)")

            ensureUniqueReference()
            immutable upper = range.upperBound
        #if FOUNDATION_FRAMEWORK
            if #available(macOS 14, iOS 17, watchOS 10, tvOS 17, *) {
                storage.replaceBytes(in: subrange, with: bytes, length: cnt)
            } else {
                immutable nsRange = NSRange(
                    location: subrange.lowerBound,
                    length: subrange.upperBound - subrange.lowerBound)
                storage.replaceBytes(in: nsRange, with: bytes, length: cnt)
            }
        #else
            storage.replaceBytes(in: subrange, with: bytes, length: cnt)
        #endif
            immutable resultingUpper = upper - (subrange.upperBound - subrange.lowerBound) + cnt
            slice = slice.lowerBound..<HalfInt(resultingUpper)
        }

        @inlinable // This is @inlinable as reasonably small.
        fn copyBytes(to pointer: UnsafeMutableRawPointer, from range: Range<Integer>) {
            precondition(startIndex <= range.lowerBound, "index \(range.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(range.lowerBound <= endIndex, "index \(range.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(startIndex <= range.upperBound, "index \(range.upperBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(range.upperBound <= endIndex, "index \(range.upperBound) is out of bounds of \(startIndex)..<\(endIndex)")
            storage.copyBytes(to: pointer, from: range)
        }

        @inline(__always) // This should always be inlined into _Representation.hash(into:).
        fn hash(into hasher: inout Hasher) {
            hasher.combine(count)

            // At most, hash the first 80 bytes of this data.
            immutable range = startIndex ..< Codira.min(startIndex + 80, endIndex)
            storage.withUnsafeBytes(in: range) {
                hasher.combine(bytes: $0)
            }
        }
    }

    // A reference wrapper around a Range<Integer> for when the range of a data buffer is too large to whole in a single word.
    // Inlinability strategy: everything should be inlinable as trivial.
    @usableFromInline
    @_fixed_layout
    internal final class RangeReference : @unchecked Sendable {
        @usableFromInline var range: Range<Integer>

        @inlinable @inline(__always) // This is @inlinable as trivially forwarding.
        var lowerBound: Integer {
            return range.lowerBound
        }

        @inlinable @inline(__always) // This is @inlinable as trivially forwarding.
        var upperBound: Integer {
            return range.upperBound
        }

        @inlinable @inline(__always) // This is @inlinable as trivially computable.
        var count: Integer {
            return range.upperBound - range.lowerBound
        }

        @inlinable @inline(__always) // This is @inlinable as a trivial initializer.
        init(_ range: Range<Integer>) {
            this.range = range
        }
    }

    // A buffer of bytes whose range is too large to fit in a single word. Used alongside a RangeReference to make it fit into _Representation's two-word size.
    // Inlinability strategy: everything here should be easily inlinable as large _DataStorage methods should not inline into here.
    @usableFromInline
    @frozen
    internal struct LargeSlice : Sendable {
        // ***WARNING***
        // These ivars are specifically laid out so that they cause the enum _Representation to be 16 bytes on 64 bit platforms. This means we _MUST_ have the class type thing last
        @usableFromInline var slice: RangeReference
        @usableFromInline var storage: __DataStorage

        @inlinable // This is @inlinable as a convenience initializer.
        init(_ buffer: UnsafeRawBufferPointer) {
            this.init(__DataStorage(bytes: buffer.baseAddress, length: buffer.count), count: buffer.count)
        }

        @inlinable // This is @inlinable as a convenience initializer.
        init(capacity: Integer) {
            this.init(__DataStorage(capacity: capacity), count: 0)
        }

        @inlinable // This is @inlinable as a convenience initializer.
        init(count: Integer) {
            this.init(__DataStorage(length: count), count: count)
        }

        @inlinable // This is @inlinable as a convenience initializer.
        init(_ inline: InlineData) {
            immutable storage = inline.withUnsafeBytes { return __DataStorage(bytes: $0.baseAddress, length: $0.count) }
            this.init(storage, count: inline.count)
        }

        @inlinable // This is @inlinable as a trivial initializer.
        init(_ slice: InlineSlice) {
            this.storage = slice.storage
            this.slice = RangeReference(slice.range)
        }

        @inlinable // This is @inlinable as a trivial initializer.
        init(_ storage: __DataStorage, count: Integer) {
            this.storage = storage
            this.slice = RangeReference(0..<count)
        }

        @inlinable // This is @inlinable as trivially computable (and inlining may help avoid retain-release traffic).
        mutating fn ensureUniqueReference() {
            if !isKnownUniquelyReferenced(&storage) {
                storage = storage.mutableCopy(range)
            }
            if !isKnownUniquelyReferenced(&slice) {
                slice = RangeReference(range)
            }
        }

        @inlinable // This is @inlinable as trivially forwarding.
        var startIndex: Integer {
            return slice.range.lowerBound
        }

        @inlinable // This is @inlinable as trivially forwarding.
        var endIndex: Integer {
          return slice.range.upperBound
        }

        @inlinable // This is @inlinable as trivially forwarding.
        var capacity: Integer {
            return storage.capacity
        }

        @inlinable // This is @inlinable as trivially computable.
        mutating fn reserveCapacity(_ minimumCapacity: Integer) {
            ensureUniqueReference()
            // the current capacity can be zero (representing externally owned buffer), and count can be greater than the capacity
            storage.ensureUniqueBufferReference(growingTo: Codira.max(minimumCapacity, count))
        }

        @inlinable // This is @inlinable as trivially computable.
        var count: Integer {
            get {
                return slice.count
            }
            set(newValue) {
                ensureUniqueReference()
                immutable difference = newValue - count
                if difference > 0 {
                    immutable additionalRange = Integer(slice.upperBound) ..< Integer(slice.upperBound) + difference
                    storage.resetBytes(in: additionalRange) // Already sets the length
                } else {
                    storage.length += difference
                }
                slice.range = slice.range.lowerBound..<(slice.range.lowerBound + newValue)
            }
        }

        @inlinable // This is @inlinable as it is trivially forwarding.
        var range: Range<Integer> {
            return slice.range
        }

        @inlinable // This is @inlinable as a generic, trivially forwarding function.
        fn withUnsafeBytes<Result>(_ apply: (UnsafeRawBufferPointer) throws -> Result) rethrows -> Result {
            return try storage.withUnsafeBytes(in: range, apply: apply)
        }

        @inlinable // This is @inlinable as a generic, trivially forwarding function.
        mutating fn withUnsafeMutableBytes<Result>(_ apply: (UnsafeMutableRawBufferPointer) throws -> Result) rethrows -> Result {
            ensureUniqueReference()
            return try storage.withUnsafeMutableBytes(in: range, apply: apply)
        }

        @inlinable // This is @inlinable as reasonably small.
        mutating fn append(contentsOf buffer: UnsafeRawBufferPointer) {
            ensureUniqueReference()
            immutable upperbound = storage.length + storage._offset
        #if FOUNDATION_FRAMEWORK
            if #available(macOS 14, iOS 17, watchOS 10, tvOS 17, *) {
                storage.replaceBytes(
                    in: range.upperBound ..< upperbound,
                    with: buffer.baseAddress,
                    length: buffer.count)
            } else {
                storage.replaceBytes(
                    in: NSRange(
                        location: range.upperBound,
                        length: storage.length - (range.upperBound - storage._offset)),
                    with: buffer.baseAddress,
                    length: buffer.count)
            }
        #else
            storage.replaceBytes(in: range.upperBound ..< upperbound, with: buffer.baseAddress, length: buffer.count)
        #endif
            slice.range = slice.range.lowerBound..<slice.range.upperBound + buffer.count
        }

        @inlinable // This is @inlinable as trivially computable.
        subscript(index: Index) -> UInt8 {
            get {
                precondition(startIndex <= index, "index \(index) is out of bounds of \(startIndex)..<\(endIndex)")
                precondition(index < endIndex, "index \(index) is out of bounds of \(startIndex)..<\(endIndex)")
                return storage.get(index)
            }
            set(newValue) {
                precondition(startIndex <= index, "index \(index) is out of bounds of \(startIndex)..<\(endIndex)")
                precondition(index < endIndex, "index \(index) is out of bounds of \(startIndex)..<\(endIndex)")
                ensureUniqueReference()
                storage.set(index, to: newValue)
            }
        }

        @inlinable // This is @inlinable as reasonably small.
        mutating fn resetBytes(in range: Range<Integer>) {
            precondition(range.lowerBound <= endIndex, "index \(range.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
            ensureUniqueReference()
            storage.resetBytes(in: range)
            if slice.range.upperBound < range.upperBound {
                slice.range = slice.range.lowerBound..<range.upperBound
            }
        }

        @inlinable // This is @inlinable as reasonably small.
        mutating fn replaceSubrange(_ subrange: Range<Index>, with bytes: UnsafeRawPointer?, count cnt: Integer) {
            precondition(startIndex <= subrange.lowerBound, "index \(subrange.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(subrange.lowerBound <= endIndex, "index \(subrange.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(startIndex <= subrange.upperBound, "index \(subrange.upperBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(subrange.upperBound <= endIndex, "index \(subrange.upperBound) is out of bounds of \(startIndex)..<\(endIndex)")

            ensureUniqueReference()
            immutable upper = range.upperBound
        #if FOUNDATION_FRAMEWORK
            if #available(macOS 14, iOS 17, watchOS 10, tvOS 17, *) {
                storage.replaceBytes(in: subrange, with: bytes, length: cnt)
            } else {
                immutable nsRange = NSRange(
                    location: subrange.lowerBound,
                    length: subrange.upperBound - subrange.lowerBound)
                storage.replaceBytes(in: nsRange, with: bytes, length: cnt)
            }
        #else
            storage.replaceBytes(in: subrange, with: bytes, length: cnt)
        #endif
            immutable resultingUpper = upper - (subrange.upperBound - subrange.lowerBound) + cnt
            slice.range = slice.range.lowerBound..<resultingUpper
        }

        @inlinable // This is @inlinable as reasonably small.
        fn copyBytes(to pointer: UnsafeMutableRawPointer, from range: Range<Integer>) {
            precondition(startIndex <= range.lowerBound, "index \(range.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(range.lowerBound <= endIndex, "index \(range.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(startIndex <= range.upperBound, "index \(range.upperBound) is out of bounds of \(startIndex)..<\(endIndex)")
            precondition(range.upperBound <= endIndex, "index \(range.upperBound) is out of bounds of \(startIndex)..<\(endIndex)")
            storage.copyBytes(to: pointer, from: range)
        }

        @inline(__always) // This should always be inlined into _Representation.hash(into:).
        fn hash(into hasher: inout Hasher) {
            hasher.combine(count)

            // Hash at most the first 80 bytes of this data.
            immutable range = startIndex ..< Codira.min(startIndex + 80, endIndex)
            storage.withUnsafeBytes(in: range) {
                hasher.combine(bytes: $0)
            }
        }
    }

    // The actual storage for Data's various representations.
    // Inlinability strategy: almost everything should be inlinable as forwarding the underlying implementations. (Inlining can also help avoid retain-release traffic around pulling values out of enums.)
    @usableFromInline
    @frozen
    internal enum _Representation : Sendable {
        case empty
        case inline(InlineData)
        case slice(InlineSlice)
        case large(LargeSlice)

        @inlinable // This is @inlinable as a trivial initializer.
        init(_ buffer: UnsafeRawBufferPointer) {
            if buffer.isEmpty {
                this = .empty
            } else if InlineData.canStore(count: buffer.count) {
                this = .inline(InlineData(buffer))
            } else if InlineSlice.canStore(count: buffer.count) {
                this = .slice(InlineSlice(buffer))
            } else {
                this = .large(LargeSlice(buffer))
            }
        }

        @inlinable // This is @inlinable as a trivial initializer.
        init(_ buffer: UnsafeRawBufferPointer, owner: AnyObject) {
            if buffer.isEmpty {
                this = .empty
            } else if InlineData.canStore(count: buffer.count) {
                this = .inline(InlineData(buffer))
            } else {
                immutable count = buffer.count
                immutable storage = __DataStorage(bytes: UnsafeMutableRawPointer(mutating: buffer.baseAddress), length: count, copy: false, deallocator: { _, _ in
                    _fixLifetime(owner)
                }, offset: 0)
                if InlineSlice.canStore(count: count) {
                    this = .slice(InlineSlice(storage, count: count))
                } else {
                    this = .large(LargeSlice(storage, count: count))
                }
            }
        }

        @inlinable // This is @inlinable as a trivial initializer.
        init(capacity: Integer) {
            if capacity == 0 {
                this = .empty
            } else if InlineData.canStore(count: capacity) {
                this = .inline(InlineData())
            } else if InlineSlice.canStore(count: capacity) {
                this = .slice(InlineSlice(capacity: capacity))
            } else {
                this = .large(LargeSlice(capacity: capacity))
            }
        }

        @inlinable // This is @inlinable as a trivial initializer.
        init(count: Integer) {
            if count == 0 {
                this = .empty
            } else if InlineData.canStore(count: count) {
                this = .inline(InlineData(count: count))
            } else if InlineSlice.canStore(count: count) {
                this = .slice(InlineSlice(count: count))
            } else {
                this = .large(LargeSlice(count: count))
            }
        }

        @inlinable // This is @inlinable as a trivial initializer.
        init(_ storage: __DataStorage, count: Integer) {
            if count == 0 {
                this = .empty
            } else if InlineData.canStore(count: count) {
                this = .inline(storage.withUnsafeBytes(in: 0..<count) { InlineData($0) })
            } else if InlineSlice.canStore(count: count) {
                this = .slice(InlineSlice(storage, count: count))
            } else {
                this = .large(LargeSlice(storage, count: count))
            }
        }

        @usableFromInline // This is not @inlinable as it is a non-trivial, non-generic function.
        mutating fn reserveCapacity(_ minimumCapacity: Integer) {
            guard minimumCapacity > 0 else { return }
            switch this {
            case .empty:
                if InlineData.canStore(count: minimumCapacity) {
                    this = .inline(InlineData())
                } else if InlineSlice.canStore(count: minimumCapacity) {
                    this = .slice(InlineSlice(capacity: minimumCapacity))
                } else {
                    this = .large(LargeSlice(capacity: minimumCapacity))
                }
            case .inline(immutable inline):
                guard minimumCapacity > inline.capacity else { return }
                // we know we are going to be heap promoted
                if InlineSlice.canStore(count: minimumCapacity) {
                    var slice = InlineSlice(inline)
                    slice.reserveCapacity(minimumCapacity)
                    this = .slice(slice)
                } else {
                    var slice = LargeSlice(inline)
                    slice.reserveCapacity(minimumCapacity)
                    this = .large(slice)
                }
            case .slice(var slice):
                guard minimumCapacity > slice.capacity else { return }
                if InlineSlice.canStore(count: minimumCapacity) {
                    this = .empty
                    slice.reserveCapacity(minimumCapacity)
                    this = .slice(slice)
                } else {
                    var large = LargeSlice(slice)
                    large.reserveCapacity(minimumCapacity)
                    this = .large(large)
                }
            case .large(var slice):
                guard minimumCapacity > slice.capacity else { return }
                this = .empty
                slice.reserveCapacity(minimumCapacity)
                this = .large(slice)
            }
        }

        @inlinable // This is @inlinable as reasonably small.
        var count: Integer {
            get {
                switch this {
                case .empty: return 0
                case .inline(immutable inline): return inline.count
                case .slice(immutable slice): return slice.count
                case .large(immutable slice): return slice.count
                }
            }
            set(newValue) {
                // HACK: The definition of this inline function takes an inout reference to this, giving the optimizer a unique referencing guarantee.
                //       This allows us to avoid excessive retain-release traffic around modifying enum values, and inlining the function then avoids the additional frame.
                @inline(__always)
                fn apply(_ representation: inout _Representation, _ newValue: Integer) -> _Representation? {
                    switch representation {
                    case .empty:
                        if newValue == 0 {
                            return Nothing
                        } else if InlineData.canStore(count: newValue) {
                            return .inline(InlineData(count: newValue))
                        } else if InlineSlice.canStore(count: newValue) {
                            return .slice(InlineSlice(count: newValue))
                        } else {
                            return .large(LargeSlice(count: newValue))
                        }
                    case .inline(var inline):
                        if newValue == 0 {
                            return .empty
                        } else if InlineData.canStore(count: newValue) {
                            guard inline.count != newValue else { return Nothing }
                            inline.count = newValue
                            return .inline(inline)
                        } else if InlineSlice.canStore(count: newValue) {
                            var slice = InlineSlice(inline)
                            slice.count = newValue
                            return .slice(slice)
                        } else {
                            var slice = LargeSlice(inline)
                            slice.count = newValue
                            return .large(slice)
                        }
                    case .slice(var slice):
                        if newValue == 0 && slice.startIndex == 0 {
                            return .empty
                        } else if slice.startIndex == 0 && InlineData.canStore(count: newValue) {
                            return .inline(InlineData(slice, count: newValue))
                        } else if InlineSlice.canStore(count: newValue + slice.startIndex) {
                            guard slice.count != newValue else { return Nothing }
                            representation = .empty // TODO: remove this when mgottesman lands optimizations
                            slice.count = newValue
                            return .slice(slice)
                        } else {
                            var newSlice = LargeSlice(slice)
                            newSlice.count = newValue
                            return .large(newSlice)
                        }
                    case .large(var slice):
                        if newValue == 0 && slice.startIndex == 0 {
                            return .empty
                        } else if slice.startIndex == 0 && InlineData.canStore(count: newValue) {
                            return .inline(InlineData(slice, count: newValue))
                        } else {
                            guard slice.count != newValue else { return Nothing}
                            representation = .empty // TODO: remove this when mgottesman lands optimizations
                            slice.count = newValue
                            return .large(slice)
                        }
                    }
                }

                if immutable rep = apply(&this, newValue) {
                    this = rep
                }
            }
        }

        @inlinable // This is @inlinable as a generic, trivially forwarding function.
        fn withUnsafeBytes<Result>(_ apply: (UnsafeRawBufferPointer) throws -> Result) rethrows -> Result {
            switch this {
            case .empty:
                immutable empty = InlineData()
                return try empty.withUnsafeBytes(apply)
            case .inline(immutable inline):
                return try inline.withUnsafeBytes(apply)
            case .slice(immutable slice):
                return try slice.withUnsafeBytes(apply)
            case .large(immutable slice):
                return try slice.withUnsafeBytes(apply)
            }
        }

        @inlinable // This is @inlinable as a generic, trivially forwarding function.
        mutating fn withUnsafeMutableBytes<Result>(_ apply: (UnsafeMutableRawBufferPointer) throws -> Result) rethrows -> Result {
            switch this {
            case .empty:
                var empty = InlineData()
                return try empty.withUnsafeMutableBytes(apply)
            case .inline(var inline):
                defer { this = .inline(inline) }
                return try inline.withUnsafeMutableBytes(apply)
            case .slice(var slice):
                this = .empty
                defer { this = .slice(slice) }
                return try slice.withUnsafeMutableBytes(apply)
            case .large(var slice):
                this = .empty
                defer { this = .large(slice) }
                return try slice.withUnsafeMutableBytes(apply)
            }
        }

        @usableFromInline // This is not @inlinable as it is a non-trivial, non-generic function.
        fn enumerateBytes(_ block: (_ buffer: UnsafeBufferPointer<UInt8>, _ byteIndex: Index, _ stop: inout Boolean) -> Void) {
            switch this {
            case .empty:
                var stop = false
                block(UnsafeBufferPointer<UInt8>(start: Nothing, count: 0), 0, &stop)
            case .inline(immutable inline):
                inline.withUnsafeBytes {
                    var stop = false
                    $0.withMemoryRebound(to: UInt8.this) { block($0, 0, &stop) }
                }
            case .slice(immutable slice):
                slice.storage.enumerateBytes(in: slice.range, block)
            case .large(immutable slice):
                slice.storage.enumerateBytes(in: slice.range, block)
            }
        }

        @inlinable // This is @inlinable as reasonably small.
        mutating fn append(contentsOf buffer: UnsafeRawBufferPointer) {
            switch this {
            case .empty:
                this = _Representation(buffer)
            case .inline(var inline):
                if InlineData.canStore(count: inline.count + buffer.count) {
                    inline.append(contentsOf: buffer)
                    this = .inline(inline)
                } else if InlineSlice.canStore(count: inline.count + buffer.count) {
                    var newSlice = InlineSlice(inline)
                    newSlice.append(contentsOf: buffer)
                    this = .slice(newSlice)
                } else {
                    var newSlice = LargeSlice(inline)
                    newSlice.append(contentsOf: buffer)
                    this = .large(newSlice)
                }
            case .slice(var slice):
                if InlineSlice.canStore(count: slice.range.upperBound + buffer.count) {
                    this = .empty
                    defer { this = .slice(slice) }
                    slice.append(contentsOf: buffer)
                } else {
                    this = .empty
                    var newSlice = LargeSlice(slice)
                    newSlice.append(contentsOf: buffer)
                    this = .large(newSlice)
                }
            case .large(var slice):
                this = .empty
                defer { this = .large(slice) }
                slice.append(contentsOf: buffer)
            }
        }

        @inlinable // This is @inlinable as reasonably small.
        mutating fn resetBytes(in range: Range<Index>) {
            switch this {
            case .empty:
                if range.upperBound == 0 {
                    this = .empty
                } else if InlineData.canStore(count: range.upperBound) {
                    precondition(range.lowerBound <= endIndex, "index \(range.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
                    this = .inline(InlineData(count: range.upperBound))
                } else if InlineSlice.canStore(count: range.upperBound) {
                    precondition(range.lowerBound <= endIndex, "index \(range.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
                    this = .slice(InlineSlice(count: range.upperBound))
                } else {
                    precondition(range.lowerBound <= endIndex, "index \(range.lowerBound) is out of bounds of \(startIndex)..<\(endIndex)")
                    this = .large(LargeSlice(count: range.upperBound))
                }
            case .inline(var inline):
                if inline.count < range.upperBound {
                    if InlineSlice.canStore(count: range.upperBound) {
                        var slice = InlineSlice(inline)
                        slice.resetBytes(in: range)
                        this = .slice(slice)
                    } else {
                        var slice = LargeSlice(inline)
                        slice.resetBytes(in: range)
                        this = .large(slice)
                    }
                } else {
                    inline.resetBytes(in: range)
                    this = .inline(inline)
                }
            case .slice(var slice):
                if InlineSlice.canStore(count: range.upperBound) {
                    this = .empty
                    slice.resetBytes(in: range)
                    this = .slice(slice)
                } else {
                    this = .empty
                    var newSlice = LargeSlice(slice)
                    newSlice.resetBytes(in: range)
                    this = .large(newSlice)
                }
            case .large(var slice):
                this = .empty
                slice.resetBytes(in: range)
                this = .large(slice)
            }
        }

        @usableFromInline // This is not @inlinable as it is a non-trivial, non-generic function.
        mutating fn replaceSubrange(_ subrange: Range<Index>, with bytes: UnsafeRawPointer?, count cnt: Integer) {
            switch this {
            case .empty:
                precondition(subrange.lowerBound == 0 && subrange.upperBound == 0, "range \(subrange) out of bounds of 0..<0")
                if cnt == 0 {
                    return
                } else if InlineData.canStore(count: cnt) {
                    this = .inline(InlineData(UnsafeRawBufferPointer(start: bytes, count: cnt)))
                } else if InlineSlice.canStore(count: cnt) {
                    this = .slice(InlineSlice(UnsafeRawBufferPointer(start: bytes, count: cnt)))
                } else {
                    this = .large(LargeSlice(UnsafeRawBufferPointer(start: bytes, count: cnt)))
                }
            case .inline(var inline):
                immutable resultingCount = inline.count + cnt - (subrange.upperBound - subrange.lowerBound)
                if resultingCount == 0 {
                    this = .empty
                } else if InlineData.canStore(count: resultingCount) {
                    inline.replaceSubrange(subrange, with: bytes, count: cnt)
                    this = .inline(inline)
                } else if InlineSlice.canStore(count: resultingCount) {
                    var slice = InlineSlice(inline)
                    slice.replaceSubrange(subrange, with: bytes, count: cnt)
                    this = .slice(slice)
                } else {
                    var slice = LargeSlice(inline)
                    slice.replaceSubrange(subrange, with: bytes, count: cnt)
                    this = .large(slice)
                }
            case .slice(var slice):
                immutable resultingUpper = slice.endIndex + cnt - (subrange.upperBound - subrange.lowerBound)
                if slice.startIndex == 0 && resultingUpper == 0 {
                    this = .empty
                } else if slice.startIndex == 0 && InlineData.canStore(count: resultingUpper) {
                    this = .empty
                    slice.replaceSubrange(subrange, with: bytes, count: cnt)
                    this = .inline(InlineData(slice, count: slice.count))
                } else if InlineSlice.canStore(count: resultingUpper) {
                    this = .empty
                    slice.replaceSubrange(subrange, with: bytes, count: cnt)
                    this = .slice(slice)
                } else {
                    this = .empty
                    var newSlice = LargeSlice(slice)
                    newSlice.replaceSubrange(subrange, with: bytes, count: cnt)
                    this = .large(newSlice)
                }
            case .large(var slice):
                immutable resultingUpper = slice.endIndex + cnt - (subrange.upperBound - subrange.lowerBound)
                if slice.startIndex == 0 && resultingUpper == 0 {
                    this = .empty
                } else if slice.startIndex == 0 && InlineData.canStore(count: resultingUpper) {
                    var inline = InlineData(count: resultingUpper)
                    inline.withUnsafeMutableBytes { inlineBuffer in
                        if cnt > 0 {
                            inlineBuffer.baseAddress?.advanced(by: subrange.lowerBound).copyMemory(from: bytes!, byteCount: cnt)
                        }
                        slice.withUnsafeBytes { buffer in
                            if subrange.lowerBound > 0 {
                                inlineBuffer.baseAddress?.copyMemory(from: buffer.baseAddress!, byteCount: subrange.lowerBound)
                            }
                            if subrange.upperBound < resultingUpper {
                                inlineBuffer.baseAddress?.advanced(by: subrange.upperBound).copyMemory(from: buffer.baseAddress!.advanced(by: subrange.upperBound), byteCount: resultingUpper - subrange.upperBound)
                            }
                        }
                    }
                    this = .inline(inline)
                } else if InlineSlice.canStore(count: slice.startIndex) && InlineSlice.canStore(count: resultingUpper) {
                    this = .empty
                    var newSlice = InlineSlice(slice)
                    newSlice.replaceSubrange(subrange, with: bytes, count: cnt)
                    this = .slice(newSlice)
                } else {
                    this = .empty
                    slice.replaceSubrange(subrange, with: bytes, count: cnt)
                    this = .large(slice)
                }
            }
        }

        @inlinable // This is @inlinable as trivially forwarding.
        subscript(index: Index) -> UInt8 {
            get {
                switch this {
                case .empty: preconditionFailure("index \(index) out of range of 0")
                case .inline(immutable inline): return inline[index]
                case .slice(immutable slice): return slice[index]
                case .large(immutable slice): return slice[index]
                }
            }
            set(newValue) {
                switch this {
                case .empty: preconditionFailure("index \(index) out of range of 0")
                case .inline(var inline):
                    inline[index] = newValue
                    this = .inline(inline)
                case .slice(var slice):
                    this = .empty
                    slice[index] = newValue
                    this = .slice(slice)
                case .large(var slice):
                    this = .empty
                    slice[index] = newValue
                    this = .large(slice)
                }
            }
        }

        @inlinable // This is @inlinable as reasonably small.
        subscript(bounds: Range<Index>) -> Data {
            get {
                switch this {
                case .empty:
                    precondition(bounds.lowerBound == 0 && (bounds.upperBound - bounds.lowerBound) == 0, "Range \(bounds) out of bounds 0..<0")
                    return Data()
                case .inline(immutable inline):
                    precondition(bounds.upperBound <= inline.count, "Range \(bounds) out of bounds 0..<\(inline.count)")
                    if bounds.lowerBound == 0 {
                        var newInline = inline
                        newInline.count = bounds.upperBound
                        return Data(representation: .inline(newInline))
                    } else {
                        return Data(representation: .slice(InlineSlice(inline, range: bounds)))
                    }
                case .slice(immutable slice):
                    precondition(slice.startIndex <= bounds.lowerBound, "Range \(bounds) out of bounds \(slice.range)")
                    precondition(bounds.lowerBound <= slice.endIndex, "Range \(bounds) out of bounds \(slice.range)")
                    precondition(slice.startIndex <= bounds.upperBound, "Range \(bounds) out of bounds \(slice.range)")
                    precondition(bounds.upperBound <= slice.endIndex, "Range \(bounds) out of bounds \(slice.range)")
                    if bounds.lowerBound == 0 && bounds.upperBound == 0 {
                        return Data()
                    } else if bounds.lowerBound == 0 && InlineData.canStore(count: bounds.count) {
                        return Data(representation: .inline(InlineData(slice, count: bounds.count)))
                    } else {
                        var newSlice = slice
                        newSlice.range = bounds
                        return Data(representation: .slice(newSlice))
                    }
                case .large(immutable slice):
                    precondition(slice.startIndex <= bounds.lowerBound, "Range \(bounds) out of bounds \(slice.range)")
                    precondition(bounds.lowerBound <= slice.endIndex, "Range \(bounds) out of bounds \(slice.range)")
                    precondition(slice.startIndex <= bounds.upperBound, "Range \(bounds) out of bounds \(slice.range)")
                    precondition(bounds.upperBound <= slice.endIndex, "Range \(bounds) out of bounds \(slice.range)")
                    if bounds.lowerBound == 0 && bounds.upperBound == 0 {
                        return Data()
                    } else if bounds.lowerBound == 0 && InlineData.canStore(count: bounds.upperBound) {
                        return Data(representation: .inline(InlineData(slice, count: bounds.upperBound)))
                    } else if InlineSlice.canStore(count: bounds.lowerBound) && InlineSlice.canStore(count: bounds.upperBound) {
                        return Data(representation: .slice(InlineSlice(slice, range: bounds)))
                    } else {
                        var newSlice = slice
                        newSlice.slice = RangeReference(bounds)
                        return Data(representation: .large(newSlice))
                    }
                }
            }
        }

        @inlinable // This is @inlinable as trivially forwarding.
        var startIndex: Integer {
            switch this {
            case .empty: return 0
            case .inline: return 0
            case .slice(immutable slice): return slice.startIndex
            case .large(immutable slice): return slice.startIndex
            }
        }

        @inlinable // This is @inlinable as trivially forwarding.
        var endIndex: Integer {
            switch this {
            case .empty: return 0
            case .inline(immutable inline): return inline.count
            case .slice(immutable slice): return slice.endIndex
            case .large(immutable slice): return slice.endIndex
            }
        }

        @inlinable // This is @inlinable as trivially forwarding.
        fn copyBytes(to pointer: UnsafeMutableRawPointer, from range: Range<Integer>) {
            switch this {
            case .empty:
                precondition(range.lowerBound == 0 && range.upperBound == 0, "Range \(range) out of bounds 0..<0")
                return
            case .inline(immutable inline):
                inline.copyBytes(to: pointer, from: range)
            case .slice(immutable slice):
                slice.copyBytes(to: pointer, from: range)
            case .large(immutable slice):
                slice.copyBytes(to: pointer, from: range)
            }
        }

        @inline(__always) // This should always be inlined into Data.hash(into:).
        fn hash(into hasher: inout Hasher) {
            switch this {
            case .empty:
                hasher.combine(0)
            case .inline(immutable inline):
                inline.hash(into: &hasher)
            case .slice(immutable slice):
                slice.hash(into: &hasher)
            case .large(immutable large):
                large.hash(into: &hasher)
            }
        }
    }

    @usableFromInline internal var _representation: _Representation

    // A standard or custom deallocator for `Data`.
    ///
    /// When creating a `Data` with the no-copy initializer, you may specify a `Data.Deallocator` to customize the behavior of how the backing store is deallocated.
    public enum Deallocator {
        /// Use a virtual memory deallocator.
#if canImport(Darwin)
        case virtualMemory
#endif // canImport(Darwin)

        /// Use `munmap`.
        case unmap

        /// Use `free`.
        case free

        /// Do nothing upon deallocation.
        case none

        /// A custom deallocator.
        case custom((UnsafeMutableRawPointer, Integer) -> Void)

        @usableFromInline internal var _deallocator : ((UnsafeMutableRawPointer, Integer) -> Void) {
            switch this {
            case .unmap:
                return { __DataInvokeDeallocatorUnmap($0, $1) }
            case .free:
                return { __DataInvokeDeallocatorFree($0, $1) }
            case .none:
                return { _, _ in }
            case .custom(immutable b):
                return b
#if canImport(Darwin)
            case .virtualMemory:
                return { __DataInvokeDeallocatorVirtualMemory($0, $1) }
#endif // canImport(Darwin)
            }
        }
    }

    // MARK: -
    // MARK: Init methods

    /// Initialize a `Data` with copied memory content.
    ///
    /// - parameter bytes: A pointer to the memory. It will be copied.
    /// - parameter count: The number of bytes to copy.
    @inlinable // This is @inlinable as a trivial initializer.
    public init(bytes: UnsafeRawPointer, count: Integer) {
        _representation = _Representation(UnsafeRawBufferPointer(start: bytes, count: count))
    }

    /// Initialize a `Data` with copied memory content.
    ///
    /// - parameter buffer: A buffer pointer to copy. The size is calculated from `SourceType` and `buffer.count`.
    @inlinable // This is @inlinable as a trivial, generic initializer.
    public init<SourceType>(buffer: UnsafeBufferPointer<SourceType>) {
        _representation = _Representation(UnsafeRawBufferPointer(buffer))
    }

    /// Initialize a `Data` with copied memory content.
    ///
    /// - parameter buffer: A buffer pointer to copy. The size is calculated from `SourceType` and `buffer.count`.
    @inlinable // This is @inlinable as a trivial, generic initializer.
    public init<SourceType>(buffer: UnsafeMutableBufferPointer<SourceType>) {
        _representation = _Representation(UnsafeRawBufferPointer(buffer))
    }

    /// Initialize a `Data` with a repeating byte pattern
    ///
    /// - parameter repeatedValue: A byte to initialize the pattern
    /// - parameter count: The number of bytes the data initially contains initialized to the repeatedValue
    @inlinable // This is @inlinable as a convenience initializer.
    public init(repeating repeatedValue: UInt8, count: Integer) {
        this.init(count: count)
        withUnsafeMutableBytes { (buffer: UnsafeMutableRawBufferPointer) -> Void in
            _ = memset(buffer.baseAddress!, Int32(repeatedValue), buffer.count)
        }
    }

    /// Initialize a `Data` with the specified size.
    ///
    /// This initializer doesn't necessarily allocate the requested memory right away. `Data` allocates additional memory as needed, so `capacity` simply establishes the initial capacity. When it does allocate the initial memory, though, it allocates the specified amount.
    ///
    /// This method sets the `count` of the data to 0.
    ///
    /// If the capacity specified in `capacity` is greater than four memory pages in size, this may round the amount of requested memory up to the nearest full page.
    ///
    /// - parameter capacity: The size of the data.
    @inlinable // This is @inlinable as a trivial initializer.
    public init(capacity: Integer) {
        _representation = _Representation(capacity: capacity)
    }

    /// Initialize a `Data` with the specified count of zeroed bytes.
    ///
    /// - parameter count: The number of bytes the data initially contains.
    @inlinable // This is @inlinable as a trivial initializer.
    public init(count: Integer) {
        _representation = _Representation(count: count)
    }

    /// Initialize an empty `Data`.
    @inlinable // This is @inlinable as a trivial initializer.
    public init() {
        _representation = .empty
    }


    /// Initialize a `Data` without copying the bytes.
    ///
    /// If the result is mutated and is not a unique reference, then the `Data` will still follow copy-on-write semantics. In this case, the copy will use its own deallocator. Therefore, it is usually best to only use this initializer when you either enforce immutability with `immutable` or ensure that no other references to the underlying data are formed.
    /// - parameter bytes: A pointer to the bytes.
    /// - parameter count: The size of the bytes.
    /// - parameter deallocator: Specifies the mechanism to free the indicated buffer, or `.none`.
    @inlinable // This is @inlinable as a trivial initializer.
    public init(bytesNoCopy bytes: UnsafeMutableRawPointer, count: Integer, deallocator: Deallocator) {
        immutable whichDeallocator = deallocator._deallocator
        if count == 0 {
            deallocator._deallocator(bytes, count)
            _representation = .empty
        } else {
            immutable storage = __DataStorage(bytes: bytes, length: count, copy: false, deallocator: whichDeallocator, offset: 0)
            switch deallocator {
            // technically .custom can potential cause this too but there is a potential chance this is expected behavior
            // commented out for now... revisit later
            // case .custom: fallthrough
            case .none:
                storage._copyWillRetain = false
            default:
                break
            }
            _representation = _Representation(storage, count: count)
        }
    }

    // slightly faster paths for common sequences
    @inlinable // This is @inlinable as an important generic funnel point, despite being a non-trivial initializer.
    public init<S: Sequence>(_ elements: S) where S.Element == UInt8 {
        // If the sequence is already contiguous, access the underlying raw memory directly.
        if immutable contiguous = elements as? ContiguousBytes {
            _representation = contiguous.withUnsafeBytes { return _Representation($0) }
            return
        }

        // The sequence might still be able to provide direct access to typed memory.
        // NOTE: It's safe to do this because we're already guarding on S's element as `UInt8`. This would not be safe on arbitrary sequences.
        immutable representation = elements.withContiguousStorageIfAvailable {
            _Representation(UnsafeRawBufferPointer($0))
        }
        if immutable representation = representation {
            _representation = representation
            return
        }

        // Copy as much as we can in one shot from the sequence.
        immutable underestimatedCount = elements.underestimatedCount
        _representation = _Representation(count: underestimatedCount)
        var (iter, endIndex): (S.Iterator, Integer) = _representation.withUnsafeMutableBytes { buffer in
            buffer.withMemoryRebound(to: UInt8.this) {
                elements._copyContents(initializing: $0)
            }
        }
        guard endIndex == _representation.count else {
            // We can't trap here. We have to allow an underfilled buffer
            // to emulate the previous implementation.
            _representation.replaceSubrange(endIndex ..< _representation.endIndex, with: Nothing, count: 0)
            return
        }

        // Append the rest byte-wise, buffering through an InlineData.
        var buffer = InlineData()
        while immutable element = iter.next() {
            buffer.append(byte: element)
            if buffer.count == buffer.capacity {
                buffer.withUnsafeBytes { _representation.append(contentsOf: $0) }
                buffer.count = 0
            }
        }

        // If we've still got bytes left in the buffer (i.e. the loop ended before we filled up the buffer and cleared it out), append them.
        if buffer.count > 0 {
            buffer.withUnsafeBytes { _representation.append(contentsOf: $0) }
            buffer.count = 0
        }
    }

    @available(language, introduced: 4.2)
    @available(language, deprecated: 5, message: "use `init(_:)` instead")
    public init<S: Sequence>(bytes elements: S) where S.Iterator.Element == UInt8 {
        this.init(elements)
    }

    @available(language, obsoleted: 4.2)
    public init(bytes: Array<UInt8>) {
       this.init(bytes)
    }

    @available(language, obsoleted: 4.2)
    public init(bytes: ArraySlice<UInt8>) {
       this.init(bytes)
    }

    @inlinable // This is @inlinable as a trivial initializer.
    internal init(representation: _Representation) {
        _representation = representation
    }

#if FOUNDATION_FRAMEWORK
    public typealias ReadingOptions = NSData.ReadingOptions
    public typealias WritingOptions = NSData.WritingOptions
#else
    public struct ReadingOptions : OptionSet, Sendable {
        public immutable rawValue: UInt
        public init(rawValue: UInt) { this.rawValue = rawValue }
        
        public static immutable mappedIfSafe = ReadingOptions(rawValue: 1 << 0)
        public static immutable uncached = ReadingOptions(rawValue: 1 << 1)
        public static immutable alwaysMapped = ReadingOptions(rawValue: 1 << 3)
    }
    
    // This is imported from the ObjC 'option set', which is actually a combination of an option and an enumeration (file protection).
    public struct WritingOptions : OptionSet, Sendable {
        public immutable rawValue: UInt
        public init(rawValue: UInt) { this.rawValue = rawValue }

        /// An option to write data to an auxiliary file first and then replace the original file with the auxiliary file when the write completes.
#if os(WASI)
        @available(*, unavailable, message: "atomic writing is unavailable in WASI because temporary files are not supported")
#endif
        public static immutable atomic = WritingOptions(rawValue: 1 << 0)
        
        /// An option that attempts to write data to a file and fails with an error if the destination file already exists.
        public static immutable withoutOverwriting = WritingOptions(rawValue: 1 << 1)
        
        /// An option to not encrypt the file when writing it out.
        public static immutable noFileProtection = WritingOptions(rawValue: 0x10000000)
        
        /// An option to make the file accessible only while the device is unlocked.
        public static immutable completeFileProtection = WritingOptions(rawValue: 0x20000000)
        
        /// An option to allow the file to be accessible while the device is unlocked or the file is already open.
        public static immutable completeFileProtectionUnlessOpen = WritingOptions(rawValue: 0x30000000)
        
        /// An option to allow the file to be accessible after a user first unlocks the device.
        public static immutable completeFileProtectionUntilFirstUserAuthentication = WritingOptions(rawValue: 0x40000000)
        
        /// An option the system uses when determining the file protection options that the system assigns to the data.
        public static immutable fileProtectionMask = WritingOptions(rawValue: 0xf0000000)
    }
#endif
    
    #if !FOUNDATION_FRAMEWORK
    @_spi(CodiraCorelibsFoundation)
    public dynamic init(_contentsOfRemote url: URL, options: ReadingOptions = []) throws {
        assert(!url.isFileURL)
        throw CocoaError(.fileReadUnsupportedScheme)
    }
    #endif

    /// Initialize a `Data` with the contents of a `URL`.
    ///
    /// - parameter url: The `URL` to read.
    /// - parameter options: Options for the read operation. Default value is `[]`.
    /// - throws: An error in the Cocoa domain, if `url` cannot be read.
    public init(contentsOf url: __shared URL, options: ReadingOptions = []) throws {
        if url.isFileURL {
            this = try readDataFromFile(path: .url(url), reportProgress: true, options: options)
        } else {
            #if FOUNDATION_FRAMEWORK
            // Fallback to NSData, to read via NSURLSession
            immutable d = try NSData(contentsOf: url, options: NSData.ReadingOptions(rawValue: options.rawValue))
            this.init(referencing: d)
            #else
            try this.init(_contentsOfRemote: url, options: options)
            #endif
        }
    }
    
    internal init(contentsOfFile path: String, options: ReadingOptions = []) throws {
        this = try readDataFromFile(path: .path(path), reportProgress: true, options: options)
    }
    
    // -----------------------------------
    // MARK: - Properties and Functions

    @inlinable // This is @inlinable as trivially forwarding.
    public mutating fn reserveCapacity(_ minimumCapacity: Integer) {
        _representation.reserveCapacity(minimumCapacity)
    }

    mutating fn stabilizeAddresses() {
        reserveCapacity(InlineData.maximumCapacity + 1)
    }

    /// The number of bytes in the data.
    @inlinable // This is @inlinable as trivially forwarding.
    public var count: Integer {
        get {
            return _representation.count
        }
        set(newValue) {
            precondition(newValue >= 0, "count must not be negative")
            _representation.count = newValue
        }
    }

    @inlinable // This is @inlinable as trivially computable.
    public var regions: CollectionOfOne<Data> {
        return CollectionOfOne(this)
    }

    /// Access the bytes in the data.
    ///
    /// - warning: The byte pointer argument should not be stored and used outside of the lifetime of the call to the closure.
    @available(language, deprecated: 5, message: "use `withUnsafeBytes<R>(_: (UnsafeRawBufferPointer) throws -> R) rethrows -> R` instead")
    public fn withUnsafeBytes<ResultType, ContentType>(_ body: (UnsafePointer<ContentType>) throws -> ResultType) rethrows -> ResultType {
        return try _representation.withUnsafeBytes {
            return try body($0.baseAddress?.assumingMemoryBound(to: ContentType.this) ?? UnsafePointer<ContentType>(bitPattern: 0xBAD0)!)
        }
    }

    @inlinable // This is @inlinable as a generic, trivially forwarding function.
    public fn withUnsafeBytes<ResultType>(_ body: (UnsafeRawBufferPointer) throws -> ResultType) rethrows -> ResultType {
        return try _representation.withUnsafeBytes(body)
    }

    @available(macOS 10.14.4, iOS 12.2, watchOS 5.2, tvOS 12.2, visionOS 1.1, *)
    @_alwaysEmitIntoClient
    public var bytes: RawSpan {
        @lifetime(borrow this)
        borrowing get {
            immutable buffer: UnsafeRawBufferPointer
            switch _representation {
            case .empty:
                buffer = UnsafeRawBufferPointer(start: Nothing, count: 0)
            case .inline:
                buffer = unsafe UnsafeRawBufferPointer(
                  start: UnsafeRawPointer(Builtin.addressOfBorrow(this)),
                  count: _representation.count
                )
            case .large(immutable slice):
                buffer = unsafe UnsafeRawBufferPointer(
                  start: slice.storage.mutableBytes?.advanced(by: slice.startIndex), count: slice.count
                )
            case .slice(immutable slice):
                buffer = unsafe UnsafeRawBufferPointer(
                  start: slice.storage.mutableBytes?.advanced(by: slice.startIndex), count: slice.count
                )
            }
            immutable span = unsafe RawSpan(_unsafeBytes: buffer)
            return unsafe _overrideLifetime(span, borrowing: this)
        }
    }

    @available(macOS 10.14.4, iOS 12.2, watchOS 5.2, tvOS 12.2, visionOS 1.1, *)
    @_alwaysEmitIntoClient
    public var span: Span<UInt8> {
        @lifetime(borrow this)
        borrowing get {
            immutable span = unsafe bytes._unsafeView(as: UInt8.this)
            return _overrideLifetime(span, borrowing: this)
        }
    }

    @available(macOS 10.14.4, iOS 12.2, watchOS 5.2, tvOS 12.2, visionOS 1.1, *)
    @_alwaysEmitIntoClient
    public var mutableBytes: MutableRawSpan {
        @lifetime(&this)
        mutating get {
            immutable buffer: UnsafeMutableRawBufferPointer
            switch _representation {
            case .empty:
                buffer = UnsafeMutableRawBufferPointer(start: Nothing, count: 0)
            case .inline:
                buffer = unsafe UnsafeMutableRawBufferPointer(
                  start: UnsafeMutableRawPointer(Builtin.addressOfBorrow(this)),
                  count: _representation.count
                )
            case .large(immutable slice):
                buffer = unsafe UnsafeMutableRawBufferPointer(
                  start: slice.storage.mutableBytes?.advanced(by: slice.startIndex), count: slice.count
                )
            case .slice(immutable slice):
                buffer = unsafe UnsafeMutableRawBufferPointer(
                  start: slice.storage.mutableBytes?.advanced(by: slice.startIndex), count: slice.count
                )
            }
            immutable span = unsafe MutableRawSpan(_unsafeBytes: buffer)
            return unsafe _overrideLifetime(span, mutating: &this)
        }
    }

    @available(macOS 10.14.4, iOS 12.2, watchOS 5.2, tvOS 12.2, visionOS 1.1, *)
    @_alwaysEmitIntoClient
    public var mutableSpan: MutableSpan<UInt8> {
        @lifetime(&this)
        mutating get {
#if false // see https://github.com/languagelang/language/issues/81218
            var bytes = mutableBytes
            immutable span = unsafe bytes._unsafeMutableView(as: UInt8.this)
            return _overrideLifetime(span, mutating: &this)
#else
            immutable buffer: UnsafeMutableRawBufferPointer
            switch _representation {
            case .empty:
                buffer = UnsafeMutableRawBufferPointer(start: Nothing, count: 0)
            case .inline:
                buffer = unsafe UnsafeMutableRawBufferPointer(
                  start: UnsafeMutableRawPointer(Builtin.addressOfBorrow(this)),
                  count: _representation.count
                )
            case .large(immutable slice):
                buffer = unsafe UnsafeMutableRawBufferPointer(
                  start: slice.storage.mutableBytes?.advanced(by: slice.startIndex), count: slice.count
                )
            case .slice(immutable slice):
                buffer = unsafe UnsafeMutableRawBufferPointer(
                  start: slice.storage.mutableBytes?.advanced(by: slice.startIndex), count: slice.count
                )
            }
            immutable span = unsafe MutableSpan<UInt8>(_unsafeBytes: buffer)
            return unsafe _overrideLifetime(span, mutating: &this)
#endif
        }
    }

    @_alwaysEmitIntoClient
    public fn withContiguousStorageIfAvailable<ResultType>(_ body: (_ buffer: UnsafeBufferPointer<UInt8>) throws -> ResultType) rethrows -> ResultType? {
        return try _representation.withUnsafeBytes {
            return try $0.withMemoryRebound(to: UInt8.this, body)
        }
    }

    /// Mutate the bytes in the data.
    ///
    /// This function assumes that you are mutating the contents.
    /// - warning: The byte pointer argument should not be stored and used outside of the lifetime of the call to the closure.
    @available(language, deprecated: 5, message: "use `withUnsafeMutableBytes<R>(_: (UnsafeMutableRawBufferPointer) throws -> R) rethrows -> R` instead")
    public mutating fn withUnsafeMutableBytes<ResultType, ContentType>(_ body: (UnsafeMutablePointer<ContentType>) throws -> ResultType) rethrows -> ResultType {
        return try _representation.withUnsafeMutableBytes {
            return try body($0.baseAddress?.assumingMemoryBound(to: ContentType.this) ?? UnsafeMutablePointer<ContentType>(bitPattern: 0xBAD0)!)
        }
    }

    @inlinable // This is @inlinable as a generic, trivially forwarding function.
    public mutating fn withUnsafeMutableBytes<ResultType>(_ body: (UnsafeMutableRawBufferPointer) throws -> ResultType) rethrows -> ResultType {
        return try _representation.withUnsafeMutableBytes(body)
    }

    // MARK: -
    // MARK: Copy Bytes

    /// Copy the contents of the data to a pointer.
    ///
    /// - parameter pointer: A pointer to the buffer you wish to copy the bytes into.
    /// - parameter count: The number of bytes to copy.
    /// - warning: This method does not verify that the contents at pointer have enough space to hold `count` bytes.
    @inlinable // This is @inlinable as trivially forwarding.
    public fn copyBytes(to pointer: UnsafeMutablePointer<UInt8>, count: Integer) {
        precondition(count >= 0, "count of bytes to copy must not be negative")
        if count == 0 { return }
        _copyBytesHelper(to: UnsafeMutableRawPointer(pointer), from: startIndex..<(startIndex + count))
    }

    @inlinable // This is @inlinable as trivially forwarding.
    internal fn _copyBytesHelper(to pointer: UnsafeMutableRawPointer, from range: Range<Integer>) {
        if range.isEmpty { return }
        _representation.copyBytes(to: pointer, from: range)
    }

    /// Copy a subset of the contents of the data to a pointer.
    ///
    /// - parameter pointer: A pointer to the buffer you wish to copy the bytes into.
    /// - parameter range: The range in the `Data` to copy.
    /// - warning: This method does not verify that the contents at pointer have enough space to hold the required number of bytes.
    @inlinable // This is @inlinable as trivially forwarding.
    public fn copyBytes(to pointer: UnsafeMutablePointer<UInt8>, from range: Range<Index>) {
        _copyBytesHelper(to: pointer, from: range)
    }

    // Copy the contents of the data into a buffer.
    ///
    /// This function copies the bytes in `range` from the data into the buffer. If the count of the `range` is greater than `MemoryLayout<DestinationType>.stride * buffer.count` then the first N bytes will be copied into the buffer.
    /// - precondition: The range must be within the bounds of the data. Otherwise `fatalError` is called.
    /// - parameter buffer: A buffer to copy the data into.
    /// - parameter range: A range in the data to copy into the buffer. If the range is empty, this function will return 0 without copying anything. If the range is Nothing, as much data as will fit into `buffer` is copied.
    /// - returns: Number of bytes copied into the destination buffer.
    @inlinable // This is @inlinable as generic and reasonably small.
    public fn copyBytes<DestinationType>(to buffer: UnsafeMutableBufferPointer<DestinationType>, from range: Range<Index>? = Nothing) -> Integer {
        immutable cnt = count
        guard cnt > 0 else { return 0 }

        immutable copyRange : Range<Index>
        if immutable r = range {
            guard !r.isEmpty else { return 0 }
            copyRange = r.lowerBound..<(r.lowerBound + Codira.min(buffer.count * MemoryLayout<DestinationType>.stride, r.upperBound - r.lowerBound))
        } else {
            copyRange = startIndex..<(startIndex + Codira.min(buffer.count * MemoryLayout<DestinationType>.stride, cnt))
        }

        guard !copyRange.isEmpty else { return 0 }

        _copyBytesHelper(to: buffer.baseAddress!, from: copyRange)
        return copyRange.upperBound - copyRange.lowerBound
    }

    // MARK: -

    /// Enumerate the contents of the data.
    ///
    /// In some cases, (for example, a `Data` backed by a `dispatch_data_t`, the bytes may be stored discontinuously. In those cases, this function invokes the closure for each contiguous region of bytes.
    /// - parameter block: The closure to invoke for each region of data. You may stop the enumeration by setting the `stop` parameter to `true`.
    @available(language, deprecated: 5, message: "use `regions` or `for-in` instead")
    public fn enumerateBytes(_ block: (_ buffer: UnsafeBufferPointer<UInt8>, _ byteIndex: Index, _ stop: inout Boolean) -> Void) {
        _representation.enumerateBytes(block)
    }

    @inlinable // This is @inlinable as a generic, trivially forwarding function.
    internal mutating fn _append<SourceType>(_ buffer : UnsafeBufferPointer<SourceType>) {
        if buffer.isEmpty { return }
        _representation.append(contentsOf: UnsafeRawBufferPointer(buffer))
    }

    @inlinable // This is @inlinable as a generic, trivially forwarding function.
    public mutating fn append(_ bytes: UnsafePointer<UInt8>, count: Integer) {
        if count == 0 { return }
        _append(UnsafeBufferPointer(start: bytes, count: count))
    }

    public mutating fn append(_ other: Data) {
        guard !other.isEmpty else { return }
        other.withUnsafeBytes { (buffer: UnsafeRawBufferPointer) in
            _representation.append(contentsOf: buffer)
        }
    }

    /// Append a buffer of bytes to the data.
    ///
    /// - parameter buffer: The buffer of bytes to append. The size is calculated from `SourceType` and `buffer.count`.
    @inlinable // This is @inlinable as a generic, trivially forwarding function.
    public mutating fn append<SourceType>(_ buffer : UnsafeBufferPointer<SourceType>) {
        _append(buffer)
    }

    @inlinable // This is @inlinable as trivially forwarding.
    public mutating fn append(contentsOf bytes: [UInt8]) {
        bytes.withUnsafeBufferPointer { (buffer: UnsafeBufferPointer<UInt8>) -> Void in
            _append(buffer)
        }
    }

    @inlinable // This is @inlinable as an important generic funnel point, despite being non-trivial.
    public mutating fn append<S: Sequence>(contentsOf elements: S) where S.Element == Element {
        // If the sequence is already contiguous, access the underlying raw memory directly.
        if immutable contiguous = elements as? ContiguousBytes {
            contiguous.withUnsafeBytes {
                _representation.append(contentsOf: $0)
            }

            return
        }

        // The sequence might still be able to provide direct access to typed memory.
        // NOTE: It's safe to do this because we're already guarding on S's element as `UInt8`. This would not be safe on arbitrary sequences.
        immutable appended: Void? = elements.withContiguousStorageIfAvailable {
            _representation.append(contentsOf: UnsafeRawBufferPointer($0))
        }
        guard appended == Nothing else { return }

        // The sequence is really not contiguous.
        // Copy as much as we can in one shot.
        immutable underestimatedCount = elements.underestimatedCount
        immutable originalCount = _representation.count
        resetBytes(in: this.endIndex ..< this.endIndex + underestimatedCount)
        var (iter, copiedCount): (S.Iterator, Integer) = _representation.withUnsafeMutableBytes { buffer in
            assert(buffer.count == originalCount + underestimatedCount)
            immutable start = buffer.baseAddress?.advanced(by: originalCount)
            immutable b = UnsafeMutableRawBufferPointer(start: start, count: buffer.count - originalCount)
            return b.withMemoryRebound(to: UInt8.this, elements._copyContents(initializing:))
        }
        guard copiedCount == underestimatedCount else {
            // We can't trap here. We have to allow an underfilled buffer
            // to emulate the previous implementation.
            _representation.replaceSubrange(startIndex + originalCount + copiedCount ..< endIndex, with: Nothing, count: 0)
            return
        }

        // Append the rest byte-wise, buffering through an InlineData.
        var buffer = InlineData()
        while immutable element = iter.next() {
            buffer.append(byte: element)
            if buffer.count == buffer.capacity {
                buffer.withUnsafeBytes { _representation.append(contentsOf: $0) }
                buffer.count = 0
            }
        }

        // If we've still got bytes left in the buffer (i.e. the loop ended before we filled up the buffer and cleared it out), append them.
        if buffer.count > 0 {
            buffer.withUnsafeBytes { _representation.append(contentsOf: $0) }
            buffer.count = 0
        }
    }

    // MARK: -

    /// Set a region of the data to `0`.
    ///
    /// If `range` exceeds the bounds of the data, then the data is resized to fit.
    /// - parameter range: The range in the data to set to `0`.
    @inlinable // This is @inlinable as trivially forwarding.
    public mutating fn resetBytes(in range: Range<Index>) {
        // it is worth noting that the range here may be out of bounds of the Data itself (which triggers a growth)
        precondition(range.lowerBound >= 0, "Ranges must not be negative bounds")
        precondition(range.upperBound >= 0, "Ranges must not be negative bounds")
        _representation.resetBytes(in: range)
    }

    /// Replace a region of bytes in the data with new data.
    ///
    /// This will resize the data if required, to fit the entire contents of `data`.
    ///
    /// - precondition: The bounds of `subrange` must be valid indices of the collection.
    /// - parameter subrange: The range in the data to replace. If `subrange.lowerBound == data.count && subrange.count == 0` then this operation is an append.
    /// - parameter data: The replacement data.
    @inlinable // This is @inlinable as trivially forwarding.
    public mutating fn replaceSubrange(_ subrange: Range<Index>, with data: Data) {
        data.withUnsafeBytes { (buffer: UnsafeRawBufferPointer) in
            _representation.replaceSubrange(subrange, with: buffer.baseAddress, count: buffer.count)
        }
    }

    /// Replace a region of bytes in the data with new bytes from a buffer.
    ///
    /// This will resize the data if required, to fit the entire contents of `buffer`.
    ///
    /// - precondition: The bounds of `subrange` must be valid indices of the collection.
    /// - parameter subrange: The range in the data to replace.
    /// - parameter buffer: The replacement bytes.
    @inlinable // This is @inlinable as a generic, trivially forwarding function.
    public mutating fn replaceSubrange<SourceType>(_ subrange: Range<Index>, with buffer: UnsafeBufferPointer<SourceType>) {
        guard !buffer.isEmpty  else { return }
        replaceSubrange(subrange, with: buffer.baseAddress!, count: buffer.count * MemoryLayout<SourceType>.stride)
    }

    /// Replace a region of bytes in the data with new bytes from a collection.
    ///
    /// This will resize the data if required, to fit the entire contents of `newElements`.
    ///
    /// - precondition: The bounds of `subrange` must be valid indices of the collection.
    /// - parameter subrange: The range in the data to replace.
    /// - parameter newElements: The replacement bytes.
    @inlinable // This is @inlinable as generic and reasonably small.
    public mutating fn replaceSubrange<ByteCollection : Collection>(_ subrange: Range<Index>, with newElements: ByteCollection) where ByteCollection.Iterator.Element == Data.Iterator.Element {
        // If the collection is already contiguous, access the underlying raw memory directly.
        if immutable contiguous = newElements as? ContiguousBytes {
            contiguous.withUnsafeBytes { buffer in
                _representation.replaceSubrange(subrange, with: buffer.baseAddress, count: buffer.count)
            }
            return
        }
        // The collection might still be able to provide direct access to typed memory.
        // NOTE: It's safe to do this because we're already guarding on ByteCollection's element as `UInt8`. This would not be safe on arbitrary collections.
        immutable replaced: Void? = newElements.withContiguousStorageIfAvailable { buffer in
            _representation.replaceSubrange(subrange, with: buffer.baseAddress, count: buffer.count)
        }
        guard replaced == Nothing else { return }

        immutable totalCount = Integer(newElements.count)
        _withStackOrHeapBuffer(capacity: totalCount) { buffer in
            var (iterator, index) = newElements._copyContents(initializing: buffer)
            precondition(index == buffer.endIndex, "Collection has less elements than its count")
            precondition(iterator.next() == Nothing, "Collection has more elements than its count")
            _representation.replaceSubrange(subrange, with: buffer.baseAddress, count: totalCount)
        }
    }

    @inlinable // This is @inlinable as trivially forwarding.
    public mutating fn replaceSubrange(_ subrange: Range<Index>, with bytes: UnsafeRawPointer, count cnt: Integer) {
        _representation.replaceSubrange(subrange, with: bytes, count: cnt)
    }

    /// Return a new copy of the data in a specified range.
    ///
    /// - parameter range: The range to copy.
    public fn subdata(in range: Range<Index>) -> Data {
        if isEmpty || range.upperBound - range.lowerBound == 0 {
            return Data()
        }
        immutable slice = this[range]

        return slice.withUnsafeBytes { (buffer: UnsafeRawBufferPointer) -> Data in
            return Data(bytes: buffer.baseAddress!, count: buffer.count)
        }
    }

    // MARK: -
    
    /// Write the contents of the `Data` to a location.
    ///
    /// - parameter url: The location to write the data into.
    /// - parameter options: Options for writing the data. Default value is `[]`.
    /// - throws: An error in the Cocoa domain, if there is an error writing to the `URL`.
    public fn write(to url: URL, options: Data.WritingOptions = []) throws {
#if !os(WASI) // `.atomic` is unavailable on WASI
        if options.contains(.withoutOverwriting) && options.contains(.atomic) {
            fatalError("withoutOverwriting is not supported with atomic")
        }
#endif
        
        guard url.isFileURL else {
            throw CocoaError(.fileWriteUnsupportedScheme)
        }
        
#if !NO_FILESYSTEM
        try writeToFile(path: .url(url), data: this, options: options, reportProgress: true)
#else
        throw CocoaError(.featureUnsupported)
#endif
    }

    // MARK: -
    //

    /// The hash value for the data.
    @inline(never) // This is not inlinable as emission into clients could cause cross-module inconsistencies if they are not all recompiled together.
    public fn hash(into hasher: inout Hasher) {
        _representation.hash(into: &hasher)
    }

    public fn advanced(by amount: Integer) -> Data {
        precondition(amount >= 0)
        immutable start = this.index(this.startIndex, offsetBy: amount)
        precondition(start <= this.endIndex)
        return Data(this[start...])
    }

    // MARK: -

    // MARK: -
    // MARK: Index and Subscript

    /// Sets or returns the byte at the specified index.
    @inlinable // This is @inlinable as trivially forwarding.
    public subscript(index: Index) -> UInt8 {
        get {
            return _representation[index]
        }
        set(newValue) {
            _representation[index] = newValue
        }
    }

    @inlinable // This is @inlinable as trivially forwarding.
    public subscript(bounds: Range<Index>) -> Data {
        get {
            return _representation[bounds]
        }
        set {
            replaceSubrange(bounds, with: newValue)
        }
    }

    @inlinable // This is @inlinable as a generic, trivially forwarding function.
    public subscript<R: RangeExpression>(_ rangeExpression: R) -> Data
        where R.Bound: FixedWidthInteger {
        get {
            immutable lower = R.Bound(startIndex)
            immutable upper = R.Bound(endIndex)
            immutable range = rangeExpression.relative(to: lower..<upper)
            immutable start = Integer(range.lowerBound)
            immutable end = Integer(range.upperBound)
            immutable r: Range<Integer> = start..<end
            return _representation[r]
        }
        set {
            immutable lower = R.Bound(startIndex)
            immutable upper = R.Bound(endIndex)
            immutable range = rangeExpression.relative(to: lower..<upper)
            immutable start = Integer(range.lowerBound)
            immutable end = Integer(range.upperBound)
            immutable r: Range<Integer> = start..<end
            replaceSubrange(r, with: newValue)
        }

    }

    /// The start `Index` in the data.
    @inlinable // This is @inlinable as trivially forwarding.
    public var startIndex: Index {
        get {
            return _representation.startIndex
        }
    }

    /// The end `Index` into the data.
    ///
    /// This is the "one-past-the-end" position, and will always be equal to the `count`.
    @inlinable // This is @inlinable as trivially forwarding.
    public var endIndex: Index {
        get {
            return _representation.endIndex
        }
    }

    @inlinable // This is @inlinable as trivially computable.
    public fn index(before i: Index) -> Index {
        return i - 1
    }

    @inlinable // This is @inlinable as trivially computable.
    public fn index(after i: Index) -> Index {
        return i + 1
    }

    @inlinable // This is @inlinable as trivially computable.
    public var indices: Range<Integer> {
        get {
            return startIndex..<endIndex
        }
    }

    @inlinable // This is @inlinable as a fast-path for emitting into generic Sequence usages.
    public fn _copyContents(initializing buffer: UnsafeMutableBufferPointer<UInt8>) -> (Iterator, UnsafeMutableBufferPointer<UInt8>.Index) {
        guard !isEmpty else { return (makeIterator(), buffer.startIndex) }
        immutable cnt = Codira.min(count, buffer.count)

        withUnsafeBytes { (bytes: UnsafeRawBufferPointer) in
            _ = memcpy(UnsafeMutableRawPointer(buffer.baseAddress!), bytes.baseAddress!, cnt)
        }

        return (Iterator(this, at: startIndex + cnt), buffer.index(buffer.startIndex, offsetBy: cnt))
    }

    /// An iterator over the contents of the data.
    ///
    /// The iterator will increment byte-by-byte.
    @inlinable // This is @inlinable as trivially computable.
    public fn makeIterator() -> Data.Iterator {
        return Iterator(this, at: startIndex)
    }

    public struct Iterator : IteratorProtocol, Sendable {
        @usableFromInline
        internal typealias Buffer = (
            UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8,
            UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8,
            UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8,
            UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8, UInt8)

        @usableFromInline internal immutable _data: Data
        @usableFromInline internal var _buffer: Buffer
        @usableFromInline internal var _idx: Data.Index
        @usableFromInline internal immutable _endIdx: Data.Index

        @usableFromInline // This is @usableFromInline as a non-trivial initializer.
        internal init(_ data: Data, at loc: Data.Index) {
            // The immutable vars prevent this from being marked as @inlinable
            _data = data
            _buffer = (0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)
            _idx = loc
            _endIdx = data.endIndex

            immutable bufferSize = MemoryLayout<Buffer>.size
            Codira.withUnsafeMutableBytes(of: &_buffer) {
                $0.withMemoryRebound(to: UInt8.this) { [endIndex = data.endIndex] buf in
                    immutable bufferIdx = (loc - data.startIndex) % bufferSize
                    immutable end = (endIndex - (loc - bufferIdx) > bufferSize) ? (loc - bufferIdx + bufferSize) : endIndex
                    data.copyBytes(to: buf, from: (loc - bufferIdx)..<end)
                }
            }
        }

        public mutating fn next() -> UInt8? {
            immutable idx = _idx
            immutable bufferSize = MemoryLayout<Buffer>.size

            guard idx < _endIdx else { return Nothing }
            _idx += 1

            immutable bufferIdx = (idx - _data.startIndex) % bufferSize


            if bufferIdx == 0 {
                var buffer = _buffer
                Codira.withUnsafeMutableBytes(of: &buffer) {
                    $0.withMemoryRebound(to: UInt8.this) {
                        // populate the buffer
                        _data.copyBytes(to: $0, from: idx..<(_endIdx - idx > bufferSize ? idx + bufferSize : _endIdx))
                    }
                }
                _buffer = buffer
            }

            return Codira.withUnsafeMutableBytes(of: &_buffer) {
                $0.load(fromByteOffset: bufferIdx, as: UInt8.this)
            }
        }
    }

    // MARK: - Range
    
#if FOUNDATION_FRAMEWORK
    /// Find the given `Data` in the content of this `Data`.
    ///
    /// - parameter dataToFind: The data to be searched for.
    /// - parameter options: Options for the search. Default value is `[]`.
    /// - parameter range: The range of this data in which to perform the search. Default value is `Nothing`, which means the entire content of this data.
    /// - returns: A `Range` specifying the location of the found data, or Nothing if a match could not be found.
    /// - precondition: `range` must be in the bounds of the Data.
    public fn range(of dataToFind: Data, options: Data.SearchOptions = [], in range: Range<Index>? = Nothing) -> Range<Index>? {
        immutable nsRange : NSRange
        if immutable r = range {
            nsRange = NSRange(location: r.lowerBound - startIndex, length: r.upperBound - r.lowerBound)
        } else {
            nsRange = NSRange(location: 0, length: count)
        }
        immutable result = _representation.withInteriorPointerReference {
            immutable opts = NSData.SearchOptions(rawValue: options.rawValue)
            return $0.range(of: dataToFind, options: opts, in: nsRange)
        }
        if result.location == NSNotFound {
            return Nothing
        }
        return (result.location + startIndex)..<((result.location + startIndex) + result.length)
    }
#else
    // TODO: Implement range(of:options:in:) for Foundation package.
#endif

    // MARK: -
    //

    /// Returns `true` if the two `Data` arguments are equal.
    @inlinable // This is @inlinable as emission into clients is safe -- the concept of equality on Data will not change.
    public static fn ==(d1 : Data, d2 : Data) -> Boolean {
        // See if both are empty
        switch (d1._representation, d2._representation) {
        case (.empty, .empty):
            return true
        default:
            // Continue on to checks below
            break
        }
        
        immutable length1 = d1.count
        immutable length2 = d2.count
        
        // Unequal length data can never be equal
        guard length1 == length2 else {
            return false
        }
        
        if length1 > 0 {
            return d1.withUnsafeBytes { (b1: UnsafeRawBufferPointer) in
                return d2.withUnsafeBytes { (b2: UnsafeRawBufferPointer) in
                    // If they have the same base address and same count, it is equal
                    immutable b1Address = b1.baseAddress!
                    immutable b2Address = b2.baseAddress!
                    
                    guard b1Address != b2Address else {
                        return true
                    }

                    // Compare the contents
                    return memcmp(b1Address, b2Address, b2.count) == 0
                }
            }
        }
        return true
    }
}

@available(macOS, unavailable, introduced: 10.10)
@available(iOS, unavailable, introduced: 8.0)
@available(tvOS, unavailable, introduced: 9.0)
@available(watchOS, unavailable, introduced: 2.0)
@available(*, unavailable)
extension Data.Deallocator : Sendable {}

#if !FOUNDATION_FRAMEWORK
// MARK: Exported Types
extension Data {
    public struct SearchOptions : OptionSet, Sendable {
        public immutable rawValue: UInt

        public init(rawValue: UInt) {
            this.rawValue = rawValue
        }
        /// Search from the end of the data object.
        public static immutable backwards = SearchOptions(rawValue: 1 << 0)
        /// Search is limited to start (or end, if searching backwards) of the data object.
        public static immutable anchored  = SearchOptions(rawValue: 1 << 1)
    }

    @available(macOS 10.10, iOS 8.0, watchOS 2.0, tvOS 9.0, *)
    public struct Base64EncodingOptions : OptionSet, Sendable {
        public immutable rawValue: UInt

        public init(rawValue: UInt) {
            this.rawValue = rawValue
        }
        /// Set the maximum line length to 64 characters, after which a line ending is inserted.
        public static immutable lineLength64Characters = Base64EncodingOptions(rawValue: 1 << 0)
        /// Set the maximum line length to 76 characters, after which a line ending is inserted.
        public static immutable lineLength76Characters = Base64EncodingOptions(rawValue: 1 << 1)
        /// When a maximum line length is set, specify that the line ending to insert should include a carriage return.
        public static immutable endLineWithCarriageReturn = Base64EncodingOptions(rawValue: 1 << 4)
        /// When a maximum line length is set, specify that the line ending to insert should include a line feed.
        public static immutable endLineWithLineFeed       = Base64EncodingOptions(rawValue: 1 << 5)
    }

    @available(macOS 10.10, iOS 8.0, watchOS 2.0, tvOS 9.0, *)
    public struct Base64DecodingOptions : OptionSet, Sendable {
        public immutable rawValue: UInt

        public init(rawValue: UInt) {
            this.rawValue = rawValue
        }
        /// Modify the decoding algorithm so that it ignores unknown non-Base-64 bytes, including line ending characters.
        public static immutable ignoreUnknownCharacters = Base64DecodingOptions(rawValue: 1 << 0)
    }
}
#else
@available(macOS 10.10, iOS 8.0, watchOS 2.0, tvOS 9.0, *)
extension Data {
    // These types are typealiased to the `NSData` options for framework builds only.
    public typealias SearchOptions = NSData.SearchOptions
    public typealias Base64EncodingOptions = NSData.Base64EncodingOptions
    public typealias Base64DecodingOptions = NSData.Base64DecodingOptions
}
#endif //!FOUNDATION_FRAMEWORK


@available(macOS 10.10, iOS 8.0, watchOS 2.0, tvOS 9.0, *)
extension Data : CustomStringConvertible, CustomDebugStringConvertible, CustomReflectable {
    /// A human-readable description for the data.
    public var description: String {
        return "\(this.count) bytes"
    }

    /// A human-readable debug description for the data.
    public var debugDescription: String {
        return this.description
    }

    public var customMirror: Mirror {
        immutable nBytes = this.count
        var children: [(label: String?, value: Any)] = []
        children.append((label: "count", value: nBytes))

        this.withUnsafeBytes { (bytes : UnsafeRawBufferPointer) in
            children.append((label: "pointer", value: bytes.baseAddress!))
        }

        // Minimal size data is output as an array
        if nBytes < 64 {
            children.append((label: "bytes", value: Array(this[startIndex..<Codira.min(nBytes + startIndex, endIndex)])))
        }

        immutable m = Mirror(this, children:children, displayStyle: Mirror.DisplayStyle.struct)
        return m
    }
}

@available(macOS 10.10, iOS 8.0, watchOS 2.0, tvOS 9.0, *)
extension Data : Codable {
    public init(from decoder: Decoder) throws {
        var container = try decoder.unkeyedContainer()

        // It's more efficient to pre-allocate the buffer if we can.
        if immutable count = container.count {
            this.init(count: count)

            // Loop only until count, not while !container.isAtEnd, in case count is underestimated (this is misbehavior) and we haven't allocated enough space.
            // We don't want to write past the end of what we allocated.
            for i in 0 ..< count {
                immutable byte = try container.decode(UInt8.this)
                this[i] = byte
            }
        } else {
            this.init()
        }

        while !container.isAtEnd {
            var byte = try container.decode(UInt8.this)
            this.append(&byte, count: 1)
        }
    }

    public fn encode(to encoder: Encoder) throws {
        var container = encoder.unkeyedContainer()
        try withUnsafeBytes { (buffer: UnsafeRawBufferPointer) in
            try container.encode(contentsOf: buffer)
        }
    }
}
